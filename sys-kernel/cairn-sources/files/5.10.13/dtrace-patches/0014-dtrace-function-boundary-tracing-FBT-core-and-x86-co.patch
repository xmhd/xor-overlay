From bc81b22d39f0332275cd6834fdffb749368e62a0 Mon Sep 17 00:00:00 2001
From: Kris Van Hees <kris.van.hees@oracle.com>
Date: Mon, 19 Nov 2018 19:02:39 +0000
Subject: [PATCH 14/19] dtrace: function boundary tracing (FBT) core and x86
 components

This commit implements the core components needed for FBT tracing.
Unlike ftrace we allow the tracing of very large numbers of functions at
once: the intent is that the system should still be stable when every
eligible function in the kernel is traced simultaneously.  Functions
that are not safe for this (because e.g. they are used in trap handling,
or by functions called by the DTrace module itself during probe
processing) are (semi-manually) blacklisted from being probed.

As part of this, a treewide change to the prototype of traps is started:
they all return 0 by default now, with a nonzero return value indicating
that the trap happened as a result of an FBT probe: the return value is
the opcode atop which the trap was originally placed for later emulation.

Signed-off-by: Kris Van Hees <kris.van.hees@oracle.com>
Signed-off-by: Tomas Jedlicka <tomas.jedlicka@oracle.com>
Signed-off-by: Nick Alcock <nick.alcock@oracle.com>
Signed-off-by: Eugene Loh <eugene.loh@oracle.com>
Signed-off-by: David Mc Lean <david.mclean@oracle.com>
Signed-off-by: Vincent Lim <vincent.lim@oracle.com>
---
 arch/x86/entry/entry_64.S             | 134 ++++++++++++++++++-
 arch/x86/hyperv/hv_init.c             |   1 +
 arch/x86/include/asm/idtentry.h       |  86 +++++++------
 arch/x86/include/asm/irq_stack.h      |  36 +++---
 arch/x86/kernel/apic/apic.c           |   4 +
 arch/x86/kernel/apic/vector.c         |   1 +
 arch/x86/kernel/cpu/acrn.c            |   1 +
 arch/x86/kernel/cpu/mce/amd.c         |   1 +
 arch/x86/kernel/cpu/mce/core.c        |   3 +
 arch/x86/kernel/cpu/mce/therm_throt.c |   1 +
 arch/x86/kernel/cpu/mce/threshold.c   |   1 +
 arch/x86/kernel/cpu/mshyperv.c        |   2 +
 arch/x86/kernel/dtrace_fbt.c          | 177 ++++++++++++++++++++++++++
 arch/x86/kernel/fbt_blacklist.h       |  95 ++++++++++++++
 arch/x86/kernel/irq.c                 |   5 +
 arch/x86/kernel/irq_work.c            |   1 +
 arch/x86/kernel/kvm.c                 |   1 +
 arch/x86/kernel/nmi.c                 |   5 +-
 arch/x86/kernel/sev-es.c              |   6 +-
 arch/x86/kernel/smp.c                 |   4 +
 arch/x86/kernel/traps.c               |  91 ++++++++-----
 arch/x86/mm/fault.c                   |   3 +-
 arch/x86/xen/enlighten_hvm.c          |   1 +
 arch/x86/xen/enlighten_pv.c           |   8 +-
 include/linux/dtrace_fbt.h            |  48 +++++++
 kernel/dtrace/Kconfig                 |   7 +
 kernel/dtrace/Makefile                |   4 +-
 kernel/dtrace/dtrace_fbt_core.c       | 125 ++++++++++++++++++
 kernel/dtrace/dtrace_os.c             |   2 +
 kernel/kprobes.c                      |   8 ++
 30 files changed, 764 insertions(+), 98 deletions(-)
 create mode 100644 arch/x86/kernel/dtrace_fbt.c
 create mode 100644 arch/x86/kernel/fbt_blacklist.h
 create mode 100644 include/linux/dtrace_fbt.h
 create mode 100644 kernel/dtrace/dtrace_fbt_core.c

diff --git a/arch/x86/entry/entry_64.S b/arch/x86/entry/entry_64.S
index cad08703c4ad..689b45e5b0c4 100644
--- a/arch/x86/entry/entry_64.S
+++ b/arch/x86/entry/entry_64.S
@@ -38,7 +38,7 @@
 #include <asm/frame.h>
 #include <asm/trapnr.h>
 #include <asm/nospec-branch.h>
-#include <asm/fsgsbase.h>
+#include <asm/dtrace_util.h>
 #include <linux/err.h>
 
 #include "calling.h"
@@ -335,6 +335,15 @@ SYM_CODE_END(ret_from_fork)
 
 	call	\cfunc
 
+#ifdef CONFIG_DTRACE
+	/*
+	 * Nonzero exit from a trap handler means we want to emulate
+	 * an instruction.
+	 */
+	test %rax,%rax
+	jnz dtrace_error_return
+#endif
+
 	jmp	error_return
 .endm
 
@@ -1097,6 +1106,129 @@ SYM_CODE_START_LOCAL(error_return)
 	jmp	swapgs_restore_regs_and_return_to_usermode
 SYM_CODE_END(error_return)
 
+#ifdef CONFIG_DTRACE
+/*
+ * Emulate an instruction (given by one of the DTRACE_INVOP constants) on exit
+ * from a trap handler.
+ */
+SYM_CODE_START_LOCAL(dtrace_error_return)
+	UNWIND_HINT_REGS
+
+	negq %rax
+
+	cmpl $DTRACE_INVOP_MOV_RSP_RBP,%eax
+	je dtrace_emu_mov
+	cmpl $DTRACE_INVOP_PUSH_BP,%eax
+	je dtrace_emu_push
+	cmpl $DTRACE_INVOP_LEAVE,%eax
+	je dtrace_emu_leave
+	cmpl $DTRACE_INVOP_NOP,%eax
+	je dtrace_emu_nop
+	cmpl $DTRACE_INVOP_RET,%eax
+	je dtrace_emu_ret
+
+	leaq dtrace_error_msg(%rip),%rdi
+	movq %rax,%rsi
+	movq (%rsp),%rdx
+	call printk
+
+	jmp error_return
+
+dtrace_emu_mov:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/* Emulate "mov %rsp, %rbp" instruction. */
+	pushq %rax			/* push temp */
+	movq 8(%rsp),%rax		/* load calling RIP */
+	addq $3,%rax			/* increment over trapping instr */
+	movq %rax,8(%rsp)		/* store calling RIP */
+	movq 32(%rsp),%rbp		/* load %rsp into %rbp */
+	popq %rax			/* pop off temp */
+
+	INTERRUPT_RETURN
+
+dtrace_emu_push:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/*
+	 * Emulate a "pushq %rbp" instruction.  We need to move the stack down
+	 * to make room for the extra address getting pushed.
+	 */
+	subq $16,%rsp			/* make room for %rbp */
+	pushq %rax			/* push temp */
+	movq 24(%rsp),%rax		/* load calling RIP */
+	addq $1,%rax			/* increment over trapping instr */
+	movq %rax,8(%rsp)		/* store calling RIP */
+	movq 32(%rsp),%rax		/* load calling CS */
+	movq %rax,16(%rsp)		/* store calling CS */
+	movq 40(%rsp),%rax		/* load calling RFLAGS */
+	movq %rax,24(%rsp)		/* store calling RFLAGS */
+	movq 48(%rsp),%rax		/* load calling RSP */
+	subq $8,%rax			/* make room for %rbp */
+	movq %rax,32(%rsp)		/* store calling RSP */
+	movq 56(%rsp),%rax		/* load calling SS */
+	movq %rax,40(%rsp)		/* store calling SS */
+	movq 32(%rsp),%rax		/* reload calling RSP */
+	movq %rbp,(%rax)		/* store %rbp there */
+	popq %rax			/* pop off temp */
+
+	INTERRUPT_RETURN
+
+dtrace_emu_nop:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/* Emulate a "nop" instruction. */
+	incq (%rsp)
+
+	INTERRUPT_RETURN
+
+dtrace_emu_leave:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/*
+	 * Emulate a "leave" instruction.  This is equivalent to the sequence:
+	 *	movq %rbp,%rsp
+	 *	popq %rbp
+	 * We can use the fact that on x86_64 %rsp is saved explicitly, so we
+	 * do not need to move any data around.
+	 */
+	pushq %rax			/* push temp */
+	movq 8(%rsp),%rax		/* load calling RIP */
+	addq $1,%rax			/* increment over trapping instr */
+	movq %rax,8(%rsp)		/* store calling RIP */
+	movq (%rbp),%rax		/* get new %rbp */
+	addq $8,%rbp			/* adjust new %rsp */
+	movq %rbp,32(%rsp)		/* store new %rsp */
+	movq %rax,%rbp			/* set new %rbp */
+	popq %rax			/* pop off temp */
+
+	INTERRUPT_RETURN
+
+dtrace_emu_ret:
+	POP_REGS
+	addq	$8, %rsp	/* skip regs->orig_ax */
+
+	/* Emulate a "ret" instruction. */
+	pushq %rax			/* push temp */
+	movq 32(%rsp),%rax		/* load %rsp */
+	movq (%rax),%rax		/* load calling RIP */
+	movq %rax,8(%rsp)		/* store calling RIP */
+	addq $8,32(%rsp)		/* adjust new %rsp */
+	popq %rax			/* pop off temp */
+
+	INTERRUPT_RETURN
+SYM_CODE_END(dtrace_error_return)
+
+.pushsection .rodata, "a"
+dtrace_error_msg:
+	.asciz "DTRACE: non-zero (%x) return from trap at %x\n"
+.popsection
+#endif
+
 /*
  * Runs on exception stack.  Xen PV does not go through this path at all,
  * so we can use real assembly here.
diff --git a/arch/x86/hyperv/hv_init.c b/arch/x86/hyperv/hv_init.c
index 6375967a8244..e22347681c03 100644
--- a/arch/x86/hyperv/hv_init.c
+++ b/arch/x86/hyperv/hv_init.c
@@ -161,6 +161,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_hyperv_reenlightenment)
 	ack_APIC_irq();
 	inc_irq_stat(irq_hv_reenlightenment_count);
 	schedule_delayed_work(&hv_reenlightenment_work, HZ/10);
+	return 0;
 }
 
 void set_hv_tscchange_cb(void (*cb)(void))
diff --git a/arch/x86/include/asm/idtentry.h b/arch/x86/include/asm/idtentry.h
index b2442eb0ac2f..2222870fb7ab 100644
--- a/arch/x86/include/asm/idtentry.h
+++ b/arch/x86/include/asm/idtentry.h
@@ -32,7 +32,7 @@ void idtentry_exit_nmi(struct pt_regs *regs, bool irq_state);
 #define DECLARE_IDTENTRY(vector, func)					\
 	asmlinkage void asm_##func(void);				\
 	asmlinkage void xen_asm_##func(void);				\
-	__visible void func(struct pt_regs *regs)
+	__visible int func(struct pt_regs *regs)
 
 /**
  * DEFINE_IDTENTRY - Emit code for simple IDT entry points
@@ -48,19 +48,21 @@ void idtentry_exit_nmi(struct pt_regs *regs, bool irq_state);
  * which has to run before returning to the low level assembly code.
  */
 #define DEFINE_IDTENTRY(func)						\
-static __always_inline void __##func(struct pt_regs *regs);		\
+static __always_inline int __##func(struct pt_regs *regs);		\
 									\
-__visible noinstr void func(struct pt_regs *regs)			\
+__visible noinstr int func(struct pt_regs *regs)			\
 {									\
 	irqentry_state_t state = irqentry_enter(regs);			\
+	int ret;							\
 									\
 	instrumentation_begin();					\
-	__##func (regs);						\
+	ret = __##func (regs);						\
 	instrumentation_end();						\
 	irqentry_exit(regs, state);					\
+	return ret;							\
 }									\
 									\
-static __always_inline void __##func(struct pt_regs *regs)
+static __always_inline int __##func(struct pt_regs *regs)
 
 /* Special case for 32bit IRET 'trap' */
 #define DECLARE_IDTENTRY_SW	DECLARE_IDTENTRY
@@ -83,7 +85,7 @@ static __always_inline void __##func(struct pt_regs *regs)
 #define DECLARE_IDTENTRY_ERRORCODE(vector, func)			\
 	asmlinkage void asm_##func(void);				\
 	asmlinkage void xen_asm_##func(void);				\
-	__visible void func(struct pt_regs *regs, unsigned long error_code)
+	__visible int func(struct pt_regs *regs, unsigned long error_code)
 
 /**
  * DEFINE_IDTENTRY_ERRORCODE - Emit code for simple IDT entry points
@@ -93,22 +95,24 @@ static __always_inline void __##func(struct pt_regs *regs)
  * Same as DEFINE_IDTENTRY, but has an extra error_code argument
  */
 #define DEFINE_IDTENTRY_ERRORCODE(func)					\
-static __always_inline void __##func(struct pt_regs *regs,		\
-				     unsigned long error_code);		\
+static __always_inline int __##func(struct pt_regs *regs,		\
+				    unsigned long error_code);		\
 									\
-__visible noinstr void func(struct pt_regs *regs,			\
-			    unsigned long error_code)			\
+__visible noinstr int func(struct pt_regs *regs,			\
+			   unsigned long error_code)			\
 {									\
 	irqentry_state_t state = irqentry_enter(regs);			\
+	int ret;							\
 									\
 	instrumentation_begin();					\
-	__##func (regs, error_code);					\
+	ret = __##func (regs, error_code);				\
 	instrumentation_end();						\
 	irqentry_exit(regs, state);					\
+	return ret;							\
 }									\
 									\
-static __always_inline void __##func(struct pt_regs *regs,		\
-				     unsigned long error_code)
+static __always_inline int __##func(struct pt_regs *regs,		\
+				    unsigned long error_code)
 
 /**
  * DECLARE_IDTENTRY_RAW - Declare functions for raw IDT entry points
@@ -136,7 +140,7 @@ static __always_inline void __##func(struct pt_regs *regs,		\
  * is required before the enter/exit() helpers are invoked.
  */
 #define DEFINE_IDTENTRY_RAW(func)					\
-__visible noinstr void func(struct pt_regs *regs)
+__visible noinstr int func(struct pt_regs *regs)
 
 /**
  * DECLARE_IDTENTRY_RAW_ERRORCODE - Declare functions for raw IDT entry points
@@ -164,7 +168,7 @@ __visible noinstr void func(struct pt_regs *regs)
  * is required before the enter/exit() helpers are invoked.
  */
 #define DEFINE_IDTENTRY_RAW_ERRORCODE(func)				\
-__visible noinstr void func(struct pt_regs *regs, unsigned long error_code)
+__visible noinstr int func(struct pt_regs *regs, unsigned long error_code)
 
 /**
  * DECLARE_IDTENTRY_IRQ - Declare functions for device interrupt IDT entry
@@ -190,23 +194,25 @@ __visible noinstr void func(struct pt_regs *regs, unsigned long error_code)
  * has to be done in the function body if necessary.
  */
 #define DEFINE_IDTENTRY_IRQ(func)					\
-static __always_inline void __##func(struct pt_regs *regs, u8 vector);	\
+static __always_inline int __##func(struct pt_regs *regs, u8 vector);	\
 									\
-__visible noinstr void func(struct pt_regs *regs,			\
-			    unsigned long error_code)			\
+__visible noinstr int func(struct pt_regs *regs,			\
+			   unsigned long error_code)			\
 {									\
 	irqentry_state_t state = irqentry_enter(regs);			\
+	int ret;							\
 									\
 	instrumentation_begin();					\
 	irq_enter_rcu();						\
 	kvm_set_cpu_l1tf_flush_l1d();					\
-	__##func (regs, (u8)error_code);				\
+	ret = __##func (regs, (u8)error_code);				\
 	irq_exit_rcu();							\
 	instrumentation_end();						\
 	irqentry_exit(regs, state);					\
+	return ret;							\
 }									\
 									\
-static __always_inline void __##func(struct pt_regs *regs, u8 vector)
+static __always_inline int __##func(struct pt_regs *regs, u8 vector)
 
 /**
  * DECLARE_IDTENTRY_SYSVEC - Declare functions for system vector entry points
@@ -233,22 +239,24 @@ static __always_inline void __##func(struct pt_regs *regs, u8 vector)
  * Runs the function on the interrupt stack if the entry hit kernel mode
  */
 #define DEFINE_IDTENTRY_SYSVEC(func)					\
-static void __##func(struct pt_regs *regs);				\
+static int __##func(struct pt_regs *regs);				\
 									\
-__visible noinstr void func(struct pt_regs *regs)			\
+__visible noinstr int func(struct pt_regs *regs)			\
 {									\
 	irqentry_state_t state = irqentry_enter(regs);			\
+	int ret;							\
 									\
 	instrumentation_begin();					\
 	irq_enter_rcu();						\
 	kvm_set_cpu_l1tf_flush_l1d();					\
-	run_sysvec_on_irqstack_cond(__##func, regs);			\
+	ret = run_sysvec_on_irqstack_cond(__##func, regs);		\
 	irq_exit_rcu();							\
 	instrumentation_end();						\
 	irqentry_exit(regs, state);					\
+	return ret;							\
 }									\
 									\
-static noinline void __##func(struct pt_regs *regs)
+static noinline int __##func(struct pt_regs *regs)
 
 /**
  * DEFINE_IDTENTRY_SYSVEC_SIMPLE - Emit code for simple system vector IDT
@@ -262,22 +270,24 @@ static noinline void __##func(struct pt_regs *regs)
  * interrupt vectors.
  */
 #define DEFINE_IDTENTRY_SYSVEC_SIMPLE(func)				\
-static __always_inline void __##func(struct pt_regs *regs);		\
+static __always_inline int __##func(struct pt_regs *regs);		\
 									\
-__visible noinstr void func(struct pt_regs *regs)			\
+__visible noinstr int func(struct pt_regs *regs)			\
 {									\
 	irqentry_state_t state = irqentry_enter(regs);			\
+	int ret;							\
 									\
 	instrumentation_begin();					\
 	__irq_enter_raw();						\
 	kvm_set_cpu_l1tf_flush_l1d();					\
-	__##func (regs);						\
+	ret = __##func (regs);						\
 	__irq_exit_raw();						\
 	instrumentation_end();						\
 	irqentry_exit(regs, state);					\
+	return ret;							\
 }									\
 									\
-static __always_inline void __##func(struct pt_regs *regs)
+static __always_inline int __##func(struct pt_regs *regs)
 
 /**
  * DECLARE_IDTENTRY_XENCB - Declare functions for XEN HV callback entry point
@@ -306,7 +316,7 @@ static __always_inline void __##func(struct pt_regs *regs)
  */
 #define DECLARE_IDTENTRY_IST(vector, func)				\
 	DECLARE_IDTENTRY_RAW(vector, func);				\
-	__visible void noist_##func(struct pt_regs *regs)
+	__visible int noist_##func(struct pt_regs *regs)
 
 /**
  * DECLARE_IDTENTRY_VC - Declare functions for the VC entry point
@@ -318,8 +328,8 @@ static __always_inline void __##func(struct pt_regs *regs)
  */
 #define DECLARE_IDTENTRY_VC(vector, func)				\
 	DECLARE_IDTENTRY_RAW_ERRORCODE(vector, func);			\
-	__visible noinstr void ist_##func(struct pt_regs *regs, unsigned long error_code);	\
-	__visible noinstr void safe_stack_##func(struct pt_regs *regs, unsigned long error_code)
+	__visible noinstr int ist_##func(struct pt_regs *regs, unsigned long error_code);	\
+	__visible noinstr int safe_stack_##func(struct pt_regs *regs, unsigned long error_code)
 
 /**
  * DEFINE_IDTENTRY_IST - Emit code for IST entry points
@@ -401,10 +411,10 @@ static __always_inline void __##func(struct pt_regs *regs)
  * - The C handler called from the C shim
  */
 #define DECLARE_IDTENTRY_DF(vector, func)				\
-	asmlinkage void asm_##func(void);				\
-	__visible void func(struct pt_regs *regs,			\
-			    unsigned long error_code,			\
-			    unsigned long address)
+	asmlinkage int asm_##func(void);				\
+	__visible int func(struct pt_regs *regs,			\
+			   unsigned long error_code,			\
+			   unsigned long address)
 
 /**
  * DEFINE_IDTENTRY_DF - Emit code for double fault on 32bit
@@ -414,9 +424,9 @@ static __always_inline void __##func(struct pt_regs *regs)
  * cr2 in the address argument.
  */
 #define DEFINE_IDTENTRY_DF(func)					\
-__visible noinstr void func(struct pt_regs *regs,			\
-			    unsigned long error_code,			\
-			    unsigned long address)
+__visible noinstr int func(struct pt_regs *regs,			\
+			   unsigned long error_code,			\
+			   unsigned long address)
 
 #endif	/* !CONFIG_X86_64 */
 
diff --git a/arch/x86/include/asm/irq_stack.h b/arch/x86/include/asm/irq_stack.h
index 775816965c6a..04f91986cee3 100644
--- a/arch/x86/include/asm/irq_stack.h
+++ b/arch/x86/include/asm/irq_stack.h
@@ -12,11 +12,11 @@ static __always_inline bool irqstack_active(void)
 	return __this_cpu_read(irq_count) != -1;
 }
 
-void asm_call_on_stack(void *sp, void (*func)(void), void *arg);
-void asm_call_sysvec_on_stack(void *sp, void (*func)(struct pt_regs *regs),
-			      struct pt_regs *regs);
-void asm_call_irq_on_stack(void *sp, void (*func)(struct irq_desc *desc),
-			   struct irq_desc *desc);
+int asm_call_on_stack(void *sp, void (*func)(void), void *arg);
+int asm_call_sysvec_on_stack(void *sp, int (*func)(struct pt_regs *regs),
+			     struct pt_regs *regs);
+int asm_call_irq_on_stack(void *sp, void (*func)(struct irq_desc *desc),
+			  struct irq_desc *desc);
 
 static __always_inline void __run_on_irqstack(void (*func)(void))
 {
@@ -27,15 +27,17 @@ static __always_inline void __run_on_irqstack(void (*func)(void))
 	__this_cpu_sub(irq_count, 1);
 }
 
-static __always_inline void
-__run_sysvec_on_irqstack(void (*func)(struct pt_regs *regs),
+static __always_inline int
+__run_sysvec_on_irqstack(int (*func)(struct pt_regs *regs),
 			 struct pt_regs *regs)
 {
 	void *tos = __this_cpu_read(hardirq_stack_ptr);
+	int ret;
 
 	__this_cpu_add(irq_count, 1);
-	asm_call_sysvec_on_stack(tos - 8, func, regs);
+	ret = asm_call_sysvec_on_stack(tos - 8, func, regs);
 	__this_cpu_sub(irq_count, 1);
+	return ret;
 }
 
 static __always_inline void
@@ -51,11 +53,11 @@ __run_irq_on_irqstack(void (*func)(struct irq_desc *desc),
 
 #else /* CONFIG_X86_64 */
 static inline bool irqstack_active(void) { return false; }
-static inline void __run_on_irqstack(void (*func)(void)) { }
-static inline void __run_sysvec_on_irqstack(void (*func)(struct pt_regs *regs),
-					    struct pt_regs *regs) { }
-static inline void __run_irq_on_irqstack(void (*func)(struct irq_desc *desc),
-					 struct irq_desc *desc) { }
+static inline int __run_on_irqstack(int (*func)(void)) { }
+static inline int __run_sysvec_on_irqstack(int (*func)(struct pt_regs *regs),
+					   struct pt_regs *regs) { }
+static inline int __run_irq_on_irqstack(int (*func)(struct irq_desc *desc),
+					struct irq_desc *desc) { }
 #endif /* !CONFIG_X86_64 */
 
 static __always_inline bool irq_needs_irq_stack(struct pt_regs *regs)
@@ -79,16 +81,16 @@ static __always_inline void run_on_irqstack_cond(void (*func)(void),
 		func();
 }
 
-static __always_inline void
-run_sysvec_on_irqstack_cond(void (*func)(struct pt_regs *regs),
+static __always_inline int
+run_sysvec_on_irqstack_cond(int (*func)(struct pt_regs *regs),
 			    struct pt_regs *regs)
 {
 	lockdep_assert_irqs_disabled();
 
 	if (irq_needs_irq_stack(regs))
-		__run_sysvec_on_irqstack(func, regs);
+		return __run_sysvec_on_irqstack(func, regs);
 	else
-		func(regs);
+		return func(regs);
 }
 
 static __always_inline void
diff --git a/arch/x86/kernel/apic/apic.c b/arch/x86/kernel/apic/apic.c
index 113f6ca7b828..06bd0bf3ae5a 100644
--- a/arch/x86/kernel/apic/apic.c
+++ b/arch/x86/kernel/apic/apic.c
@@ -1098,6 +1098,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_apic_timer_interrupt)
 	trace_local_timer_exit(LOCAL_TIMER_VECTOR);
 
 	set_irq_regs(old_regs);
+	return 0;
 }
 
 int setup_profiling_timer(unsigned int multiplier)
@@ -2160,11 +2161,13 @@ DEFINE_IDTENTRY_IRQ(spurious_interrupt)
 	}
 out:
 	trace_spurious_apic_exit(vector);
+	return 0;
 }
 
 DEFINE_IDTENTRY_SYSVEC(sysvec_spurious_apic_interrupt)
 {
 	__spurious_interrupt(regs, SPURIOUS_APIC_VECTOR);
+	return 0;
 }
 
 /*
@@ -2207,6 +2210,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_error_interrupt)
 	apic_printk(APIC_DEBUG, KERN_CONT "\n");
 
 	trace_error_apic_exit(ERROR_APIC_VECTOR);
+	return 0;
 }
 
 /**
diff --git a/arch/x86/kernel/apic/vector.c b/arch/x86/kernel/apic/vector.c
index 758bbf25ef74..a841e833f267 100644
--- a/arch/x86/kernel/apic/vector.c
+++ b/arch/x86/kernel/apic/vector.c
@@ -887,6 +887,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_irq_move_cleanup)
 	}
 
 	raw_spin_unlock(&vector_lock);
+	return 0;
 }
 
 static void __send_cleanup_vector(struct apic_chip_data *apicd)
diff --git a/arch/x86/kernel/cpu/acrn.c b/arch/x86/kernel/cpu/acrn.c
index 0b2c03943ac6..b17c61c16e99 100644
--- a/arch/x86/kernel/cpu/acrn.c
+++ b/arch/x86/kernel/cpu/acrn.c
@@ -53,6 +53,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_acrn_hv_callback)
 		acrn_intr_handler();
 
 	set_irq_regs(old_regs);
+	return 0;
 }
 
 const __initconst struct hypervisor_x86 x86_hyper_acrn = {
diff --git a/arch/x86/kernel/cpu/mce/amd.c b/arch/x86/kernel/cpu/mce/amd.c
index 0c6b02dd744c..8126b080d488 100644
--- a/arch/x86/kernel/cpu/mce/amd.c
+++ b/arch/x86/kernel/cpu/mce/amd.c
@@ -928,6 +928,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_deferred_error)
 	deferred_error_int_vector();
 	trace_deferred_error_apic_exit(DEFERRED_ERROR_VECTOR);
 	ack_APIC_irq();
+	return 0;
 }
 
 /*
diff --git a/arch/x86/kernel/cpu/mce/core.c b/arch/x86/kernel/cpu/mce/core.c
index 311688202ea5..e94cf10e05f7 100644
--- a/arch/x86/kernel/cpu/mce/core.c
+++ b/arch/x86/kernel/cpu/mce/core.c
@@ -2030,6 +2030,7 @@ DEFINE_IDTENTRY_MCE(exc_machine_check)
 	dr7 = local_db_save();
 	exc_machine_check_kernel(regs);
 	local_db_restore(dr7);
+	return 0;
 }
 
 /* The user mode variant. */
@@ -2040,6 +2041,7 @@ DEFINE_IDTENTRY_MCE_USER(exc_machine_check)
 	dr7 = local_db_save();
 	exc_machine_check_user(regs);
 	local_db_restore(dr7);
+	return 0;
 }
 #else
 /* 32bit unified entry point */
@@ -2053,6 +2055,7 @@ DEFINE_IDTENTRY_RAW(exc_machine_check)
 	else
 		exc_machine_check_kernel(regs);
 	local_db_restore(dr7);
+	return 0;
 }
 #endif
 
diff --git a/arch/x86/kernel/cpu/mce/therm_throt.c b/arch/x86/kernel/cpu/mce/therm_throt.c
index a7cd2d203ced..8e86a3baf32e 100644
--- a/arch/x86/kernel/cpu/mce/therm_throt.c
+++ b/arch/x86/kernel/cpu/mce/therm_throt.c
@@ -621,6 +621,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_thermal)
 	smp_thermal_vector();
 	trace_thermal_apic_exit(THERMAL_APIC_VECTOR);
 	ack_APIC_irq();
+	return 0;
 }
 
 /* Thermal monitoring depends on APIC, ACPI and clock modulation */
diff --git a/arch/x86/kernel/cpu/mce/threshold.c b/arch/x86/kernel/cpu/mce/threshold.c
index 6a059a035021..fa361a5b297a 100644
--- a/arch/x86/kernel/cpu/mce/threshold.c
+++ b/arch/x86/kernel/cpu/mce/threshold.c
@@ -28,4 +28,5 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_threshold)
 	mce_threshold_vector();
 	trace_threshold_apic_exit(THRESHOLD_APIC_VECTOR);
 	ack_APIC_irq();
+	return 0;
 }
diff --git a/arch/x86/kernel/cpu/mshyperv.c b/arch/x86/kernel/cpu/mshyperv.c
index 6cc50ab07bde..5146b1f713e0 100644
--- a/arch/x86/kernel/cpu/mshyperv.c
+++ b/arch/x86/kernel/cpu/mshyperv.c
@@ -53,6 +53,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_hyperv_callback)
 		ack_APIC_irq();
 
 	set_irq_regs(old_regs);
+	return 0;
 }
 
 int hv_setup_vmbus_irq(int irq, void (*handler)(void))
@@ -88,6 +89,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_hyperv_stimer0)
 	ack_APIC_irq();
 
 	set_irq_regs(old_regs);
+	return 0;
 }
 
 int hv_setup_stimer0_irq(int *irq, int *vector, void (*handler)(void))
diff --git a/arch/x86/kernel/dtrace_fbt.c b/arch/x86/kernel/dtrace_fbt.c
new file mode 100644
index 000000000000..52ff3f49d101
--- /dev/null
+++ b/arch/x86/kernel/dtrace_fbt.c
@@ -0,0 +1,177 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:        dtrace_fbt.c
+ * DESCRIPTION: Dynamic Tracing: FBT registration code (arch-specific)
+ *
+ * Copyright (c) 2010, 2017, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#include <linux/kernel.h>
+#include <linux/kallsyms.h>
+#include <linux/dtrace_os.h>
+#include <linux/dtrace_fbt.h>
+#include <linux/slab.h>
+#include <linux/sort.h>
+#include <asm/insn.h>
+#include <asm/sections.h>
+
+#define FBT_MOV_RSP_RBP_1	0x48
+#define FBT_MOV_RSP_RBP_2	0x89
+#define FBT_MOV_RSP_RBP_3	0xe5
+#define FBT_PUSHL_EBP		0x55
+#define FBT_NOP			0x90
+#define FBT_RET_IMM16		0xc2
+#define FBT_RET			0xc3
+#define FBT_LEAVE		0xc9
+
+#define BL_SENTRY(tp, nm)	extern tp nm;
+#define BL_DENTRY(tp, nm)
+#include "fbt_blacklist.h"
+#undef BL_DENTRY
+#undef BL_SENTRY
+
+static void
+dtrace_fbt_populate_bl(void)
+{
+#define	BL_SENTRY(tp, nm)	dtrace_fbt_bl_add((unsigned long)&nm, \
+						  __stringify(nm));
+#define BL_DENTRY(tp, nm)	dtrace_fbt_bl_add(0, __stringify(nm));
+#include "fbt_blacklist.h"
+#undef BL_SENTRY
+#undef BL_DENTRY
+}
+
+void dtrace_fbt_init(fbt_add_probe_fn fbt_add_probe, struct module *mp,
+		     void *arg)
+{
+	loff_t			pos;
+	struct kallsym_iter	sym;
+	asm_instr_t		*paddr = NULL;
+	struct dt_fbt_bl_entry	*blent = NULL;
+
+	/*
+	 * Look up any unresolved symbols in the blacklist, and sort the list
+	 * by ascending address.
+	 */
+	dtrace_fbt_populate_bl();
+	blent = dtrace_fbt_bl_first();
+
+	pos = 0;
+	kallsyms_iter_reset(&sym, 0);
+	while (kallsyms_iter_update(&sym, pos++)) {
+		asm_instr_t	*addr, *end;
+		int		state = 0, insc = 0;
+		void		*fbtp = NULL;
+
+		/*
+		 * There is no point considering non-function symbols for FBT,
+		 * or symbols that have a zero size.  We could consider weak
+		 * symbols but that gets quite complicated and there is no
+		 * demands for that (so far).
+		 */
+		if (sym.type != 'T' && sym.type != 't')
+			continue;
+		if (!sym.size)
+			continue;
+
+		/*
+		 * Handle only symbols that belong to the module we have been
+		 * asked for.
+		 */
+		if (mp == dtrace_kmod && !core_kernel_text(sym.value))
+			continue;
+
+		/*
+		 * Ensure we have not been given .init symbol from kallsyms
+		 * interface. This could lead to memory corruption once DTrace
+		 * tries to enable probe in already freed memory.
+		 */
+		if (mp != dtrace_kmod && !within_module_core(sym.value, mp))
+			continue;
+
+		/*
+		 * See if the symbol is on the FBT's blacklist.  Since both
+		 * iterators are workng in sort order by ascending address we
+		 * can use concurrent traversal.
+		 */
+		while (blent != NULL &&
+		       dtrace_fbt_bl_entry_addr(blent) < sym.value) {
+			blent = dtrace_fbt_bl_next(blent);
+		}
+		if (dtrace_fbt_bl_entry_addr(blent) == sym.value)
+			continue;
+
+		/*
+		 * No FBT tracing for DTrace functions, and functions that are
+		 * crucial to probe processing.
+		 * Also weed out symbols that are not relevant here.
+		 */
+		if (strncmp(sym.name, "dtrace_", 7) == 0)
+			continue;
+		if (strncmp(sym.name, "insn_", 5) == 0)
+			continue;
+		if (strncmp(sym.name, "inat_", 5) == 0)
+			continue;
+		if (strncmp(sym.name, "_GLOBAL_", 8) == 0)
+			continue;
+		if (strncmp(sym.name, "do_", 3) == 0)
+			continue;
+		if (strncmp(sym.name, "xen_", 4) == 0)
+			continue;
+
+		addr = (asm_instr_t *)sym.value;
+		end = (asm_instr_t *)(sym.value + sym.size);
+
+		/*
+		 * FIXME:
+		 * When there are multiple symbols for the same address, we
+		 * should link them together as probes associated with the
+		 * same function.  When a probe for that function is triggered
+		 * all associated probes should fire.
+		 *
+		 * For now, we ignore duplicates.
+		 */
+		if (addr == paddr)
+			continue;
+		paddr = addr;
+
+		while (addr < end) {
+			struct insn	insn;
+
+			insc++;
+
+			switch (state) {
+			case 0:	/* start of function */
+				if (*addr == FBT_PUSHL_EBP) {
+					fbt_add_probe(
+						mp, sym.name,
+						FBT_ENTRY, *addr, addr, 0,
+						NULL, arg);
+					state = 1;
+				} else if (insc > 10)
+					state = 2;
+				break;
+			case 1: /* look for ret */
+				if (*addr == FBT_RET) {
+					uintptr_t	off;
+
+					off = addr - (asm_instr_t *)sym.value;
+					fbtp = fbt_add_probe(
+						mp, sym.name,
+						FBT_RETURN, *addr, addr, off,
+						fbtp, arg);
+				}
+				break;
+			}
+
+			if (state == 2)
+				break;
+
+			kernel_insn_init(&insn, addr, MAX_INSN_SIZE);
+			insn_get_length(&insn);
+
+			addr += insn.length;
+		}
+	}
+}
+EXPORT_SYMBOL(dtrace_fbt_init);
diff --git a/arch/x86/kernel/fbt_blacklist.h b/arch/x86/kernel/fbt_blacklist.h
new file mode 100644
index 000000000000..2e1ce2a90c86
--- /dev/null
+++ b/arch/x86/kernel/fbt_blacklist.h
@@ -0,0 +1,95 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Functions used in die notifier chain calling.
+ */
+BL_SENTRY(void *, notify_die)
+BL_DENTRY(void *, notifier_call_chain)
+BL_SENTRY(typeof(atomic_notifier_call_chain_robust), atomic_notifier_call_chain_robust)
+BL_SENTRY(typeof(atomic_notifier_call_chain), atomic_notifier_call_chain)
+BL_SENTRY(typeof(raw_notifier_call_chain_robust), raw_notifier_call_chain_robust)
+BL_SENTRY(typeof(raw_notifier_call_chain), raw_notifier_call_chain)
+BL_DENTRY(void *, hw_breakpoint_exceptions_notify)
+BL_DENTRY(void *, kprobe_exceptions_notify)
+
+/*
+ * Functions used to update vtime in probe context.
+ */
+BL_SENTRY(typeof(ktime_get_raw_fast_ns), ktime_get_raw_fast_ns)
+BL_DENTRY(void *, raw_read_seqcount)
+BL_DENTRY(void *, read_seqcount_retry)
+BL_DENTRY(void *, __read_seqcount_retry)
+
+/* xen_clocksource */
+BL_DENTRY(void *, xen_clocksource_get_cycles)
+BL_DENTRY(void *, xen_clocksource_read)
+BL_DENTRY(void *, pvclock_clocksource_read)
+BL_DENTRY(void *, pvclock_touch_watchdogs)
+BL_DENTRY(void *, touch_softlockup_watchdog_sync)
+BL_DENTRY(void *, clocksource_touch_watchdog)
+BL_DENTRY(void *, clocksource_resume_watchdog)
+BL_DENTRY(void *, reset_hung_task_detector)
+/* clocksource_tsc */
+BL_DENTRY(void *, read_tsc)
+BL_DENTRY(void *, get_cycles)
+/* clocksource_hpet */
+BL_DENTRY(void *, read_hpet)
+BL_DENTRY(void *, hpet_readl)
+/* kvm_clock */
+BL_DENTRY(void *, kvm_clock_get_cycles)
+BL_DENTRY(void *, kvm_clock_read)
+
+/*
+ * Functions used in trap handling.
+ */
+BL_DENTRY(void *, fixup_exception)
+BL_DENTRY(void *, paranoid_entry)
+BL_DENTRY(void *, kgdb_ll_trap)
+BL_DENTRY(void *, error_entry)
+BL_DENTRY(void *, xen_int3)
+BL_DENTRY(void *, ftrace_int3_handler)
+BL_DENTRY(typeof(poke_int3_handler), poke_int3_handler)
+BL_DENTRY(void *, fixup_bad_iret)
+BL_DENTRY(void *, xen_adjust_exception_frame)
+BL_DENTRY(void *, paravirt_nop)
+BL_DENTRY(void *, ist_enter)
+BL_DENTRY(void *, rcu_nmi_enter)
+BL_DENTRY(void *, rcu_dynticks_curr_cpu_in_eqs)
+BL_DENTRY(void *, rcu_dynticks_eqs_exit)
+BL_DENTRY(void *, trace_rcu_dyntick)
+BL_DENTRY(void *, rcu_nmi_exit)
+BL_DENTRY(void *, rcu_irq_exit)
+BL_DENTRY(void *, rcu_nmi_exit_common)
+BL_DENTRY(void *, rcu_dynticks_eqs_enter)
+BL_DENTRY(void *, ist_exit)
+
+/*
+ * Functions used in page fault handling.
+ */
+BL_DENTRY(void *, do_kern_addr_fault)
+BL_DENTRY(void *, do_kern_addr_fault)
+BL_DENTRY(void *, handle_page_fault)
+BL_DENTRY(void *, huge_page_mask)
+BL_DENTRY(void *, mmap_address_hint_valid)
+BL_DENTRY(void *, vm_start_gap)
+BL_DENTRY(void *, hugetlb_get_unmapped_area_bottomup)
+BL_DENTRY(void *, hugetlb_get_unmapped_area_topdown)
+BL_DENTRY(void *, down_read_trylock)
+BL_DENTRY(void *, __get_user_pages_fast)
+BL_DENTRY(void *, gup_pud_range)
+BL_DENTRY(void *, gup_huge_pud)
+BL_DENTRY(void *, gup_pmd_range)
+BL_DENTRY(void *, gup_huge_pmd)
+BL_DENTRY(void *, gup_pte_range)
+BL_DENTRY(void *, pte_mfn_to_pfn)
+
+/*
+ * Functions used under 4.12 idr_find
+ */
+BL_DENTRY(void *, idr_find)
+BL_DENTRY(void *, find_next_bit)
+BL_DENTRY(void *, _find_next_bit)
+BL_DENTRY(void *, radix_tree_lookup)
+BL_DENTRY(void *, __radix_tree_lookup)
+BL_DENTRY(void *, radix_tree_load_root)
+BL_DENTRY(void *, radix_tree_descend)
+BL_DENTRY(void *, is_sibling_entry)
diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index c5dd50369e2f..b80211006fb2 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -260,6 +260,7 @@ DEFINE_IDTENTRY_IRQ(common_interrupt)
 	}
 
 	set_irq_regs(old_regs);
+	return 0;
 }
 
 #ifdef CONFIG_X86_LOCAL_APIC
@@ -279,6 +280,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_x86_platform_ipi)
 		x86_platform_ipi_callback();
 	trace_x86_platform_ipi_exit(X86_PLATFORM_IPI_VECTOR);
 	set_irq_regs(old_regs);
+	return 0;
 }
 #endif
 
@@ -302,6 +304,7 @@ DEFINE_IDTENTRY_SYSVEC_SIMPLE(sysvec_kvm_posted_intr_ipi)
 {
 	ack_APIC_irq();
 	inc_irq_stat(kvm_posted_intr_ipis);
+	return 0;
 }
 
 /*
@@ -312,6 +315,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_kvm_posted_intr_wakeup_ipi)
 	ack_APIC_irq();
 	inc_irq_stat(kvm_posted_intr_wakeup_ipis);
 	kvm_posted_intr_wakeup_handler();
+	return 0;
 }
 
 /*
@@ -321,6 +325,7 @@ DEFINE_IDTENTRY_SYSVEC_SIMPLE(sysvec_kvm_posted_intr_nested_ipi)
 {
 	ack_APIC_irq();
 	inc_irq_stat(kvm_posted_intr_nested_ipis);
+	return 0;
 }
 #endif
 
diff --git a/arch/x86/kernel/irq_work.c b/arch/x86/kernel/irq_work.c
index 890d4778cd35..ac74998e2faa 100644
--- a/arch/x86/kernel/irq_work.c
+++ b/arch/x86/kernel/irq_work.c
@@ -21,6 +21,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_irq_work)
 	inc_irq_stat(apic_irq_work_irqs);
 	irq_work_run();
 	trace_irq_work_exit(IRQ_WORK_VECTOR);
+	return 0;
 }
 
 void arch_irq_work_raise(void)
diff --git a/arch/x86/kernel/kvm.c b/arch/x86/kernel/kvm.c
index 7f57ede3cb8e..07ea0a6336e9 100644
--- a/arch/x86/kernel/kvm.c
+++ b/arch/x86/kernel/kvm.c
@@ -285,6 +285,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_kvm_asyncpf_interrupt)
 	}
 
 	set_irq_regs(old_regs);
+	return 0;
 }
 
 static void __init paravirt_ops_setup(void)
diff --git a/arch/x86/kernel/nmi.c b/arch/x86/kernel/nmi.c
index 4bc77aaf1303..c3c8eec1a597 100644
--- a/arch/x86/kernel/nmi.c
+++ b/arch/x86/kernel/nmi.c
@@ -484,11 +484,11 @@ DEFINE_IDTENTRY_RAW(exc_nmi)
 	sev_es_nmi_complete();
 
 	if (IS_ENABLED(CONFIG_SMP) && arch_cpu_is_offline(smp_processor_id()))
-		return;
+		return 0;
 
 	if (this_cpu_read(nmi_state) != NMI_NOT_RUNNING) {
 		this_cpu_write(nmi_state, NMI_LATCHED);
-		return;
+		return 0;
 	}
 	this_cpu_write(nmi_state, NMI_EXECUTING);
 	this_cpu_write(nmi_cr2, read_cr2());
@@ -522,6 +522,7 @@ DEFINE_IDTENTRY_RAW(exc_nmi)
 
 	if (user_mode(regs))
 		mds_user_clear_cpu_buffers();
+	return 0;
 }
 
 void stop_nmi(void)
diff --git a/arch/x86/kernel/sev-es.c b/arch/x86/kernel/sev-es.c
index 84c1821819af..536e85e4932d 100644
--- a/arch/x86/kernel/sev-es.c
+++ b/arch/x86/kernel/sev-es.c
@@ -1260,7 +1260,7 @@ DEFINE_IDTENTRY_VC_SAFE_STACK(exc_vmm_communication)
 	 */
 	if (error_code == SVM_EXIT_EXCP_BASE + X86_TRAP_DB) {
 		vc_handle_trap_db(regs);
-		return;
+		return 0;
 	}
 
 	instrumentation_begin();
@@ -1326,7 +1326,7 @@ DEFINE_IDTENTRY_VC_SAFE_STACK(exc_vmm_communication)
 out:
 	instrumentation_end();
 
-	return;
+	return 0;
 
 fail:
 	if (user_mode(regs)) {
@@ -1359,6 +1359,7 @@ DEFINE_IDTENTRY_VC_IST(exc_vmm_communication)
 	instrumentation_begin();
 	panic("Can't handle #VC exception from unsupported context\n");
 	instrumentation_end();
+	return 0;
 }
 
 DEFINE_IDTENTRY_VC(exc_vmm_communication)
@@ -1367,6 +1368,7 @@ DEFINE_IDTENTRY_VC(exc_vmm_communication)
 		safe_stack_exc_vmm_communication(regs, error_code);
 	else
 		ist_exc_vmm_communication(regs, error_code);
+	return 0;
 }
 
 bool __init handle_vc_boot_ghcb(struct pt_regs *regs)
diff --git a/arch/x86/kernel/smp.c b/arch/x86/kernel/smp.c
index eff4ce3b10da..2b3046a5b07e 100644
--- a/arch/x86/kernel/smp.c
+++ b/arch/x86/kernel/smp.c
@@ -136,6 +136,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_reboot)
 	ack_APIC_irq();
 	cpu_emergency_vmxoff();
 	stop_this_cpu(NULL);
+	return 0;
 }
 
 static int register_stop_handler(void)
@@ -229,6 +230,7 @@ DEFINE_IDTENTRY_SYSVEC_SIMPLE(sysvec_reschedule_ipi)
 	inc_irq_stat(irq_resched_count);
 	scheduler_ipi();
 	trace_reschedule_exit(RESCHEDULE_VECTOR);
+	return 0;
 }
 
 DEFINE_IDTENTRY_SYSVEC(sysvec_call_function)
@@ -238,6 +240,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_call_function)
 	inc_irq_stat(irq_call_count);
 	generic_smp_call_function_interrupt();
 	trace_call_function_exit(CALL_FUNCTION_VECTOR);
+	return 0;
 }
 
 DEFINE_IDTENTRY_SYSVEC(sysvec_call_function_single)
@@ -247,6 +250,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_call_function_single)
 	inc_irq_stat(irq_call_count);
 	generic_smp_call_function_single_interrupt();
 	trace_call_function_single_exit(CALL_FUNCTION_SINGLE_VECTOR);
+	return 0;
 }
 
 static int __init nonmi_ipi_setup(char *str)
diff --git a/arch/x86/kernel/traps.c b/arch/x86/kernel/traps.c
index 170c94ec0068..39f2ab128cc7 100644
--- a/arch/x86/kernel/traps.c
+++ b/arch/x86/kernel/traps.c
@@ -166,17 +166,20 @@ do_trap(int trapnr, int signr, char *str, struct pt_regs *regs,
 }
 NOKPROBE_SYMBOL(do_trap);
 
-static void do_error_trap(struct pt_regs *regs, long error_code, char *str,
+static int do_error_trap(struct pt_regs *regs, long error_code, char *str,
 	unsigned long trapnr, int signr, int sicode, void __user *addr)
 {
+	int ret;
+
 	RCU_LOCKDEP_WARN(!rcu_is_watching(), "entry code didn't wake RCU");
 
-	if (notify_die(DIE_TRAP, str, regs, error_code, trapnr, signr) !=
-			NOTIFY_STOP) {
+	ret = notify_die(DIE_TRAP, str, regs, error_code, trapnr, signr);
+	if ((ret & NOTIFY_STOP_MASK) != NOTIFY_STOP_MASK) {
 		cond_local_irq_enable(regs);
 		do_trap(trapnr, signr, str, regs, error_code, sicode, addr);
 		cond_local_irq_disable(regs);
 	}
+	return notifier_to_errno(ret);
 }
 
 /*
@@ -196,13 +199,14 @@ static __always_inline void __user *error_get_trap_addr(struct pt_regs *regs)
 
 DEFINE_IDTENTRY(exc_divide_error)
 {
-	do_error_trap(regs, 0, "divide error", X86_TRAP_DE, SIGFPE,
-		      FPE_INTDIV, error_get_trap_addr(regs));
+	return do_error_trap(regs, 0, "divide error", X86_TRAP_DE, SIGFPE,
+			     FPE_INTDIV, error_get_trap_addr(regs));
 }
 
 DEFINE_IDTENTRY(exc_overflow)
 {
-	do_error_trap(regs, 0, "overflow", X86_TRAP_OF, SIGSEGV, 0, NULL);
+	return do_error_trap(regs, 0, "overflow", X86_TRAP_OF, SIGSEGV,
+			     0, NULL);
 }
 
 #ifdef CONFIG_X86_F00F_BUG
@@ -253,37 +257,38 @@ DEFINE_IDTENTRY_RAW(exc_invalid_op)
 	 * in case exception entry is the one triggering WARNs.
 	 */
 	if (!user_mode(regs) && handle_bug(regs))
-		return;
+		return 0;
 
 	state = irqentry_enter(regs);
 	instrumentation_begin();
 	handle_invalid_op(regs);
 	instrumentation_end();
 	irqentry_exit(regs, state);
+	return 0;
 }
 
 DEFINE_IDTENTRY(exc_coproc_segment_overrun)
 {
-	do_error_trap(regs, 0, "coprocessor segment overrun",
-		      X86_TRAP_OLD_MF, SIGFPE, 0, NULL);
+	return do_error_trap(regs, 0, "coprocessor segment overrun",
+			     X86_TRAP_OLD_MF, SIGFPE, 0, NULL);
 }
 
 DEFINE_IDTENTRY_ERRORCODE(exc_invalid_tss)
 {
-	do_error_trap(regs, error_code, "invalid TSS", X86_TRAP_TS, SIGSEGV,
-		      0, NULL);
+	return do_error_trap(regs, error_code, "invalid TSS", X86_TRAP_TS,
+			     SIGSEGV, 0, NULL);
 }
 
 DEFINE_IDTENTRY_ERRORCODE(exc_segment_not_present)
 {
-	do_error_trap(regs, error_code, "segment not present", X86_TRAP_NP,
-		      SIGBUS, 0, NULL);
+	return do_error_trap(regs, error_code, "segment not present", X86_TRAP_NP,
+			     SIGBUS, 0, NULL);
 }
 
 DEFINE_IDTENTRY_ERRORCODE(exc_stack_segment)
 {
-	do_error_trap(regs, error_code, "stack segment", X86_TRAP_SS, SIGBUS,
-		      0, NULL);
+	return do_error_trap(regs, error_code, "stack segment", X86_TRAP_SS,
+			     SIGBUS, 0, NULL);
 }
 
 DEFINE_IDTENTRY_ERRORCODE(exc_alignment_check)
@@ -291,7 +296,7 @@ DEFINE_IDTENTRY_ERRORCODE(exc_alignment_check)
 	char *str = "alignment check";
 
 	if (notify_die(DIE_TRAP, str, regs, error_code, X86_TRAP_AC, SIGBUS) == NOTIFY_STOP)
-		return;
+		return 0;
 
 	if (!user_mode(regs))
 		die("Split lock detected\n", regs, error_code);
@@ -306,6 +311,7 @@ DEFINE_IDTENTRY_ERRORCODE(exc_alignment_check)
 
 out:
 	local_irq_disable();
+	return 0;
 }
 
 #ifdef CONFIG_VMAP_STACK
@@ -402,7 +408,7 @@ DEFINE_IDTENTRY_DF(exc_double_fault)
 		regs->ip = (unsigned long)asm_exc_general_protection;
 		regs->sp = (unsigned long)&gpregs->orig_ax;
 
-		return;
+		return 0;
 	}
 #endif
 
@@ -461,13 +467,14 @@ DEFINE_IDTENTRY_DF(exc_double_fault)
 	die("double fault", regs, error_code);
 	panic("Machine halted.");
 	instrumentation_end();
+	return 0;
 }
 
 DEFINE_IDTENTRY(exc_bounds)
 {
 	if (notify_die(DIE_TRAP, "bounds", regs, 0,
 			X86_TRAP_BR, SIGSEGV) == NOTIFY_STOP)
-		return;
+		return 0;
 	cond_local_irq_enable(regs);
 
 	if (!user_mode(regs))
@@ -476,6 +483,7 @@ DEFINE_IDTENTRY(exc_bounds)
 	do_trap(X86_TRAP_BR, SIGSEGV, "bounds", regs, 0, 0, NULL);
 
 	cond_local_irq_disable(regs);
+	return 0;
 }
 
 enum kernel_gp_hint {
@@ -529,7 +537,7 @@ DEFINE_IDTENTRY_ERRORCODE(exc_general_protection)
 	enum kernel_gp_hint hint = GP_NO_HINT;
 	struct task_struct *tsk;
 	unsigned long gp_addr;
-	int ret;
+	int ret = 0;
 
 	cond_local_irq_enable(regs);
 
@@ -542,7 +550,7 @@ DEFINE_IDTENTRY_ERRORCODE(exc_general_protection)
 		local_irq_enable();
 		handle_vm86_fault((struct kernel_vm86_regs *) regs, error_code);
 		local_irq_disable();
-		return;
+		return 0;
 	}
 
 	tsk = current;
@@ -572,8 +580,10 @@ DEFINE_IDTENTRY_ERRORCODE(exc_general_protection)
 		goto exit;
 
 	ret = notify_die(DIE_GPF, desc, regs, error_code, X86_TRAP_GP, SIGSEGV);
-	if (ret == NOTIFY_STOP)
+	if ((ret & NOTIFY_STOP_MASK) == NOTIFY_STOP_MASK) {
+		ret = notifier_to_errno(ret);
 		goto exit;
+	}
 
 	if (error_code)
 		snprintf(desc, sizeof(desc), "segment-related " GPFSTR);
@@ -597,9 +607,10 @@ DEFINE_IDTENTRY_ERRORCODE(exc_general_protection)
 
 exit:
 	cond_local_irq_disable(regs);
+	return ret;
 }
 
-static bool do_int3(struct pt_regs *regs)
+static bool do_int3(struct pt_regs *regs, int *error_code)
 {
 	int res;
 
@@ -615,28 +626,37 @@ static bool do_int3(struct pt_regs *regs)
 #endif
 	res = notify_die(DIE_INT3, "int3", regs, 0, X86_TRAP_BP, SIGTRAP);
 
-	return res == NOTIFY_STOP;
+	if ((res & NOTIFY_STOP_MASK) == NOTIFY_STOP_MASK) {
+		*error_code = notifier_to_errno (res);
+		return true;
+	}
+
+	return false;
 }
 
-static void do_int3_user(struct pt_regs *regs)
+static int do_int3_user(struct pt_regs *regs)
 {
-	if (do_int3(regs))
-		return;
+	int ret = 0;
+	if (do_int3(regs, &ret))
+		return ret;
 
 	cond_local_irq_enable(regs);
 	do_trap(X86_TRAP_BP, SIGTRAP, "int3", regs, 0, 0, NULL);
 	cond_local_irq_disable(regs);
+	return 0;
 }
 
 DEFINE_IDTENTRY_RAW(exc_int3)
 {
+	int ret = 0;
+
 	/*
 	 * poke_int3_handler() is completely self contained code; it does (and
 	 * must) *NOT* call out to anything, lest it hits upon yet another
 	 * INT3.
 	 */
 	if (poke_int3_handler(regs))
-		return;
+		return 0;
 
 	/*
 	 * irqentry_enter_from_user_mode() uses static_branch_{,un}likely()
@@ -648,17 +668,18 @@ DEFINE_IDTENTRY_RAW(exc_int3)
 	if (user_mode(regs)) {
 		irqentry_enter_from_user_mode(regs);
 		instrumentation_begin();
-		do_int3_user(regs);
+		ret = do_int3_user(regs);
 		instrumentation_end();
 		irqentry_exit_to_user_mode(regs);
 	} else {
 		bool irq_state = idtentry_enter_nmi(regs);
 		instrumentation_begin();
-		if (!do_int3(regs))
+		if (!do_int3(regs, &ret))
 			die("int3", regs, 0);
 		instrumentation_end();
 		idtentry_exit_nmi(regs, irq_state);
 	}
+	return ret;
 }
 
 #ifdef CONFIG_X86_64
@@ -988,12 +1009,14 @@ static __always_inline void exc_debug_user(struct pt_regs *regs,
 DEFINE_IDTENTRY_DEBUG(exc_debug)
 {
 	exc_debug_kernel(regs, debug_read_clear_dr6());
+	return 0;
 }
 
 /* User entry, runs on regular task stack */
 DEFINE_IDTENTRY_DEBUG_USER(exc_debug)
 {
 	exc_debug_user(regs, debug_read_clear_dr6());
+	return 0;
 }
 #else
 /* 32 bit does not have separate entry points. */
@@ -1005,6 +1028,7 @@ DEFINE_IDTENTRY_RAW(exc_debug)
 		exc_debug_user(regs, dr6);
 	else
 		exc_debug_kernel(regs, dr6);
+	return 0;
 }
 #endif
 
@@ -1058,6 +1082,7 @@ static void math_error(struct pt_regs *regs, int trapnr)
 DEFINE_IDTENTRY(exc_coprocessor_error)
 {
 	math_error(regs, X86_TRAP_MF);
+	return 0;
 }
 
 DEFINE_IDTENTRY(exc_simd_coprocessor_error)
@@ -1066,10 +1091,11 @@ DEFINE_IDTENTRY(exc_simd_coprocessor_error)
 		/* AMD 486 bug: INVD in CPL 0 raises #XF instead of #GP */
 		if (!static_cpu_has(X86_FEATURE_XMM)) {
 			__exc_general_protection(regs, 0);
-			return;
+			return 0;
 		}
 	}
 	math_error(regs, X86_TRAP_XF);
+	return 0;
 }
 
 DEFINE_IDTENTRY(exc_spurious_interrupt_bug)
@@ -1093,6 +1119,7 @@ DEFINE_IDTENTRY(exc_spurious_interrupt_bug)
 	 * In theory this could be limited to 32bit, but the handler is not
 	 * hurting and who knows which other CPUs suffer from this.
 	 */
+	return 0;
 }
 
 DEFINE_IDTENTRY(exc_device_not_available)
@@ -1109,7 +1136,7 @@ DEFINE_IDTENTRY(exc_device_not_available)
 		math_emulate(&info);
 
 		cond_local_irq_disable(regs);
-		return;
+		return 0;
 	}
 #endif
 
@@ -1125,6 +1152,7 @@ DEFINE_IDTENTRY(exc_device_not_available)
 		 */
 		die("unexpected #NM exception", regs, 0);
 	}
+	return 0;
 }
 
 #ifdef CONFIG_X86_32
@@ -1137,6 +1165,7 @@ DEFINE_IDTENTRY_SW(iret_error)
 			ILL_BADSTK, (void __user *)NULL);
 	}
 	local_irq_disable();
+	return 0;
 }
 #endif
 
diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
index 5b16183100d0..d5b9734946c3 100644
--- a/arch/x86/mm/fault.c
+++ b/arch/x86/mm/fault.c
@@ -1493,7 +1493,7 @@ DEFINE_IDTENTRY_RAW_ERRORCODE(exc_page_fault)
 	 * itself.
 	 */
 	if (kvm_handle_async_pf(regs, (u32)address))
-		return;
+		return 0;
 
 	/*
 	 * Entry handling for valid #PF from kernel mode is slightly
@@ -1512,4 +1512,5 @@ DEFINE_IDTENTRY_RAW_ERRORCODE(exc_page_fault)
 	instrumentation_end();
 
 	irqentry_exit(regs, state);
+	return 0;
 }
diff --git a/arch/x86/xen/enlighten_hvm.c b/arch/x86/xen/enlighten_hvm.c
index ec50b7423a4c..1c4b08f2dc3b 100644
--- a/arch/x86/xen/enlighten_hvm.c
+++ b/arch/x86/xen/enlighten_hvm.c
@@ -129,6 +129,7 @@ DEFINE_IDTENTRY_SYSVEC(sysvec_xen_hvm_callback)
 	xen_hvm_evtchn_do_upcall();
 
 	set_irq_regs(old_regs);
+	return 0;
 }
 
 #ifdef CONFIG_KEXEC_CORE
diff --git a/arch/x86/xen/enlighten_pv.c b/arch/x86/xen/enlighten_pv.c
index 4409306364dc..080702bf757b 100644
--- a/arch/x86/xen/enlighten_pv.c
+++ b/arch/x86/xen/enlighten_pv.c
@@ -563,12 +563,12 @@ static void xen_write_ldt_entry(struct desc_struct *dt, int entrynum,
 	preempt_enable();
 }
 
-void noist_exc_debug(struct pt_regs *regs);
+int noist_exc_debug(struct pt_regs *regs);
 
 DEFINE_IDTENTRY_RAW(xenpv_exc_nmi)
 {
 	/* On Xen PV, NMI doesn't use IST.  The C part is the sane as native. */
-	exc_nmi(regs);
+	return exc_nmi(regs);
 }
 
 DEFINE_IDTENTRY_RAW(xenpv_exc_debug)
@@ -578,9 +578,9 @@ DEFINE_IDTENTRY_RAW(xenpv_exc_debug)
 	 * to the correct handler.
 	 */
 	if (user_mode(regs))
-		noist_exc_debug(regs);
+		return noist_exc_debug(regs);
 	else
-		exc_debug(regs);
+		return exc_debug(regs);
 }
 
 struct trap_array_entry {
diff --git a/include/linux/dtrace_fbt.h b/include/linux/dtrace_fbt.h
new file mode 100644
index 000000000000..d11e273cee31
--- /dev/null
+++ b/include/linux/dtrace_fbt.h
@@ -0,0 +1,48 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ *Copyright (c) 2015, 2017, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_FBT_H
+#define _LINUX_DTRACE_FBT_H
+
+#include <linux/module.h>
+#include <asm/dtrace_arch.h>
+
+extern unsigned long dtrace_fbt_nfuncs __attribute__((weak));
+
+/*
+ * Prototype for callback function that handles the actual creation of FBT
+ * probes.
+ *
+ * Arguments to pass:
+ *	- Pointer to module the probe will belong to
+ *	- function name
+ *	- probe type (FBT_ENTRY or FBT_RETURN)
+ *	- probe subtype (arch-specific)
+ *	- address (location of the probe)
+ *	- offset from the function start
+ *	- return value from previous callback invocation
+ *	- cookie passed to dtrace_fbt_init
+ * Returns:
+ *	- generic pointer (only to be used to pass back in)
+ */
+#define FBT_ENTRY	0
+#define FBT_RETURN	1
+
+typedef void *(*fbt_add_probe_fn)(struct module *, char *, int, int,
+				  asm_instr_t *, uintptr_t, void *, void *);
+extern void dtrace_fbt_init(fbt_add_probe_fn, struct module *, void *);
+
+/*
+ * Dynamic blacklist routines.
+ */
+struct dt_fbt_bl_entry;
+
+extern struct dt_fbt_bl_entry *dtrace_fbt_bl_add(unsigned long, const char *);
+extern struct dt_fbt_bl_entry *dtrace_fbt_bl_first(void);
+extern struct dt_fbt_bl_entry *dtrace_fbt_bl_next(struct dt_fbt_bl_entry *);
+extern unsigned long dtrace_fbt_bl_entry_addr(struct dt_fbt_bl_entry *);
+extern const char *dtrace_fbt_bl_entry_name(struct dt_fbt_bl_entry *);
+
+#endif /* _LINUX_DTRACE_FBT_H */
diff --git a/kernel/dtrace/Kconfig b/kernel/dtrace/Kconfig
index 6bf6620981cd..1f070e49c69f 100644
--- a/kernel/dtrace/Kconfig
+++ b/kernel/dtrace/Kconfig
@@ -55,6 +55,13 @@ config DT_SDT_PERF
 	  Provides the perf provider, containing a DTrace probe for each
 	  perf-events tracepoint in the system.
 
+config DT_FBT
+	tristate "Function boundary tracing"
+	default m
+	select FTRACE
+	help
+	  Provides function boundary tracing for functions in the kernel.
+
 config DT_SYSTRACE
 	tristate "System Call Tracing"
 	default m
diff --git a/kernel/dtrace/Makefile b/kernel/dtrace/Makefile
index 06329cbe52cb..0e5fb34b7b47 100644
--- a/kernel/dtrace/Makefile
+++ b/kernel/dtrace/Makefile
@@ -4,11 +4,11 @@
 
 DT_CORE_ARCH_OBJS		= $(addprefix ../../arch/$(SRCARCH)/kernel/, \
 				    dtrace_syscall.o dtrace_syscall_stubs.o \
-				    dtrace_sdt.o dtrace_util.o)
+				    dtrace_fbt.o dtrace_sdt.o dtrace_util.o)
 
 ifdef CONFIG_DT_CORE
 obj-y				+= cyclic.o dtrace_os.o dtrace_cpu.o \
-				   dtrace_sdt_core.o \
+				   dtrace_sdt_core.o dtrace_fbt_core.o \
 				   dtrace_task.o dtrace_psinfo.o \
 				   $(DT_CORE_ARCH_OBJS)
 endif
diff --git a/kernel/dtrace/dtrace_fbt_core.c b/kernel/dtrace/dtrace_fbt_core.c
new file mode 100644
index 000000000000..67182a3b13fc
--- /dev/null
+++ b/kernel/dtrace/dtrace_fbt_core.c
@@ -0,0 +1,125 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:        dtrace_fbt_core.c
+ * DESCRIPTION: DTrace - FBT common code
+ *
+ * Copyright (c) 2017, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/kernel.h>
+#include <linux/kallsyms.h>
+#include <linux/rbtree.h>
+#include <linux/slab.h>
+#include <linux/dtrace_fbt.h>
+
+struct dt_fbt_bl_entry {
+	struct rb_node		dfbe_node;
+	unsigned long		dfbe_addr;
+	const char		*dfbe_name;
+};
+
+static struct rb_root dt_fbt_root = RB_ROOT;
+
+struct dt_fbt_bl_entry *
+dtrace_fbt_bl_add(unsigned long addr, const char *name)
+{
+	struct rb_node **p = &dt_fbt_root.rb_node;
+	struct rb_node *parent = NULL;
+	struct dt_fbt_bl_entry *entry;
+
+	/*
+	 * If no address was given, we need to do a symbol name lookup:
+	 *  - If no symbol name was given, we cannot add anything.
+	 *  - If the lookup failed, we cannot add anything.
+	 */
+	if (addr == 0) {
+		if (name == NULL)
+			return NULL;
+
+		addr = kallsyms_lookup_name(name);
+
+		if (addr == 0)
+			return NULL;
+	}
+
+	/* Find place in the tree. */
+	while (*p) {
+		parent = *p;
+		entry = rb_entry(parent, struct dt_fbt_bl_entry, dfbe_node);
+
+		if (addr > entry->dfbe_addr)
+			p = &parent->rb_right;
+		else if (addr < entry->dfbe_addr)
+			p = &parent->rb_left;
+		else
+			return NULL;		/* no duplicates please */
+	}
+
+	/* Create a new blacklist entry. */
+	entry = kmalloc(sizeof(*entry), GFP_KERNEL);
+	if (entry == NULL)
+		return NULL;
+
+	entry->dfbe_name = name;
+	entry->dfbe_addr = addr;
+
+	/* Update the tree. */
+	rb_link_node(&entry->dfbe_node, parent, p);
+	rb_insert_color(&entry->dfbe_node, &dt_fbt_root);
+
+	return entry;
+}
+
+/*
+ * Iterators for blacklisted symbols. The iteration happens in sort order by
+ * virtual memory address. Symbols with pending resolution are inored.
+ */
+struct dt_fbt_bl_entry *
+dtrace_fbt_bl_first(void)
+{
+	struct rb_node *node = rb_first(&dt_fbt_root);
+
+	if (node == NULL)
+		return (NULL);
+
+	return rb_entry(node, struct dt_fbt_bl_entry, dfbe_node);
+}
+
+struct dt_fbt_bl_entry *
+dtrace_fbt_bl_next(struct dt_fbt_bl_entry *entry)
+{
+	struct rb_node *node = rb_next(&entry->dfbe_node);
+
+	if (node == NULL)
+		return (NULL);
+
+	return rb_entry(node, struct dt_fbt_bl_entry, dfbe_node);
+}
+
+unsigned long
+dtrace_fbt_bl_entry_addr(struct dt_fbt_bl_entry *entry)
+{
+	if (entry == NULL)
+		return (0);
+
+	return entry->dfbe_addr;
+}
+
+const char *
+dtrace_fbt_bl_entry_name(struct dt_fbt_bl_entry *entry)
+{
+	if (entry == NULL)
+		return (NULL);
+
+	return entry->dfbe_name;
+}
diff --git a/kernel/dtrace/dtrace_os.c b/kernel/dtrace/dtrace_os.c
index 874e097b84fd..bb5650cf72eb 100644
--- a/kernel/dtrace/dtrace_os.c
+++ b/kernel/dtrace/dtrace_os.c
@@ -18,6 +18,7 @@
 
 #include <linux/binfmts.h>
 #include <linux/dtrace_cpu.h>
+#include <linux/dtrace_fbt.h>
 #include <linux/dtrace_os.h>
 #include <linux/dtrace_sdt.h>
 #include <linux/fs.h>
@@ -103,6 +104,7 @@ void __init dtrace_os_init(void)
 	dtrace_kmod->core_layout.size = 0x2000000;
 #endif
 
+	dtrace_kmod->num_ftrace_callsites = dtrace_fbt_nfuncs;
 	dtrace_kmod->state = MODULE_STATE_LIVE;
 	atomic_inc(&dtrace_kmod->refcnt);
 
diff --git a/kernel/kprobes.c b/kernel/kprobes.c
index 41fdbb7953c6..b702c7c484e7 100644
--- a/kernel/kprobes.c
+++ b/kernel/kprobes.c
@@ -38,6 +38,10 @@
 #include <linux/perf_event.h>
 #include <linux/static_call.h>
 
+#ifdef CONFIG_DTRACE
+#include <linux/dtrace_fbt.h>
+#endif
+
 #include <asm/sections.h>
 #include <asm/cacheflush.h>
 #include <asm/errno.h>
@@ -2336,6 +2340,10 @@ int kprobe_add_ksym_blacklist(unsigned long entry)
 	    !kallsyms_lookup_size_offset(entry, &size, &offset))
 		return -EINVAL;
 
+#ifdef CONFIG_DTRACE
+	dtrace_fbt_bl_add(entry, NULL);
+#endif
+
 	ent = kmalloc(sizeof(*ent), GFP_KERNEL);
 	if (!ent)
 		return -ENOMEM;
-- 
2.30.0

