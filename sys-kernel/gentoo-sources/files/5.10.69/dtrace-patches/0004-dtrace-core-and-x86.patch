From e5a505793c0b487c875a7368404d86eca62840df Mon Sep 17 00:00:00 2001
From: Kris Van Hees <kris.van.hees@oracle.com>
Date: Mon, 19 Nov 2018 22:21:36 +0000
Subject: [PATCH 04/20] dtrace: core and x86

This implements DTrace's core kernel (linked-in) components,
including platform-dependent portions for x86.  (Most of this
machinery is not used until the next commit.)

Signed-off-by: Nick Alcock <nick.alcock@oracle.com>
Signed-off-by: Kris Van Hees <kris.van.hees@oracle.com>
Signed-off-by: Tomas Jedlicka <tomas.jedlicka@oracle.com>
Signed-off-by: Eugene Loh <eugene.loh@oracle.com>
Signed-off-by: David Mc Lean <david.mclean@oracle.com>
Signed-off-by: Vincent Lim <vincent.lim@oracle.com>
---
 Makefile                                      |    7 +-
 arch/x86/Kconfig                              |    3 +
 arch/x86/include/asm/dtrace_arch.h            |   28 +
 arch/x86/include/asm/dtrace_cpuinfo.h         |   14 +
 arch/x86/include/asm/dtrace_util.h            |   16 +
 arch/x86/kernel/dtrace_util.c                 |  244 ++++
 arch/x86/mm/fault.c                           |   28 +-
 fs/exec.c                                     |    5 +
 include/asm-generic/qrwlock.h                 |   24 +
 include/dtrace/dtrace_impl.h                  | 1236 +++++++++++++++++
 include/dtrace/dtrace_impl_defines.h          |  173 +++
 include/dtrace/provider.h                     |  971 +++++++++++++
 include/dtrace/provider_defines.h             |   41 +
 include/dtrace/types.h                        |  131 ++
 include/linux/cpuhotplug.h                    |    1 +
 include/linux/cyclic.h                        |   49 +
 include/linux/dtrace/cpu_defines.h            |   61 +
 include/linux/dtrace_cpu.h                    |   53 +
 include/linux/dtrace_cpu_defines.h            |    2 +
 include/linux/dtrace_os.h                     |  120 ++
 include/linux/dtrace_psinfo.h                 |   59 +
 include/linux/dtrace_task.h                   |   38 +
 include/linux/dtrace_task_impl.h              |   28 +
 include/linux/dtrace_types.h                  |   13 +
 include/linux/ktime.h                         |    8 +
 include/linux/module.h                        |    3 +
 include/linux/mutex.h                         |   16 +
 include/linux/rwlock.h                        |    7 +
 include/linux/sched.h                         |    4 +
 include/linux/spinlock_up.h                   |    5 +
 include/uapi/linux/dtrace/Kbuild              |   35 +
 include/uapi/linux/dtrace/actions.h           |   14 +
 include/uapi/linux/dtrace/actions_defines.h   |  181 +++
 include/uapi/linux/dtrace/arg.h               |   42 +
 include/uapi/linux/dtrace/arg_defines.h       |   21 +
 include/uapi/linux/dtrace/buffer.h            |   43 +
 include/uapi/linux/dtrace/buffer_defines.h    |   21 +
 include/uapi/linux/dtrace/conf.h              |   35 +
 include/uapi/linux/dtrace/conf_defines.h      |   21 +
 include/uapi/linux/dtrace/cpu_defines.h       |   17 +
 include/uapi/linux/dtrace/dif.h               |   60 +
 include/uapi/linux/dtrace/dif_defines.h       |  288 ++++
 include/uapi/linux/dtrace/difo.h              |   57 +
 include/uapi/linux/dtrace/difo_defines.h      |   21 +
 include/uapi/linux/dtrace/dof.h               |  196 +++
 include/uapi/linux/dtrace/dof_defines.h       |  192 +++
 include/uapi/linux/dtrace/dtrace.h            |   33 +
 include/uapi/linux/dtrace/enabling.h          |   76 +
 include/uapi/linux/dtrace/enabling_defines.h  |   25 +
 include/uapi/linux/dtrace/fasttrap.h          |   56 +
 include/uapi/linux/dtrace/fasttrap_defines.h  |   25 +
 include/uapi/linux/dtrace/fasttrap_ioctl.h    |   19 +
 include/uapi/linux/dtrace/faults.h            |   20 +
 include/uapi/linux/dtrace/faults_defines.h    |   39 +
 include/uapi/linux/dtrace/helpers.h           |  101 ++
 include/uapi/linux/dtrace/helpers_defines.h   |   21 +
 include/uapi/linux/dtrace/ioctl.h             |   47 +
 include/uapi/linux/dtrace/metadesc.h          |   81 ++
 include/uapi/linux/dtrace/metadesc_defines.h  |   24 +
 include/uapi/linux/dtrace/options.h           |   20 +
 include/uapi/linux/dtrace/options_defines.h   |   72 +
 include/uapi/linux/dtrace/stability.h         |   52 +
 include/uapi/linux/dtrace/stability_defines.h |   53 +
 include/uapi/linux/dtrace/status.h            |   50 +
 include/uapi/linux/dtrace/universal.h         |   47 +
 init/Kconfig                                  |    2 +
 init/main.c                                   |   10 +
 kernel/Makefile                               |    1 +
 kernel/dtrace/Kconfig                         |   54 +
 kernel/dtrace/Makefile                        |   12 +
 kernel/dtrace/cyclic.c                        |  526 +++++++
 kernel/dtrace/dtrace_cpu.c                    |   61 +
 kernel/dtrace/dtrace_os.c                     |  332 +++++
 kernel/dtrace/dtrace_psinfo.c                 |  212 +++
 kernel/dtrace/dtrace_task.c                   |  237 ++++
 kernel/exit.c                                 |    4 +
 kernel/fork.c                                 |   23 +
 kernel/module.c                               |   14 +
 kernel/sched/core.c                           |   10 +
 kernel/sched/sched.h                          |    5 +
 kernel/time/timekeeping.c                     |    2 +
 scripts/coccinelle/dtrace/enum-elision.cocci  |   29 +
 .../coccinelle/dtrace/typedef-elision.cocci   |   83 ++
 scripts/package/mkspec                        |    1 +
 84 files changed, 7107 insertions(+), 4 deletions(-)
 create mode 100644 arch/x86/include/asm/dtrace_arch.h
 create mode 100644 arch/x86/include/asm/dtrace_cpuinfo.h
 create mode 100644 arch/x86/include/asm/dtrace_util.h
 create mode 100644 arch/x86/kernel/dtrace_util.c
 create mode 100644 include/dtrace/dtrace_impl.h
 create mode 100644 include/dtrace/dtrace_impl_defines.h
 create mode 100644 include/dtrace/provider.h
 create mode 100644 include/dtrace/provider_defines.h
 create mode 100644 include/dtrace/types.h
 create mode 100644 include/linux/cyclic.h
 create mode 100644 include/linux/dtrace/cpu_defines.h
 create mode 100644 include/linux/dtrace_cpu.h
 create mode 100644 include/linux/dtrace_cpu_defines.h
 create mode 100644 include/linux/dtrace_os.h
 create mode 100644 include/linux/dtrace_psinfo.h
 create mode 100644 include/linux/dtrace_task.h
 create mode 100644 include/linux/dtrace_task_impl.h
 create mode 100644 include/linux/dtrace_types.h
 create mode 100644 include/uapi/linux/dtrace/Kbuild
 create mode 100644 include/uapi/linux/dtrace/actions.h
 create mode 100644 include/uapi/linux/dtrace/actions_defines.h
 create mode 100644 include/uapi/linux/dtrace/arg.h
 create mode 100644 include/uapi/linux/dtrace/arg_defines.h
 create mode 100644 include/uapi/linux/dtrace/buffer.h
 create mode 100644 include/uapi/linux/dtrace/buffer_defines.h
 create mode 100644 include/uapi/linux/dtrace/conf.h
 create mode 100644 include/uapi/linux/dtrace/conf_defines.h
 create mode 100644 include/uapi/linux/dtrace/cpu_defines.h
 create mode 100644 include/uapi/linux/dtrace/dif.h
 create mode 100644 include/uapi/linux/dtrace/dif_defines.h
 create mode 100644 include/uapi/linux/dtrace/difo.h
 create mode 100644 include/uapi/linux/dtrace/difo_defines.h
 create mode 100644 include/uapi/linux/dtrace/dof.h
 create mode 100644 include/uapi/linux/dtrace/dof_defines.h
 create mode 100644 include/uapi/linux/dtrace/dtrace.h
 create mode 100644 include/uapi/linux/dtrace/enabling.h
 create mode 100644 include/uapi/linux/dtrace/enabling_defines.h
 create mode 100644 include/uapi/linux/dtrace/fasttrap.h
 create mode 100644 include/uapi/linux/dtrace/fasttrap_defines.h
 create mode 100644 include/uapi/linux/dtrace/fasttrap_ioctl.h
 create mode 100644 include/uapi/linux/dtrace/faults.h
 create mode 100644 include/uapi/linux/dtrace/faults_defines.h
 create mode 100644 include/uapi/linux/dtrace/helpers.h
 create mode 100644 include/uapi/linux/dtrace/helpers_defines.h
 create mode 100644 include/uapi/linux/dtrace/ioctl.h
 create mode 100644 include/uapi/linux/dtrace/metadesc.h
 create mode 100644 include/uapi/linux/dtrace/metadesc_defines.h
 create mode 100644 include/uapi/linux/dtrace/options.h
 create mode 100644 include/uapi/linux/dtrace/options_defines.h
 create mode 100644 include/uapi/linux/dtrace/stability.h
 create mode 100644 include/uapi/linux/dtrace/stability_defines.h
 create mode 100644 include/uapi/linux/dtrace/status.h
 create mode 100644 include/uapi/linux/dtrace/universal.h
 create mode 100644 kernel/dtrace/Kconfig
 create mode 100644 kernel/dtrace/Makefile
 create mode 100644 kernel/dtrace/cyclic.c
 create mode 100644 kernel/dtrace/dtrace_cpu.c
 create mode 100644 kernel/dtrace/dtrace_os.c
 create mode 100644 kernel/dtrace/dtrace_psinfo.c
 create mode 100644 kernel/dtrace/dtrace_task.c
 create mode 100644 scripts/coccinelle/dtrace/enum-elision.cocci
 create mode 100644 scripts/coccinelle/dtrace/typedef-elision.cocci

diff --git a/Makefile b/Makefile
index 454093579f77..1d264b78dda2 100644
--- a/Makefile
+++ b/Makefile
@@ -1113,15 +1113,15 @@ core-y		+= kernel/ certs/ mm/ fs/ ipc/ security/ crypto/ block/
 
 vmlinux-dirs	:= $(patsubst %/,%,$(filter %/, \
 		     $(core-y) $(core-m) $(drivers-y) $(drivers-m) \
-		     $(libs-y) $(libs-m)))
+		     $(libs-y) $(libs-m) $(dtrace-y) $(dtrace-m)))
 
 vmlinux-alldirs	:= $(sort $(vmlinux-dirs) Documentation \
 		     $(patsubst %/,%,$(filter %/, $(core-) \
-			$(drivers-) $(libs-))))
+			$(drivers-) $(libs-) $(dtrace-))))
 
 subdir-modorder := $(addsuffix modules.order,$(filter %/, \
 			$(core-y) $(core-m) $(libs-y) $(libs-m) \
-			$(drivers-y) $(drivers-m)))
+			$(drivers-y) $(drivers-m) $(dtrace-y) $(dtrace-m)))
 
 build-dirs	:= $(vmlinux-dirs)
 clean-dirs	:= $(vmlinux-alldirs)
@@ -1136,6 +1136,7 @@ else
 KBUILD_VMLINUX_LIBS := $(patsubst %/,%/lib.a, $(libs-y))
 endif
 KBUILD_VMLINUX_OBJS += $(patsubst %/,%/built-in.a, $(drivers-y))
+KBUILD_VMLINUX_OBJS += $(patsubst %/,%/built-in.a, $(dtrace-y))
 
 export KBUILD_VMLINUX_OBJS KBUILD_VMLINUX_LIBS
 export KBUILD_LDS          := arch/$(SRCARCH)/kernel/vmlinux.lds
diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index 21f851179ff0..935f09386f18 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -373,6 +373,9 @@ config PGTABLE_LEVELS
 	default 3 if X86_PAE
 	default 2
 
+config ARCH_SUPPORTS_DTRACE
+	def_bool y if X86_64
+
 config CC_HAS_SANE_STACKPROTECTOR
 	bool
 	default $(success,$(srctree)/scripts/gcc-x86_64-has-stack-protector.sh $(CC)) if 64BIT
diff --git a/arch/x86/include/asm/dtrace_arch.h b/arch/x86/include/asm/dtrace_arch.h
new file mode 100644
index 000000000000..74e27f08a873
--- /dev/null
+++ b/arch/x86/include/asm/dtrace_arch.h
@@ -0,0 +1,28 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+/*
+ * Copyright (c) 2013, 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _X86_DTRACE_ARCH_H
+#define _X86_DTRACE_ARCH_H
+
+/* Number of arguments stored inside the mstate. */
+#define	DTRACE_MSTATE_ARGS_MAX		6
+
+typedef uint8_t		asm_instr_t;
+
+typedef int (*prov_exit_f)(void);
+
+/*
+ * Structure to hold DTrace specific information about modules (including the
+ * core kernel module).  Note that each module (and the main kernel) already
+ * has one field that relates to probing:
+ *	- pdata: pointer to a dtrace_module struct (for DTrace)
+ */
+struct dtrace_module {
+	int             enabled_cnt;
+	prov_exit_f	prov_exit;	/* Called with module_mutex held */
+};
+
+#endif /* _X86_DTRACE_ARCH_H */
diff --git a/arch/x86/include/asm/dtrace_cpuinfo.h b/arch/x86/include/asm/dtrace_cpuinfo.h
new file mode 100644
index 000000000000..47024e169ec4
--- /dev/null
+++ b/arch/x86/include/asm/dtrace_cpuinfo.h
@@ -0,0 +1,14 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+
+/* Copyright (C) 2013-2014 Oracle, Inc. */
+
+#ifndef _ASM_X86_DTRACE_CPUINFO_H_
+#define _ASM_X86_DTRACE_CPUINFO_H_
+
+#include <asm/processor.h>
+
+typedef struct cpuinfo_x86	cpuinfo_arch_t;
+
+#define dtrace_cpuinfo_chip(ci)	((ci)->phys_proc_id)
+
+#endif /* _ASM_X86_DTRACE_CPUINFO_H_ */
diff --git a/arch/x86/include/asm/dtrace_util.h b/arch/x86/include/asm/dtrace_util.h
new file mode 100644
index 000000000000..4d9843bbc95b
--- /dev/null
+++ b/arch/x86/include/asm/dtrace_util.h
@@ -0,0 +1,16 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2013, 2017, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _X86_DTRACE_UTIL_H
+#define _X86_DTRACE_UTIL_H
+
+#ifndef __ASSEMBLY__
+
+#include <asm/dtrace_arch.h>
+#include <asm/ptrace.h>
+
+#endif
+
+#endif /* _X86_DTRACE_UTIL_H */
diff --git a/arch/x86/kernel/dtrace_util.c b/arch/x86/kernel/dtrace_util.c
new file mode 100644
index 000000000000..d3d552c062f7
--- /dev/null
+++ b/arch/x86/kernel/dtrace_util.c
@@ -0,0 +1,244 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:	dtrace_util.c
+ * DESCRIPTION:	Dynamic Tracing: Architecture utility functions
+ *
+ * Copyright (c) 2010, 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#include <linux/dtrace_cpu.h>
+#include <linux/dtrace_os.h>
+#include <linux/dtrace_task_impl.h>
+#include <linux/kdebug.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/memory.h>
+#include <linux/notifier.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+#include <linux/sched/task_stack.h>
+#include <asm/insn.h>
+#include <asm/pgtable.h>
+#include <asm/ptrace.h>
+#include <asm/text-patching.h>
+#include <asm/dtrace_arch.h>
+#include <asm/dtrace_util.h>
+
+int dtrace_instr_size(const asm_instr_t *addr)
+{
+	struct insn		insn;
+
+	kernel_insn_init(&insn, addr, MAX_INSN_SIZE);
+	insn_get_length(&insn);
+
+	return insn_complete(&insn) ? insn.length : -1;
+}
+EXPORT_SYMBOL(dtrace_instr_size);
+
+/*
+ * Move the instruction pointer forward to the next instruction, effectiely
+ * skipping the current one.
+ */
+static void dtrace_skip_instruction(struct pt_regs *regs)
+{
+	int	delta;
+
+	delta = dtrace_instr_size((asm_instr_t *)regs->ip);
+	BUG_ON(delta <= 0);
+
+	regs->ip += delta;
+}
+
+void dtrace_handle_badaddr(struct pt_regs *regs)
+{
+	unsigned long	addr = read_cr2();
+
+	DTRACE_CPUFLAG_SET(CPU_DTRACE_BADADDR);
+	this_cpu_core->cpuc_dtrace_illval = addr;
+
+	dtrace_skip_instruction(regs);
+}
+
+/*
+ * Trap notification handler.
+ */
+int dtrace_die_notifier(struct notifier_block *nb, unsigned long val,
+			void *args)
+{
+	struct die_args		*dargs = args;
+
+	switch (val) {
+	case DIE_PAGE_FAULT: {
+		if (!DTRACE_CPUFLAG_ISSET(CPU_DTRACE_NOFAULT))
+			return NOTIFY_DONE;
+
+		dtrace_handle_badaddr(dargs->regs);
+
+		return NOTIFY_OK | NOTIFY_STOP_MASK;
+	}
+	case DIE_GPF: {
+		if (!DTRACE_CPUFLAG_ISSET(CPU_DTRACE_NOFAULT))
+			return NOTIFY_DONE;
+
+		dtrace_handle_badaddr(dargs->regs);
+
+		return NOTIFY_OK | NOTIFY_STOP_MASK;
+	}
+	/* fallthrough */
+	default:
+		return NOTIFY_DONE;
+	}
+}
+
+static inline int dtrace_bad_address(void *addr)
+{
+	unsigned long	dummy;
+
+	return get_kernel_nofault(dummy, (unsigned long *)addr);
+}
+
+static int dtrace_user_addr_is_exec(uintptr_t addr)
+{
+	struct mm_struct	*mm = current->mm;
+	pgd_t			*pgd;
+
+#if CONFIG_PGTABLE_LEVELS > 3
+	p4d_t			*p4d;
+#endif
+
+	pud_t			*pud;
+	pmd_t			*pmd;
+	pte_t			*pte;
+	unsigned long		flags;
+	int			ret = 0;
+
+	if (mm == NULL)
+		return 0;
+
+	addr &= PAGE_MASK;
+
+	local_irq_save(flags);
+
+	pgd = pgd_offset(mm, addr);
+	if (dtrace_bad_address(pgd))
+		goto out;
+	if (pgd_none(*pgd) || !pgd_present(*pgd))
+		goto out;
+
+#if CONFIG_PGTABLE_LEVELS > 3
+	p4d = p4d_offset(pgd, addr);
+	if (dtrace_bad_address(p4d))
+		goto out;
+	if (p4d_none(*p4d) || !p4d_present(*p4d))
+		goto out;
+
+	pud = pud_offset(p4d, addr);
+#else
+	pud = pud_offset(pgd, addr);
+#endif
+
+	if (dtrace_bad_address(pud))
+		goto out;
+	if (pud_none(*pud) || !pud_present(*pud))
+		goto out;
+	if (unlikely(pud_large(*pud))) {
+		pte = (pte_t *)pud;
+		if (dtrace_bad_address(pte))
+			goto out;
+
+		ret = pte_exec(*pte);
+		goto out;
+	}
+
+	pmd = pmd_offset(pud, addr);
+	if (dtrace_bad_address(pmd))
+		goto out;
+	if (pmd_none(*pmd))
+		goto out;
+	if (unlikely(pmd_large(*pmd) || !pmd_present(*pmd))) {
+		pte = (pte_t *)pmd;
+		if (dtrace_bad_address(pte))
+			goto out;
+
+		ret = pte_exec(*pte);
+		goto out;
+	}
+
+	pte = pte_offset_map(pmd, addr);
+	if (dtrace_bad_address(pte))
+		goto out;
+	if (pte_protnone(*pte))
+		goto out;
+	if ((pte_flags(*pte) & (_PAGE_PRESENT|_PAGE_USER|_PAGE_SPECIAL)) !=
+	    (_PAGE_PRESENT|_PAGE_USER))
+		goto out;
+
+	ret = pte_exec(*pte);
+
+out:
+	local_irq_restore(flags);
+
+	return ret;
+}
+
+void dtrace_user_stacktrace(struct stacktrace_state *st)
+{
+	struct pt_regs		*regs = current_pt_regs();
+	uint64_t		*pcs = st->pcs;
+	int			limit = st->limit;
+	unsigned long		*bos;
+	unsigned long		*sp = (unsigned long *)user_stack_pointer(regs);
+	int			ret;
+
+	if (!user_mode(regs))
+		goto out;
+
+	if (current->dt_task == NULL)
+		goto out;
+
+	bos = current->dt_task->dt_ustack;
+
+	st->depth = 1;
+	if (pcs)
+		*pcs++ = (uint64_t)instruction_pointer(regs);
+	limit--;
+
+	if (!limit)
+		goto out;
+
+	while (sp <= bos && limit) {
+		unsigned long	pc;
+
+		pagefault_disable();
+		ret = __copy_from_user_inatomic(&pc, sp, sizeof(pc));
+		pagefault_enable();
+
+		if (ret)
+			break;
+
+		if (dtrace_user_addr_is_exec(pc)) {
+			if (pcs)
+				*pcs++ = pc;
+			limit--;
+			st->depth++;
+		}
+
+		sp++;
+	}
+
+out:
+	if (pcs) {
+		while (limit--)
+			*pcs++ = 0;
+	}
+}
+
+void dtrace_mod_pdata_init(struct dtrace_module *pdata)
+{
+}
+
+void dtrace_mod_pdata_cleanup(struct dtrace_module *pdata)
+{
+}
diff --git a/arch/x86/mm/fault.c b/arch/x86/mm/fault.c
index 441c3e9b8971..264650d29d5f 100644
--- a/arch/x86/mm/fault.c
+++ b/arch/x86/mm/fault.c
@@ -18,6 +18,7 @@
 #include <linux/uaccess.h>		/* faulthandler_disabled()	*/
 #include <linux/efi.h>			/* efi_recover_from_page_fault()*/
 #include <linux/mm_types.h>
+#include <linux/dtrace_os.h>		/* dtrace_no_pf			*/
 
 #include <asm/cpufeature.h>		/* boot_cpu_has, ...		*/
 #include <asm/traps.h>			/* dotraplinkage, ...		*/
@@ -694,6 +695,16 @@ no_context(struct pt_regs *regs, unsigned long error_code,
 	    (((unsigned long)tsk->stack - 1 - address < PAGE_SIZE) ||
 	     address - ((unsigned long)tsk->stack + THREAD_SIZE) < PAGE_SIZE)) {
 		unsigned long stack = __this_cpu_ist_top_va(DF) - sizeof(void *);
+
+		/*
+		 * Allow for the possibility that we know what we are doing and
+		 * ignore this fault.  E.g. the address may come from a source
+		 * we cannot trust and it is OK if we cannot access it.
+		 */
+		if (notify_die(DIE_PAGE_FAULT, "page fault", regs, error_code,
+				14, SIGKILL) == NOTIFY_STOP)
+			return;
+
 		/*
 		 * We're likely to be running with very little stack space
 		 * left.  It's plausible that we'd hit this condition but
@@ -742,8 +753,13 @@ no_context(struct pt_regs *regs, unsigned long error_code,
 oops:
 	/*
 	 * Oops. The kernel tried to access some bad page. We'll have to
-	 * terminate things with extreme prejudice:
+	 * terminate things with extreme prejudice, unless a notifier decides
+	 * to let this one slide.
 	 */
+	if (notify_die(DIE_PAGE_FAULT, "page fault", regs, error_code, 14,
+		       SIGKILL) == NOTIFY_STOP)
+		return;
+
 	flags = oops_begin();
 
 	show_fault_oops(regs, error_code, address);
@@ -1251,10 +1267,20 @@ void do_user_addr_fault(struct pt_regs *regs,
 	tsk = current;
 	mm = tsk->mm;
 
+	/*
+	 * From here on, we know this must be a fault in userspace.
+	 */
+
 	/* kprobes don't want to hook the spurious faults: */
 	if (unlikely(kprobe_page_fault(regs, X86_TRAP_PF)))
 		return;
 
+	/*
+	 * DTrace doesn't want to either.
+	 */
+	if (unlikely(dtrace_no_pf(regs)))
+		return;
+
 	/*
 	 * Reserved bits are never expected to be set on
 	 * entries in the user portion of the page tables.
diff --git a/fs/exec.c b/fs/exec.c
index 5d4d52039105..d196ce5d296f 100644
--- a/fs/exec.c
+++ b/fs/exec.c
@@ -65,6 +65,7 @@
 #include <linux/vmalloc.h>
 #include <linux/io_uring.h>
 #include <linux/syscall_user_dispatch.h>
+#include <linux/dtrace_os.h>
 
 #include <linux/uaccess.h>
 #include <asm/mmu_context.h>
@@ -1828,6 +1829,10 @@ static int bprm_execve(struct linux_binprm *bprm,
 		goto out;
 
 	/* execve succeeded */
+
+	/* Update DTrace per-task data. */
+	dtrace_task_exec(current);
+
 	current->fs->in_exec = 0;
 	current->in_execve = 0;
 	rseq_execve(current);
diff --git a/include/asm-generic/qrwlock.h b/include/asm-generic/qrwlock.h
index 84ce841ce735..b9a2866d6ecc 100644
--- a/include/asm-generic/qrwlock.h
+++ b/include/asm-generic/qrwlock.h
@@ -30,6 +30,26 @@
 extern void queued_read_lock_slowpath(struct qrwlock *lock);
 extern void queued_write_lock_slowpath(struct qrwlock *lock);
 
+#ifdef CONFIG_DTRACE
+/**
+ * queued_peek_read_can_lock -- would read_trylock() be likely to succeed?
+ * @lock: Pointer to queue rwlock structure
+ */
+static inline int queued_peek_read_can_lock(struct qrwlock *lock)
+{
+	return !(atomic_read(&lock->cnts) & _QW_WMASK);
+}
+
+/**
+ * queued_peek_write_can_lock -- would write_trylock() be likely to succeed?
+ * @lock: Pointer to queue rwlock structure
+ */
+static inline int queued_peek_write_can_lock(struct qrwlock *lock)
+{
+	return !atomic_read(&lock->cnts);
+}
+#endif /* CONFIG_DTRACE */
+
 /**
  * queued_read_trylock - try to acquire read lock of a queue rwlock
  * @lock : Pointer to queue rwlock structure
@@ -120,6 +140,10 @@ static inline void queued_write_unlock(struct qrwlock *lock)
  * Remapping rwlock architecture specific functions to the corresponding
  * queue rwlock functions.
  */
+#ifdef CONFIG_DTRACE
+#define arch_peek_read_can_lock(l)	queued_peek_read_can_lock(l)
+#define arch_peek_write_can_lock(l)	queued_peek_write_can_lock(l)
+#endif /* CONFIG_DTRACE */
 #define arch_read_lock(l)	queued_read_lock(l)
 #define arch_write_lock(l)	queued_write_lock(l)
 #define arch_read_trylock(l)	queued_read_trylock(l)
diff --git a/include/dtrace/dtrace_impl.h b/include/dtrace/dtrace_impl.h
new file mode 100644
index 000000000000..2420103c765c
--- /dev/null
+++ b/include/dtrace/dtrace_impl.h
@@ -0,0 +1,1236 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Dynamic Tracing for Linux - Implementation
+ *
+ * Copyright (c) 2009, 2018, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_IMPL_H
+#define _LINUX_DTRACE_IMPL_H
+
+#include <linux/cyclic.h>
+#include <linux/idr.h>
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/dif.h>
+#include <linux/dtrace/difo_defines.h>
+#include <linux/dtrace/metadesc.h>
+#include <linux/dtrace/stability.h>
+#include <linux/dtrace/helpers.h>
+#include <dtrace/types.h>
+#include <dtrace/provider.h>
+#include <dtrace/dtrace_impl_defines.h>
+
+struct dtrace_provider {
+	struct dtrace_pattr dtpv_attr;
+	struct dtrace_ppriv dtpv_priv;
+	struct dtrace_pops dtpv_pops;
+	char *dtpv_name;
+	void *dtpv_arg;
+	uint_t dtpv_defunct;
+	struct dtrace_provider *dtpv_next;
+};
+
+struct dtrace_predicate {
+	struct dtrace_difo *dtp_difo;
+	dtrace_cacheid_t dtp_cacheid;
+	int dtp_refcnt;
+};
+
+struct dtrace_statvar {
+	uint64_t dtsv_data;
+	size_t dtsv_size;
+	int dtsv_refcnt;
+	struct dtrace_difv dtsv_var;
+};
+
+struct dtrace_action {
+	dtrace_actkind_t dta_kind;
+	uint16_t dta_intuple;
+	uint32_t dta_refcnt;
+	struct dtrace_difo *dta_difo;
+	struct dtrace_recdesc dta_rec;
+	struct dtrace_action *dta_prev;
+	struct dtrace_action *dta_next;
+};
+
+struct dtrace_ecb;
+
+struct dtrace_probe {
+	dtrace_id_t dtpr_id;
+	struct dtrace_ecb *dtpr_ecb;
+	struct dtrace_ecb *dtpr_ecb_last;
+	void *dtpr_arg;
+	dtrace_cacheid_t dtpr_predcache;
+	int dtpr_aframes;
+	struct dtrace_provider *dtpr_provider;
+	char *dtpr_mod;
+	char *dtpr_func;
+	char *dtpr_name;
+	struct dtrace_probe *dtpr_nextmod;
+	struct dtrace_probe *dtpr_prevmod;
+	struct dtrace_probe *dtpr_nextfunc;
+	struct dtrace_probe *dtpr_prevfunc;
+	struct dtrace_probe *dtpr_nextname;
+	struct dtrace_probe *dtpr_prevname;
+	dtrace_genid_t dtpr_gen;
+};
+
+struct dtrace_state;
+
+struct dtrace_ecb {
+	dtrace_epid_t dte_epid;
+	uint32_t dte_alignment;
+	size_t dte_needed;
+	size_t dte_size;
+	struct dtrace_predicate *dte_predicate;
+	struct dtrace_action *dte_action;
+	struct dtrace_ecb *dte_next;
+	struct dtrace_state *dte_state;
+	uint32_t dte_cond;
+	struct dtrace_probe *dte_probe;
+	struct dtrace_action *dte_action_last;
+	uint64_t dte_uarg;
+};
+
+struct dtrace_key {
+	uint64_t dttk_value;
+	uint64_t dttk_size;
+};
+
+struct dtrace_tuple {
+	uint32_t dtt_nkeys;
+	uint32_t dtt_pad;
+	struct dtrace_key dtt_key[1];
+};
+
+struct dtrace_dynvar {
+	uint64_t dtdv_hashval;
+	struct dtrace_dynvar *dtdv_next;
+	void *dtdv_data;
+	struct dtrace_tuple dtdv_tuple;
+};
+
+struct dtrace_dstate_percpu {
+	struct dtrace_dynvar *dtdsc_free;
+	struct dtrace_dynvar *dtdsc_dirty;
+	struct dtrace_dynvar *dtdsc_rinsing;
+	struct dtrace_dynvar *dtdsc_clean;
+	uint64_t dtdsc_drops;
+	uint64_t dtdsc_dirty_drops;
+	uint64_t dtdsc_rinsing_drops;
+#ifdef CONFIG_64BIT
+	uint64_t dtdsc_pad;
+#else
+	uint64_t dtdsc_pad[2];
+#endif
+};
+
+struct dtrace_dynhash {
+	struct dtrace_dynvar *dtdh_chain;
+	uintptr_t dtdh_lock;
+#ifdef CONFIG_64BIT
+	uintptr_t dtdh_pad[6];
+#else
+	uintptr_t dtdh_pad[14];
+#endif
+};
+
+struct dtrace_dstate {
+	void *dtds_base;
+	size_t dtds_size;
+	size_t dtds_hashsize;
+	size_t dtds_chunksize;
+	struct dtrace_dynhash *dtds_hash;
+	enum dtrace_dstate_state dtds_state;
+	struct dtrace_dstate_percpu *dtds_percpu;
+};
+
+struct dtrace_vstate {
+	struct dtrace_state *dtvs_state;
+	struct dtrace_statvar **dtvs_globals;
+	int dtvs_nglobals;
+	struct dtrace_difv *dtvs_tlocals;
+	int dtvs_ntlocals;
+	struct dtrace_statvar **dtvs_locals;
+	int dtvs_nlocals;
+	struct dtrace_dstate dtvs_dynvars;
+};
+
+/*
+ * DTrace Machine State
+ *
+ * In the process of processing a fired probe, DTrace needs to track and/or
+ * cache some per-CPU state associated with that particular firing.  This is
+ * state that is always discarded after the probe firing has completed, and
+ * much of it is not specific to any DTrace consumer, remaining valid across
+ * all ECBs.  This state is tracked in the dtrace_mstate structure.
+ */
+
+struct dtrace_mstate {
+	uintptr_t dtms_scratch_base;
+	uintptr_t dtms_scratch_ptr;
+	size_t dtms_scratch_size;
+	uint32_t dtms_present;
+	uint64_t dtms_arg[7];
+	dtrace_epid_t dtms_epid;
+	ktime_t dtms_timestamp;
+	int dtms_stackdepth;
+	int dtms_ustackdepth;
+	struct dtrace_probe *dtms_probe;
+	uintptr_t dtms_caller;
+	uint64_t dtms_ucaller;
+	int dtms_ipl;
+	int dtms_fltoffs;
+	uintptr_t dtms_strtok;
+	uint32_t dtms_access;
+	struct dtrace_difo *dtms_difo;
+};
+
+struct dtrace_buffer {
+	uint64_t dtb_offset;
+	uint64_t dtb_size;
+	uint32_t dtb_flags;
+	uint32_t dtb_drops;
+	caddr_t dtb_tomax;
+	caddr_t dtb_xamot;
+	uint32_t dtb_xamot_flags;
+	uint32_t dtb_xamot_drops;
+	uint64_t dtb_xamot_offset;
+	uint32_t dtb_errors;
+	uint32_t dtb_xamot_errors;
+#ifndef CONFIG_64BIT
+	uint64_t dtb_pad1;
+#endif
+};
+
+struct dtrace_speculation {
+	enum dtrace_speculation_state dtsp_state;
+	int dtsp_cleaning;
+	struct dtrace_buffer *dtsp_buffer;
+};
+
+struct dtrace_aggregation {
+	struct dtrace_action dtag_action;
+	dtrace_aggid_t dtag_id;
+	struct dtrace_ecb *dtag_ecb;
+	struct dtrace_action *dtag_first;
+	uint32_t dtag_base;
+	uint8_t dtag_hasarg;
+	uint64_t dtag_initial;
+	void (*dtag_aggregate)(uint64_t *, uint64_t, uint64_t);
+};
+
+struct dtrace_cred {
+	const struct cred *dcr_cred;
+	uint8_t dcr_destructive;
+	uint8_t dcr_visible;
+	uint16_t dcr_action;
+};
+
+struct dtrace_state {
+	dev_t dts_dev;
+	int dts_necbs;
+	struct dtrace_ecb **dts_ecbs;
+	dtrace_epid_t dts_epid;
+	size_t dts_needed;
+	struct dtrace_state *dts_anon;
+	enum dtrace_activity dts_activity;
+	struct dtrace_vstate dts_vstate;
+	struct dtrace_buffer *dts_buffer;
+	struct dtrace_buffer *dts_aggbuffer;
+	struct dtrace_speculation *dts_speculations;
+	int dts_nspeculations;
+	struct idr dts_agg_idr;
+	int dts_naggs;
+	uint64_t dts_errors;
+	uint32_t dts_speculations_busy;
+	uint32_t dts_speculations_unavail;
+	uint32_t dts_stkstroverflows;
+	uint32_t dts_dblerrors;
+	uint32_t dts_reserve;
+	cyclic_id_t dts_cleaner;
+	cyclic_id_t dts_deadman;
+	ktime_t dts_laststatus;
+	ktime_t dts_alive;
+	char dts_speculates;
+	char dts_destructive;
+	int dts_nformats;
+	char **dts_formats;
+	dtrace_optval_t dts_options[DTRACEOPT_MAX];
+	struct dtrace_cred dts_cred;
+	size_t dts_nretained;
+};
+
+struct dtrace_enabling {
+	struct dtrace_ecbdesc **dten_desc;
+	int dten_ndesc;
+	int dten_maxdesc;
+	struct dtrace_vstate *dten_vstate;
+	dtrace_genid_t dten_probegen;
+	struct dtrace_ecbdesc *dten_current;
+	int dten_error;
+	int dten_primed;
+	struct dtrace_enabling *dten_prev;
+	struct dtrace_enabling *dten_next;
+};
+
+typedef int dtrace_probekey_f(const char *, const char *, int);
+
+struct dtrace_probekey {
+	const char *dtpk_prov;
+	dtrace_probekey_f *dtpk_pmatch;
+	const char *dtpk_mod;
+	dtrace_probekey_f *dtpk_mmatch;
+	const char *dtpk_func;
+	dtrace_probekey_f *dtpk_fmatch;
+	const char *dtpk_name;
+	dtrace_probekey_f *dtpk_nmatch;
+	dtrace_id_t dtpk_id;
+};
+
+struct dtrace_hashbucket {
+	struct dtrace_hashbucket *dthb_next;
+	struct dtrace_probe *dthb_chain;
+	int dthb_len;
+};
+
+struct dtrace_hash {
+	struct dtrace_hashbucket **dth_tab;
+	int dth_size;
+	int dth_mask;
+	int dth_nbuckets;
+	uintptr_t dth_nextoffs;
+	uintptr_t dth_prevoffs;
+	uintptr_t dth_stroffs;
+};
+
+/*
+ * DTrace supports safe loads from probe context; if the address turns out to
+ * be invalid, a bit will be set by the kernel indicating that DTrace
+ * encountered a memory error, and DTrace will propagate the error to the user
+ * accordingly.  However, there may exist some regions of memory in which an
+ * arbitrary load can change system state, and from which it is impossible to
+ * recover from such a load after it has been attempted.  Examples of this may
+ * include memory in which programmable I/O registers are mapped (for which a
+ * read may have some implications for the device) or (in the specific case of
+ * UltraSPARC-I and -II) the virtual address hole.  The platform is required
+ * to make DTrace aware of these toxic ranges; DTrace will then check that
+ * target addresses are not in a toxic range before attempting to issue a
+ * safe load.
+ */
+struct dtrace_toxrange {
+	uintptr_t dtt_base;
+	uintptr_t dtt_limit;
+};
+
+/*
+ * DTrace Helper Implementation
+ *
+ * A description of the helper architecture may be found in <linux/dtrace.h>.
+ * Each process contains a pointer to its helpers in its dtrace_helpers
+ * member.  This is a pointer to a dtrace_helpers structure, which contains an
+ * array of pointers to dtrace_helper structures, helper variable state (shared
+ * among a process's helpers) and a generation count.  (The generation count is
+ * used to provide an identifier when a helper is added so that it may be
+ * subsequently removed.)  The dtrace_helper structure is self-explanatory,
+ * containing pointers to the objects needed to execute the helper.  Note that
+ * helpers are _duplicated_ across fork(2), and destroyed on exec(2).  No more
+ * than dtrace_helpers_max are allowed per-process.
+ */
+struct dtrace_helper_action {
+	int dtha_generation;			/* helper action generation */
+	int dtha_nactions;			/* number of actions */
+	struct dtrace_difo *dtha_predicate;	/* helper action predicate */
+	struct dtrace_difo **dtha_actions;	/* array of actions */
+	struct dtrace_helper_action *dtha_next;	/* next helper action */
+};
+
+struct dtrace_helper_provider {
+	int dthp_generation;			/* helper provider generation */
+	uint32_t dthp_ref;			/* reference count */
+	struct dof_helper dthp_prov;		/* DOF w/ provider and probes */
+};
+
+struct dtrace_helpers {
+	struct dtrace_helper_action **dthps_actions; /* helper actions array */
+	struct dtrace_vstate dthps_vstate;	/* helper action var. state */
+	struct dtrace_helper_provider **dthps_provs; /* providers array */
+	uint_t dthps_nprovs;			/* count of providers */
+	uint_t dthps_maxprovs;			/* provider array size */
+	int dthps_generation;			/* current generation */
+	pid_t dthps_pid;			/* pid of associated proc */
+	int dthps_deferred;			/* helper in deferred list */
+	struct dtrace_helpers *dthps_next;	/* next pointer */
+	struct dtrace_helpers *dthps_prev;	/* prev pointer */
+};
+
+/*
+ * DTrace Helper Action Tracing
+ *
+ * Debugging helper actions can be arduous.  To ease the development and
+ * debugging of helpers, DTrace contains a tracing-framework-within-a-tracing-
+ * framework: helper tracing.  If dtrace_helptrace_enabled is non-zero (which
+ * it is by default on DEBUG kernels), all helper activity will be traced to a
+ * global, in-kernel ring buffer.  Each entry includes a pointer to the specific
+ * helper, the location within the helper, and a trace of all local variables.
+ * The ring buffer may be displayed in a human-readable format with the
+ * ::dtrace_helptrace mdb(1) dcmd.
+ */
+struct dtrace_helptrace {
+	struct dtrace_helper_action  *dtht_helper; /* helper action */
+	int dtht_where;				/* where in helper action */
+	int dtht_nlocals;			/* number of locals */
+	int dtht_fault;				/* type of fault (if any) */
+	int dtht_fltoffs;			/* DIF offset */
+	uint64_t dtht_illval;			/* faulting value */
+	uint64_t dtht_locals[1];		/* local variables */
+};
+
+extern struct mutex		dtrace_lock;
+extern struct mutex		dtrace_provider_lock;
+extern struct mutex		dtrace_meta_lock;
+
+extern dtrace_genid_t		dtrace_probegen;
+extern struct kmem_cache	*dtrace_probe_cachep;
+
+extern struct dtrace_pops	dtrace_provider_ops;
+
+extern int			dtrace_opens;
+extern int			dtrace_err_verbose;
+
+extern struct dtrace_toxrange	*dtrace_toxrange;
+extern int			dtrace_toxranges;
+
+extern void dtrace_nullop(void);
+extern int dtrace_enable_nullop(void);
+extern int dtrace_istoxic(uintptr_t, size_t);
+
+/*
+ * DTrace Probe Context Functions
+ */
+
+extern void dtrace_panic(const char *, ...);
+extern int dtrace_assfail(const char *, const char *, int);
+extern void dtrace_aggregate_min(uint64_t *, uint64_t, uint64_t);
+extern void dtrace_aggregate_max(uint64_t *, uint64_t, uint64_t);
+extern void dtrace_aggregate_quantize(uint64_t *, uint64_t, uint64_t);
+extern void dtrace_aggregate_lquantize(uint64_t *, uint64_t, uint64_t);
+extern void dtrace_aggregate_llquantize(uint64_t *, uint64_t, uint64_t);
+extern void dtrace_aggregate_avg(uint64_t *, uint64_t, uint64_t);
+extern void dtrace_aggregate_stddev(uint64_t *, uint64_t, uint64_t);
+extern void dtrace_aggregate_count(uint64_t *, uint64_t, uint64_t);
+extern void dtrace_aggregate_sum(uint64_t *, uint64_t, uint64_t);
+extern void dtrace_aggregate(struct dtrace_aggregation *,
+			     struct dtrace_buffer *,
+			     intptr_t, struct dtrace_buffer *, uint64_t,
+			     uint64_t);
+
+/*
+ * DTrace Probe Hashing Functions
+ */
+
+extern struct dtrace_hash *dtrace_hash_create(uintptr_t, uintptr_t, uintptr_t);
+extern void dtrace_hash_destroy(struct dtrace_hash *);
+extern int dtrace_hash_add(struct dtrace_hash *, struct dtrace_probe *);
+extern struct dtrace_probe *dtrace_hash_lookup(struct dtrace_hash *,
+					       struct dtrace_probe *);
+extern int dtrace_hash_collisions(struct dtrace_hash *, struct dtrace_probe *);
+extern void dtrace_hash_remove(struct dtrace_hash *, struct dtrace_probe *);
+
+/*
+ * DTrace Speculation Functions
+ */
+extern int dtrace_speculation(struct dtrace_state *);
+extern void dtrace_speculation_commit(struct dtrace_state *, processorid_t,
+				      dtrace_specid_t);
+extern void dtrace_speculation_discard(struct dtrace_state *, processorid_t,
+				       dtrace_specid_t);
+extern void dtrace_speculation_clean(struct dtrace_state *);
+extern struct dtrace_buffer *dtrace_speculation_buffer(struct dtrace_state *,
+						       processorid_t,
+						       dtrace_specid_t);
+
+/*
+ * DTrace Non-Probe Context Utility Functions
+ */
+
+/*
+ * DTrace Matching Functions
+ */
+extern struct dtrace_hash		*dtrace_bymod;
+extern struct dtrace_hash		*dtrace_byfunc;
+extern struct dtrace_hash		*dtrace_byname;
+
+extern int dtrace_match_priv(const struct dtrace_probe *, uint32_t, kuid_t);
+extern int dtrace_match_probe(const struct dtrace_probe *,
+			      const struct dtrace_probekey *, uint32_t,
+			      kuid_t);
+extern int dtrace_match_glob(const char *, const char *, int);
+extern int dtrace_match_string(const char *, const char *, int);
+extern int dtrace_match_nul(const char *, const char *, int);
+extern int dtrace_match_nonzero(const char *, const char *, int);
+extern int dtrace_match(const struct dtrace_probekey *, uint32_t, kuid_t,
+			int (*matched)(struct dtrace_probe *, void *), void *);
+extern void dtrace_probekey(const struct dtrace_probedesc *,
+			    struct dtrace_probekey *);
+
+/*
+ * DTrace Provider-to-Framework API Functions
+ */
+
+extern struct dtrace_provider	*dtrace_provider;
+extern struct dtrace_meta	*dtrace_meta_pid;
+extern struct dtrace_helpers	*dtrace_deferred_pid;
+
+/*
+ * DTrace Privilege Check Functions
+ */
+extern int dtrace_priv_proc_destructive(struct dtrace_state *);
+extern int dtrace_priv_proc_control(struct dtrace_state *);
+extern int dtrace_priv_proc(struct dtrace_state *);
+extern int dtrace_priv_kernel(struct dtrace_state *);
+
+/*
+ * DTrace Probe Management Functions
+ */
+
+extern int dtrace_probe_enable(const struct dtrace_probedesc *,
+			       struct dtrace_enabling *);
+extern void dtrace_probe_description(const struct dtrace_probe *,
+				     struct dtrace_probedesc *);
+extern void dtrace_probe_provide(struct dtrace_probedesc *,
+				 struct dtrace_provider *);
+extern int dtrace_probe_init(void);
+extern void dtrace_probe_exit(void);
+extern void dtrace_probe_remove_id(dtrace_id_t);
+extern struct dtrace_probe *dtrace_probe_lookup_id(dtrace_id_t);
+extern struct dtrace_probe *dtrace_probe_get_next(dtrace_id_t *);
+extern int dtrace_probe_for_each(int (*)(int, void *, void *), void *);
+
+/*
+ * DTrace Kernel Hooks
+ */
+extern void (*dtrace_modload)(struct module *);
+extern void (*dtrace_modunload)(struct module *);
+
+extern uint8_t dtrace_load8(uintptr_t);
+extern uint16_t dtrace_load16(uintptr_t);
+extern uint32_t dtrace_load32(uintptr_t);
+extern uint64_t dtrace_load64(uintptr_t);
+#ifdef CONFIG_64BIT
+#define dtrace_loadptr dtrace_load64
+#else
+#define dtrace_loadptr dtrace_load32
+#endif
+
+
+extern void dtrace_bzero(void *, size_t);
+
+extern int dtrace_vcanload(void *, struct dtrace_diftype *,
+			   struct dtrace_mstate *,
+			   struct dtrace_vstate *);
+extern int dtrace_canload(uintptr_t, size_t, struct dtrace_mstate *,
+			  struct dtrace_vstate *);
+
+extern int dtrace_difo_validate(struct dtrace_difo *, struct dtrace_vstate *,
+				uint_t, const struct cred *);
+extern int dtrace_difo_validate_helper(struct dtrace_difo *);
+extern int dtrace_difo_cacheable(struct dtrace_difo *);
+extern void dtrace_difo_hold(struct dtrace_difo *);
+extern void dtrace_difo_init(struct dtrace_difo *, struct dtrace_vstate *);
+extern struct dtrace_difo *dtrace_difo_duplicate(struct dtrace_difo *,
+						 struct dtrace_vstate *);
+extern void dtrace_difo_release(struct dtrace_difo *, struct dtrace_vstate *);
+
+extern uint64_t dtrace_vtime_references;
+
+extern uint64_t dtrace_dif_emulate(struct dtrace_difo *,
+				   struct dtrace_mstate *,
+				   struct dtrace_vstate *,
+				   struct dtrace_state *);
+
+/*
+ * DTrace Format Functions
+ */
+extern uint16_t dtrace_format_add(struct dtrace_state *, char *);
+extern void dtrace_format_remove(struct dtrace_state *, uint16_t);
+extern void dtrace_format_destroy(struct dtrace_state *);
+
+/*
+ * DTrace Predicate Functions
+ */
+extern struct dtrace_predicate *dtrace_predicate_create(struct dtrace_difo *);
+extern void dtrace_predicate_hold(struct dtrace_predicate *);
+extern void dtrace_predicate_release(struct dtrace_predicate *,
+				     struct dtrace_vstate *);
+
+/*
+ * DTrace Action Description Functions
+ */
+extern struct dtrace_actdesc *dtrace_actdesc_create(dtrace_actkind_t, uint32_t,
+					       uint64_t, uint64_t);
+extern void dtrace_actdesc_hold(struct dtrace_actdesc *);
+extern void dtrace_actdesc_release(struct dtrace_actdesc *,
+				   struct dtrace_vstate *);
+
+/*
+ * DTrace Helper Functions
+ */
+extern void dtrace_helpers_destroy(struct task_struct *);
+extern void dtrace_helpers_duplicate(struct task_struct *,
+				     struct task_struct *);
+extern uint64_t dtrace_helper(int, struct dtrace_mstate *,
+			      struct dtrace_state *,
+			      uint64_t, uint64_t);
+
+/*
+ * DTrace ECB Functions
+ */
+extern struct dtrace_ecb *dtrace_ecb_create_cache;
+
+extern int dtrace_ecb_create_enable(struct dtrace_probe *, void *);
+extern void dtrace_ecb_disable(struct dtrace_ecb *);
+extern void dtrace_ecb_destroy(struct dtrace_ecb *);
+extern void dtrace_ecb_resize(struct dtrace_ecb *);
+extern int dtrace_ecb_enable(struct dtrace_ecb *);
+extern struct dtrace_ecb *dtrace_epid2ecb(struct dtrace_state *,
+					  dtrace_epid_t);
+extern struct dtrace_aggregation *dtrace_aggid2agg(struct dtrace_state *,
+						   dtrace_aggid_t);
+
+/*
+ * DTrace Buffer Functions
+ *
+ * DTrace Buffers
+ *
+ * Principal buffers, aggregation buffers, and speculative buffers are all
+ * managed with the dtrace_buffer structure.  By default, this structure
+ * includes twin data buffers -- dtb_tomax and dtb_xamot -- that serve as the
+ * active and passive buffers, respectively.  For speculative buffers,
+ * dtb_xamot will be NULL; for "ring" and "fill" buffers, dtb_xamot will point
+ * to a scratch buffer.  For all buffer types, the dtrace_buffer structure is
+ * always allocated on a per-CPU basis; a single dtrace_buffer structure is
+ * never shared among CPUs.  (That is, there is never true sharing of the
+ * dtrace_buffer structure; to prevent false sharing of the structure, it must
+ * always be aligned to the coherence granularity -- generally 64 bytes.)
+ *
+ * One of the critical design decisions of DTrace is that a given ECB always
+ * stores the same quantity and type of data.  This is done to assure that the
+ * only metadata required for an ECB's traced data is the EPID.  That is, from
+ * the EPID, the consumer can determine the data layout.  (The data buffer
+ * layout is shown schematically below.)  By assuring that one can determine
+ * data layout from the EPID, the metadata stream can be separated from the
+ * data stream -- simplifying the data stream enormously.
+ *
+ *      base of data buffer --->  +------+--------------------+------+
+ *                                | EPID | data               | EPID |
+ *                                +------+--------+------+----+------+
+ *                                | data          | EPID | data      |
+ *                                +---------------+------+-----------+
+ *                                | data, cont.                      |
+ *                                +------+--------------------+------+
+ *                                | EPID | data               |      |
+ *                                +------+--------------------+      |
+ *                                |                ||                |
+ *                                |                ||                |
+ *                                |                \/                |
+ *                                :                                  :
+ *                                .                                  .
+ *                                .                                  .
+ *                                .                                  .
+ *                                :                                  :
+ *                                |                                  |
+ *     limit of data buffer --->  +----------------------------------+
+ *
+ * When evaluating an ECB, dtrace_probe() determines if the ECB's needs of the
+ * principal buffer (both scratch and payload) exceed the available space.  If
+ * the ECB's needs exceed available space (and if the principal buffer policy
+ * is the default "switch" policy), the ECB is dropped, the buffer's drop count
+ * is incremented, and processing advances to the next ECB.  If the ECB's needs
+ * can be met with the available space, the ECB is processed, but the offset in
+ * the principal buffer is only advanced if the ECB completes processing
+ * without error.
+ *
+ * When a buffer is to be switched (either because the buffer is the principal
+ * buffer with a "switch" policy or because it is an aggregation buffer), a
+ * cross call is issued to the CPU associated with the buffer.  In the cross
+ * call context, interrupts are disabled, and the active and the inactive
+ * buffers are atomically switched.  This involves switching the data pointers,
+ * copying the various state fields (offset, drops, errors, etc.) into their
+ * inactive equivalents, and clearing the state fields.  Because interrupts are
+ * disabled during this procedure, the switch is guaranteed to appear atomic to
+ * dtrace_probe().
+ *
+ * DTrace Ring Buffering
+ *
+ * To process a ring buffer correctly, one must know the oldest valid record.
+ * Processing starts at the oldest record in the buffer and continues until
+ * the end of the buffer is reached.  Processing then resumes starting with
+ * the record stored at offset 0 in the buffer, and continues until the
+ * youngest record is processed.  If trace records are of a fixed-length,
+ * determining the oldest record is trivial:
+ *
+ *   - If the ring buffer has not wrapped, the oldest record is the record
+ *     stored at offset 0.
+ *
+ *   - If the ring buffer has wrapped, the oldest record is the record stored
+ *     at the current offset.
+ *
+ * With variable length records, however, just knowing the current offset
+ * doesn't suffice for determining the oldest valid record:  assuming that one
+ * allows for arbitrary data, one has no way of searching forward from the
+ * current offset to find the oldest valid record.  (That is, one has no way
+ * of separating data from metadata.) It would be possible to simply refuse to
+ * process any data in the ring buffer between the current offset and the
+ * limit, but this leaves (potentially) an enormous amount of otherwise valid
+ * data unprocessed.
+ *
+ * To effect ring buffering, we track two offsets in the buffer:  the current
+ * offset and the _wrapped_ offset.  If a request is made to reserve some
+ * amount of data, and the buffer has wrapped, the wrapped offset is
+ * incremented until the wrapped offset minus the current offset is greater
+ * than or equal to the reserve request.  This is done by repeatedly looking
+ * up the ECB corresponding to the EPID at the current wrapped offset, and
+ * incrementing the wrapped offset by the size of the data payload
+ * corresponding to that ECB.  If this offset is greater than or equal to the
+ * limit of the data buffer, the wrapped offset is set to 0.  Thus, the
+ * current offset effectively "chases" the wrapped offset around the buffer.
+ * Schematically:
+ *
+ *      base of data buffer --->  +------+--------------------+------+
+ *                                | EPID | data               | EPID |
+ *                                +------+--------+------+----+------+
+ *                                | data          | EPID | data      |
+ *                                +---------------+------+-----------+
+ *                                | data, cont.                      |
+ *                                +------+---------------------------+
+ *                                | EPID | data                      |
+ *           current offset --->  +------+---------------------------+
+ *                                | invalid data                     |
+ *           wrapped offset --->  +------+--------------------+------+
+ *                                | EPID | data               | EPID |
+ *                                +------+--------+------+----+------+
+ *                                | data          | EPID | data      |
+ *                                +---------------+------+-----------+
+ *                                :                                  :
+ *                                .                                  .
+ *                                .        ... valid data ...        .
+ *                                .                                  .
+ *                                :                                  :
+ *                                +------+-------------+------+------+
+ *                                | EPID | data        | EPID | data |
+ *                                +------+------------++------+------+
+ *                                | data, cont.       | leftover     |
+ *     limit of data buffer --->  +-------------------+--------------+
+ *
+ * If the amount of requested buffer space exceeds the amount of space
+ * available between the current offset and the end of the buffer:
+ *
+ *  (1)  all words in the data buffer between the current offset and the limit
+ *       of the data buffer (marked "leftover", above) are set to
+ *       DTRACE_EPIDNONE
+ *
+ *  (2)  the wrapped offset is set to zero
+ *
+ *  (3)  the iteration process described above occurs until the wrapped offset
+ *       is greater than the amount of desired space.
+ *
+ * The wrapped offset is implemented by (re-)using the inactive offset.
+ * In a "switch" buffer policy, the inactive offset stores the offset in
+ * the inactive buffer; in a "ring" buffer policy, it stores the wrapped
+ * offset.
+ *
+ * DTrace Scratch Buffering
+ *
+ * Some ECBs may wish to allocate dynamically-sized temporary scratch memory.
+ * To accommodate such requests easily, scratch memory may be allocated in
+ * the buffer beyond the current offset plus the needed memory of the current
+ * ECB.  If there isn't sufficient room in the buffer for the requested amount
+ * of scratch space, the allocation fails and an error is generated.  Scratch
+ * memory is tracked in the dtrace_mstate_t and is automatically freed when
+ * the ECB ceases processing.  Note that ring buffers cannot allocate their
+ * scratch from the principal buffer -- lest they needlessly overwrite older,
+ * valid data.  Ring buffers therefore have their own dedicated scratch buffer
+ * from which scratch is allocated.
+ */
+
+extern void dtrace_buffer_switch(struct dtrace_buffer *);
+extern void dtrace_buffer_activate(struct dtrace_state *);
+extern int dtrace_buffer_alloc(struct dtrace_buffer *, size_t, int,
+			       processorid_t);
+extern void dtrace_buffer_drop(struct dtrace_buffer *);
+extern intptr_t dtrace_buffer_reserve(struct dtrace_buffer *, size_t, size_t,
+				      struct dtrace_state *,
+				      struct dtrace_mstate *);
+extern void dtrace_buffer_polish(struct dtrace_buffer *);
+extern void dtrace_buffer_free(struct dtrace_buffer *);
+
+/*
+ * DTrace framework/probe data synchronization
+ * -------------------------------------------
+ *
+ * The dtrace_sync() facility is used to synchronize global DTrace framework
+ * data with DTrace probe context.  The framework updates data and then calls
+ * dtrace_sync().  dtrace_sync() loops until it observes all CPUs have been out
+ * of probe context at least once.  This ensures all consumers are using the
+ * updated data.
+ *
+ * DTrace probes have several requirements.  First DTrace probe context cannot
+ * block.  DTrace probes execute with interrupts disabled.  Locks cannot be
+ * acquired in DTrace probe context.  A second requirement is that DTrace
+ * probes need to be as high performance as possible to minimize the effect of
+ * enabled probes.
+ *
+ * DTrace framework data changes have their own requirements.  DTrace data
+ * changes/syncs are extremely infrequent compared to DTrace probe firings.
+ * Probes can be in commonly executed code.  A good trade-off is to favor
+ * DTrace probe context performance over DTrace sync performance.
+ *
+ * To meet the above requirements, the DTrace data synchronization algorithm
+ * is lock-less.  The DTrace probe path is wait-free.  The DTrace probe path
+ * is memory-barrier-free in the common case to minimize probe effect.
+ * dtrace_probe has been made membar free in the common case by adding a read
+ * in dtrace_probe and adding an additional write and membar to dtrace_sync().
+ *
+ * A simple algorithm is to have dtrace_probe set a flag for its CPU when
+ * entering DTrace probe context and clear the flag when it exits DTrace probe
+ * context.  A producer of DTrace framework data checks the flag to detect and
+ * synchronize with probe context.  Unfortunately memory ordering issues
+ * complicate the implementation.  Memory barriers are required in probe
+ * context for this simple approach to work.
+ *
+ * A simple implementation to sync with one CPU that works with any memory
+ * ordering model is:
+ *
+ * DTrace probe:
+ *    1. CPU->in_probe_context = B_TRUE;
+ *    2. dtrace_membar_enter()// membar #StoreLoad|#StoreStore
+ *    3. access framework shared data// critical section
+ *    4. dtrace_membar_exit()// membar #LoadStore|#StoreStore
+ *    5. CPU->in_probe_context = B_FALSE;
+ *
+ * DTrace framework dtrace_sync:
+ *    0. update framework shared data
+ *    1. dtrace_membar_enter()// membar #StoreLoad|#StoreStore
+ *    2. while (CPU->in_probe_context == B_TRUE)
+ *    3.     spin
+ *    4. dtrace_membar_exit()// membar #LoadStore|#StoreStore
+ *    5. produce shared dtrace data
+ *
+ * A note on memory ordering
+ * -------------------------
+ *
+ * dtrace_membar_enter() guarantees later loads cannot complete before earlier
+ * stores, and it guarantees later stores cannot complete before earlier stores.
+ * dtrace_membar_enter() is, in SPARC parlance, a membar #StoreLoad|#StoreStore.
+ *
+ * dtrace_membar_exit() guarantees later stores cannot complete before earlier
+ * loads, and it guarantees later stores cannot complete before earlier stores.
+ * dtrace_membar_exit() is, in SPARC parlance, a membar #LoadStore|#StoreStore.
+ *
+ * Please see the SPARC and Intel processor guides on memory ordering.
+ * All sun4v and Fujitsu processors are TSO (Total Store Order).  Modern
+ * supported Intel and AMD processors have similar load and store ordering
+ * to SPARC.  All processors currently supported by Solaris have these memory
+ * ordering properties:
+ * 1) Loads are ordered with respect to earlier loads.
+ * 2) Stores are ordered with respect to earlier stores.
+ * 3a) SPARC Atomic load-store behaves as if it were followed by a
+ *     MEMBAR #LoadLoad, #LoadStore, and #StoreStore.
+ * 3b) X86 Atomic operations serialize load and store.
+ * 4) Stores cannot bypass earlier loads.
+ *
+ * The above implementation details allow the membars to be simplified thus:
+ * A) dtrace_membar_enter() can be reduced to "membar #StoreLoad" on sparc.
+ *    See property number 4 above.
+ *    Since dtrace_membar_enter() is an atomic operation on x86, it cannot be
+ *    reduced further.
+ * B) dtrace_membar_exit() becomes a NOP on both SPARC and x86.
+ *    See properties 2 and 4.
+ *
+ *
+ * Elimination of membar #StoreLoad from dtrace probe context
+ * ----------------------------------------------------------
+ *
+ * Furthermore it is possible to eliminate all memory barriers from the common
+ * dtrace_probe() entry case.  The only membar needed in dtrace_probe is there
+ * to prevent Loads of global DTrace framework data from passing the Store to
+ * the "in_probe_context" flag (i.e. the dtrace_membar_enter()).
+ * A Load at the beginning of the algorithm is also ordered with these later
+ * Loads and Stores: the membar #StoreLoad can be replaced with a early Load of
+ * a "sync_request" flag and a conditional branch on the flag value.
+ *
+ * dtrace_sync() first Stores to the "sync_request" flag, and dtrace_probe()
+ * starts by Loading the flag.  This Load in dtrace_probe() of "sync_request"
+ * is ordered with its later Store to the "in_probe_context" flag and
+ * dtrace_probe's later Loads of DTrace framework data.  dtrace_probe() only
+ * needs a membar #StoreLoad iff the "sync_request" flag is set.
+ *
+ * Optimized Synchronization Algorithm
+ * -----------------------------------
+ *
+ * DTrace probe:
+ * +  1a. request_flag = CPU->sync_request		// Load
+ *    1b. CPU->in_probe_context = B_TRUE		// Store
+ * +  2.  if request_flag > 0
+ *            dtrace_membar_enter()			// membar #StoreLoad
+ *    3. access framework shared data			// critical section
+ * -
+ *    5. CPU->in_probe_context = B_FALSE		// Store
+ *
+ * DTrace framework dtrace_sync:
+ * +  1a. atomically add 1 to CPU->sync_request		// Store and
+ *    1b. dtrace_membar_enter()				// membar #StoreLoad
+ *    2.  while (CPU->in_probe_context == B_TRUE)	// Load
+ *    3.      spin
+ * +  4a. atomically subtract 1 from CPU->sync_request	// Load + Store
+ * -
+ *    5.  produce shared dtrace data
+ *
+ * This algorithm has been proven correct by analysis of all interleaving
+ * scenarios of the above operations with the hardware memory ordering
+ * described above.
+ *
+ * The Load and store of the flag pair is very inexpensive.  The cacheline with
+ * the flag pair is never accessed by a different CPU except by dtrace_sync.
+ * dtrace_sync is very uncommon compared to typical probe firings.  The removal
+ * of membars from DTrace probe context at the expense of a Load and Store and
+ * a conditional branch is a good performance win.
+ *
+ * As implemented there is one pair of flags per CPU.  The flags are in one
+ * cacheline; they could be split into two cachelines if dtrace_sync was more
+ * common.  dtrace_sync loops over all NCPU sets of flags.  dtrace_sync lazily
+ * only does one dtrace_membar_enter() (step 1b) after setting all NCPU
+ * sync_request flags.
+ *
+ * Sample aliasing could cause dtrace_sync() to always sample a CPU's
+ * in_probe_context flag when the CPU is in probe context even if the CPU
+ * left and returned to probe context one or more times since the last sample.
+ * cpuc_in_probe_ctxt is implemented as an even/odd counter instead of a
+ * boolean flag.  cpuc_in_probe_ctxt is odd when in probe context and even
+ * when not in probe context.  Probe context increments cpuc_in_probe_ctxt when
+ * entering and exiting.  dtrace_probe() handles re-entry by not increment the
+ * counter for re-enterant entry and exit.
+ */
+
+/*
+ * dtrace_membar_exit() is a NOP on current SPARC and X86 hardware.
+ * It is defined as an inline asm statement to prevent the C optimizer from
+ * moving C statements around the membar.
+ */
+#define	dtrace_membar_exit()						\
+	__asm__ __volatile__("" ::: "memory")
+
+/*
+ * dtrace_membar_enter() does not need an explicit membar #StoreStore because
+ * modern SPARC hardware is TSO: stores are ordered with other stores.
+ */
+#define	dtrace_membar_enter()						\
+	mb()
+
+#define	dtrace_safe_smt_pause()						\
+	cpu_relax()
+
+/*
+ * Used by dtrace_probe() to flag entry to the the critical section.
+ * dtrace_probe() context may be consuming DTrace framework data.
+ *
+ * cpuc_in_probe_ctxt is odd when in probe context and even when not in
+ * probe context.  The flag must not be incremented when re-entering from
+ * probe context.
+ */
+#define	DTRACE_SYNC_ENTER_CRITICAL(cookie, re_entry)			\
+{									\
+	uint64_t	requests;					\
+	uint64_t	count;						\
+									\
+	preempt_disable();						\
+	local_irq_save(cookie);						\
+									\
+	requests = atomic64_read(&this_cpu_core->cpuc_sync_requests);	\
+									\
+	/* Increment flag iff it is even */				\
+	count = atomic64_read(&this_cpu_core->cpuc_in_probe_ctx);	\
+	re_entry = count & 0x1;						\
+	atomic64_set(&this_cpu_core->cpuc_in_probe_ctx, count | 0x1);	\
+	ASSERT(DTRACE_SYNC_IN_CRITICAL(smp_processor_id()));		\
+									\
+	/*								\
+	 * Later Loads are ordered with respect to the Load of		\
+	 * cpuc_sync_requests.  The Load is also guaranteed to complete	\
+	 * before the store to cpuc_in_probe_ctxt.  Thus a member_enter	\
+	 * is only needed when requests is not 0.  This is very		\
+	 * uncommon.							\
+	 */								\
+	if (requests > 0) {						\
+		dtrace_membar_enter();					\
+	}								\
+}
+
+/*
+ * Used by dtrace_probe() to flag exit from the critical section.
+ * dtrace_probe context is no longer using DTrace framework data.
+ */
+#define	DTRACE_SYNC_EXIT_CRITICAL(cookie, re_entry)			\
+{									\
+	dtrace_membar_exit();						\
+	ASSERT((re_entry | 0x1) ==  0x1);				\
+									\
+	/*								\
+	 * flag must not be incremented when returning to probe context.\
+	 */								\
+	atomic64_add(~re_entry & 0x1, &this_cpu_core->cpuc_in_probe_ctx); \
+	ASSERT(re_entry ==						\
+	    (atomic64_read(&this_cpu_core->cpuc_in_probe_ctx) & 0x1));	\
+	local_irq_restore(cookie);					\
+	preempt_enable();						\
+}
+
+/*
+ * Used by dtrace_sync to inform dtrace_probe it needs to synchronize with
+ * dtrace_sync.  dtrace_probe consumes the cpuc_sync_requests flag to determine
+ * if it needs a membar_enter.  Not called from probe context.
+ *
+ * cpuc_sync_requests must be updated atomically by dtrace_sync because there
+ * may be multiple dtrace_sync operations executing at the same time.
+ * cpuc_sync_requests is a simple count of the number of concurrent
+ * dtrace_sync requests.
+ */
+#define	DTRACE_SYNC_START(cpuid)					\
+{									\
+	atomic64_add(1, &(per_cpu_core(cpuid))->cpuc_sync_requests);	\
+	ASSERT(atomic64_read(&per_cpu_core(cpuid)->cpuc_sync_requests) > 0); \
+}
+
+/*
+ * Used by dtrace_sync to flag dtrace_probe that it no longer needs to
+ * synchronize with dtrace_sync.  Not called from probe context.
+ */
+#define	DTRACE_SYNC_END(cpuid)						\
+{									\
+	atomic64_add(-1, &(per_cpu_core(cpuid))->cpuc_sync_requests);	\
+	ASSERT(atomic64_read(&per_cpu_core(cpuid)->cpuc_sync_requests) >= 0); \
+}
+
+/*
+ * The next two macros are used by dtrace_sync to check if the target CPU is in
+ * DTrace probe context.  cpuc_in_probe_ctxt is a monotonically increasing
+ * count which dtrace_probe() increments when entering and exiting probe
+ * context.  The flag is odd when in probe context, and even when not in probe
+ * context.
+ */
+#define	DTRACE_SYNC_IN_CRITICAL(cpuid)					\
+	(atomic64_read(&per_cpu_core(cpuid)->cpuc_in_probe_ctx) & 0x1)
+
+/*
+ * Used to check if the target CPU left and then entered probe context again.
+ */
+#define	DTRACE_SYNC_CRITICAL_COUNT(cpuid)				\
+	(atomic64_read(&per_cpu_core(cpuid)->cpuc_in_probe_ctx))
+
+/*
+ * The next three macros are bitmap operations used by dtrace_sync to keep track
+ * of which CPUs it still needs to synchronize with.
+ */
+#define	DTRACE_SYNC_OUTSTANDING(cpuid, bitmap)				\
+	(cpumask_test_cpu(cpuid, bitmap) == 1)
+
+#define	DTRACE_SYNC_NEEDED(cpuid, bitmap)				\
+	cpumask_set_cpu(cpuid, bitmap)
+
+#define	DTRACE_SYNC_DONE(cpuid, bitmap)					\
+	cpumask_clear_cpu(cpuid, bitmap)
+
+extern uint64_t dtrace_sync_sample_count;
+extern void dtrace_sync(void);
+
+/*
+ * DTrace Enabling Functions
+ */
+extern struct dtrace_enabling	*dtrace_retained;
+extern dtrace_genid_t		dtrace_retained_gen;
+
+extern struct dtrace_enabling *dtrace_enabling_create(struct dtrace_vstate *);
+extern void dtrace_enabling_add(struct dtrace_enabling *,
+				struct dtrace_ecbdesc *);
+extern void dtrace_enabling_dump(struct dtrace_enabling *);
+extern void dtrace_enabling_destroy(struct dtrace_enabling *);
+extern int dtrace_enabling_retain(struct dtrace_enabling *);
+extern int dtrace_enabling_replicate(struct dtrace_state *,
+				     struct dtrace_probedesc *,
+				     struct dtrace_probedesc *);
+extern void dtrace_enabling_retract(struct dtrace_state *);
+extern int dtrace_enabling_match(struct dtrace_enabling *, int *);
+extern void dtrace_enabling_matchall(void);
+extern void dtrace_enabling_prime(struct dtrace_state *);
+extern void dtrace_enabling_provide(struct dtrace_provider *);
+
+/*
+ * DOF functions
+ */
+extern void dtrace_dof_error(struct dof_hdr *, const char *);
+extern struct dof_hdr *dtrace_dof_create(struct dtrace_state *);
+extern struct dof_hdr *dtrace_dof_copyin(void __user *, int *);
+extern struct dof_hdr *dtrace_dof_property(const char *);
+extern void dtrace_dof_destroy(struct dof_hdr *);
+extern int dtrace_dof_slurp(struct dof_hdr *, struct dtrace_vstate *,
+			    const struct cred *, struct dtrace_enabling **,
+			    uint64_t, int);
+extern int dtrace_dof_options(struct dof_hdr *, struct dtrace_state *);
+extern void dtrace_helper_provide(struct dof_helper *dhp, pid_t pid);
+extern int dtrace_helper_slurp(struct dof_hdr *, struct dof_helper *);
+extern int dtrace_helper_destroygen(int);
+
+/*
+ * DTrace Anonymous Enabling Functions
+ */
+struct dtrace_anon {
+	struct dtrace_state *dta_state;
+	struct dtrace_enabling *dta_enabling;
+	processorid_t dta_beganon;
+};
+
+extern struct dtrace_anon	dtrace_anon;
+
+extern struct dtrace_state *dtrace_anon_grab(void);
+extern void dtrace_anon_property(void);
+
+/*
+ * DTrace Consumer State Functions
+ */
+extern struct kmem_cache	*dtrace_state_cachep;
+extern size_t			dtrace_strsize_default;
+
+extern ktime_t			dtrace_deadman_timeout;
+extern int			dtrace_destructive_disallow;
+
+extern dtrace_id_t		dtrace_probeid_begin;
+extern dtrace_id_t		dtrace_probeid_end;
+extern dtrace_id_t		dtrace_probeid_error;
+
+extern struct dtrace_dynvar	dtrace_dynhash_sink;
+
+extern struct user_namespace	*init_user_namespace;
+
+extern int dtrace_dstate_init(struct dtrace_dstate *, size_t);
+extern void dtrace_dstate_fini(struct dtrace_dstate *);
+extern void dtrace_vstate_fini(struct dtrace_vstate *);
+extern struct dtrace_state *dtrace_state_create(struct file *);
+extern int dtrace_state_go(struct dtrace_state *, processorid_t *);
+extern int dtrace_state_stop(struct dtrace_state *, processorid_t *);
+extern int dtrace_state_option(struct dtrace_state *, dtrace_optid_t,
+			       dtrace_optval_t);
+extern void dtrace_state_destroy(struct dtrace_state *);
+
+/*
+ * DTrace Utility Functions
+ */
+extern int dtrace_isglob(const char *);
+extern int dtrace_gmatch(const char *, const char *);
+extern void *dtrace_vzalloc(unsigned long);
+extern void *dtrace_vzalloc_try(unsigned long);
+extern char *dtrace_strdup(const char *);
+extern int dtrace_strncmp(char *, char *, size_t);
+extern size_t dtrace_strlen(const char *, size_t);
+extern int dtrace_badattr(const struct dtrace_attribute *);
+extern int dtrace_badname(const char *);
+extern void dtrace_cred2priv(const struct cred *, uint32_t *, kuid_t *);
+
+extern void ctf_forceload(void);
+
+#define dtrace_membar_producer()	smp_wmb()
+#define dtrace_membar_consumer()	smp_rmb()
+
+typedef unsigned long	dtrace_icookie_t;
+
+extern struct mutex	cpu_lock;
+
+extern void dtrace_toxic_ranges(void (*)(uintptr_t, uintptr_t));
+extern void dtrace_vpanic(const char *, va_list);
+extern int dtrace_getipl(void);
+
+extern dtrace_icookie_t dtrace_interrupt_disable(void);
+extern void dtrace_interrupt_enable(dtrace_icookie_t);
+
+typedef void (*dtrace_xcall_t)(void *);
+
+extern void dtrace_xcall(processorid_t, dtrace_xcall_t, void *);
+
+extern uintptr_t dtrace_fulword(void *);
+extern uint8_t dtrace_fuword8(void *);
+extern uint16_t dtrace_fuword16(void *);
+extern uint32_t dtrace_fuword32(void *);
+extern uint64_t dtrace_fuword64(void *);
+
+extern void dtrace_probe_error(struct dtrace_state *, dtrace_epid_t, int, int,
+			       int, uintptr_t);
+
+extern void dtrace_getpcstack(uint64_t *, int, int, uint32_t *);
+extern void dtrace_getupcstack(uint64_t *, int);
+extern unsigned long dtrace_getufpstack(uint64_t *, uint64_t *, int);
+extern uintptr_t dtrace_getfp(void);
+extern uint64_t dtrace_getarg(int, int);
+extern int dtrace_getstackdepth(struct dtrace_mstate *, int);
+extern int dtrace_getustackdepth(void);
+extern ulong_t dtrace_getreg(struct task_struct *, uint_t);
+extern void dtrace_copyin(uintptr_t, uintptr_t, size_t,
+			  volatile uint16_t *);
+extern void dtrace_copyout(uintptr_t, uintptr_t, size_t,
+			   volatile uint16_t *);
+extern void dtrace_copyinstr(uintptr_t, uintptr_t, size_t,
+			     volatile uint16_t *);
+extern void dtrace_copyoutstr(uintptr_t, uintptr_t, size_t,
+			      volatile uint16_t *);
+
+/*
+ * Plaforms that support a fast path to obtain the caller implement the
+ * dtrace_caller() function.
+ *
+ * The first argument is the number of frames that should be skipped when
+ * looking for a caller address.  The 2nd argument is a dummy argument that
+ * is necessary for SPARC.
+ *
+ * On x86 this is effectively a NOP.
+ *
+ * On SPARC it is possible to retrieve the caller address from the register
+ * windows without flushing them to the stack.  This involves performing
+ * explicit rotation of the register windows.  Modification of the windowing
+ * mechanism state alters all %i, %o, and %l registers so we are can only use
+ * %g registers to store temporary data.
+ *
+ * On Linux a lot of %g registers are already allocated for specific purposes.
+ * Saving temporaries to the stack would be a violation of the fast path code
+ * logic. Therefore, the function prototype declares a 2nd argument that serves
+ * as a temporary value.  A compiler will not expect that the value in %o1
+ * will survive the call and therefore dtrace_caller() can use %o1 as a
+ * temporary register.
+ */
+extern uintptr_t dtrace_caller(int, int);
+
+extern void dtrace_copyin_arch(uintptr_t, uintptr_t, size_t,
+			       volatile uint16_t *);
+extern void dtrace_copyinstr_arch(uintptr_t, uintptr_t, size_t,
+				  volatile uint16_t *);
+
+extern void pdata_init(struct dtrace_module *, struct module *);
+extern void pdata_cleanup(struct dtrace_module *, struct module *);
+
+extern void debug_enter(char *);
+
+#endif /* _LINUX_DTRACE_IMPL_H */
diff --git a/include/dtrace/dtrace_impl_defines.h b/include/dtrace/dtrace_impl_defines.h
new file mode 100644
index 000000000000..19b57f6188a0
--- /dev/null
+++ b/include/dtrace/dtrace_impl_defines.h
@@ -0,0 +1,173 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Dynamic Tracing for Linux - Implementation Defines
+ *
+ * Copyright (c) 2009, 2017, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_IMPL_DEFINES_H
+#define _LINUX_DTRACE_IMPL_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/preempt.h>
+#include <asm/ptrace.h>
+
+typedef typeof(instruction_pointer((struct pt_regs *)0))	pc_t;
+
+enum dtrace_activity {
+	DTRACE_ACTIVITY_INACTIVE = 0,
+	DTRACE_ACTIVITY_WARMUP,
+	DTRACE_ACTIVITY_ACTIVE,
+	DTRACE_ACTIVITY_DRAINING,
+	DTRACE_ACTIVITY_COOLDOWN,
+	DTRACE_ACTIVITY_STOPPED,
+	DTRACE_ACTIVITY_KILLED
+};
+
+enum dtrace_dstate_state {
+	DTRACE_DSTATE_CLEAN = 0,
+	DTRACE_DSTATE_EMPTY,
+	DTRACE_DSTATE_DIRTY,
+	DTRACE_DSTATE_RINSING
+};
+
+enum dtrace_dynvar_op {
+	DTRACE_DYNVAR_ALLOC,
+	DTRACE_DYNVAR_NOALLOC,
+	DTRACE_DYNVAR_DEALLOC
+};
+
+#define DTRACE_MSTATE_ARGS		0x00000001
+#define DTRACE_MSTATE_PROBE		0x00000002
+#define DTRACE_MSTATE_EPID		0x00000004
+#define DTRACE_MSTATE_TIMESTAMP		0x00000008
+#define DTRACE_MSTATE_STACKDEPTH	0x00000010
+#define DTRACE_MSTATE_CALLER		0x00000020
+#define DTRACE_MSTATE_IPL		0x00000040
+#define DTRACE_MSTATE_FLTOFFS		0x00000080
+#define DTRACE_MSTATE_USTACKDEPTH	0x00000100
+#define DTRACE_MSTATE_UCALLER		0x00000200
+
+#define DTRACE_PROBEKEY_MAXDEPTH	8
+
+enum dtrace_speculation_state {
+	DTRACESPEC_INACTIVE = 0,
+	DTRACESPEC_ACTIVE,
+	DTRACESPEC_ACTIVEONE,
+	DTRACESPEC_ACTIVEMANY,
+	DTRACESPEC_COMMITTING,
+	DTRACESPEC_COMMITTINGMANY,
+	DTRACESPEC_DISCARDING
+};
+
+#define DTRACE_HELPER_ACTION_USTACK	0
+#define DTRACE_NHELPER_ACTIONS		1
+
+#define DTRACE_HELPTRACE_NEXT	(-1)
+#define DTRACE_HELPTRACE_DONE	(-2)
+#define DTRACE_HELPTRACE_ERR	(-3)
+
+#undef ASSERT
+#ifdef CONFIG_DT_DEBUG
+# define ASSERT(x)	((void)((x) || dtrace_assfail(#x, __FILE__, __LINE__)))
+#else
+# define ASSERT(x)	((void)0)
+#endif
+
+/*
+ * DTrace Probe Hashing
+ */
+
+#define DTRACE_HASHNEXT(hash, probe)					\
+	(struct dtrace_probe **)((uintptr_t)(probe) + (hash)->dth_nextoffs)
+#define DTRACE_HASHPREV(hash, probe)	\
+	(struct dtrace_probe **)((uintptr_t)(probe) + (hash)->dth_prevoffs)
+
+/*
+ * DTrace Probe Management
+ */
+#define DTRACE_ANCHORED(probe)	((probe)->dtpr_func[0] != '\0')
+#define DTRACE_FLAGS2FLT(flags)						\
+	(((flags) & CPU_DTRACE_BADADDR) ? DTRACEFLT_BADADDR :		\
+	 ((flags) & CPU_DTRACE_ILLOP) ? DTRACEFLT_ILLOP :		\
+	 ((flags) & CPU_DTRACE_DIVZERO) ? DTRACEFLT_DIVZERO :		\
+	 ((flags) & CPU_DTRACE_KPRIV) ? DTRACEFLT_KPRIV :		\
+	 ((flags) & CPU_DTRACE_UPRIV) ? DTRACEFLT_UPRIV :		\
+	 ((flags) & CPU_DTRACE_TUPOFLOW) ?  DTRACEFLT_TUPOFLOW :	\
+	 ((flags) & CPU_DTRACE_BADALIGN) ?  DTRACEFLT_BADALIGN :	\
+	 ((flags) & CPU_DTRACE_NOSCRATCH) ?  DTRACEFLT_NOSCRATCH :	\
+	 ((flags) & CPU_DTRACE_BADSTACK) ?  DTRACEFLT_BADSTACK :	\
+	 DTRACEFLT_UNKNOWN)
+
+/*
+ * Test whether alloc_sz bytes will fit in the scratch region.  We isolate
+ * alloc_sz on the righthand side of the comparison in order to avoid overflow
+ * or underflow in the comparison with it.  This is simpler than the INRANGE
+ * check above, because we know that the dtms_scratch_ptr is valid in the
+ * range.  Allocations of size zero are allowed.
+ */
+#define DTRACE_INSCRATCH(mstate, alloc_sz) \
+	((mstate)->dtms_scratch_base + (mstate)->dtms_scratch_size - \
+	 (mstate)->dtms_scratch_ptr >= (alloc_sz))
+
+/*
+ * Buffering.
+ */
+
+#define DTRACEBUF_RING		0x0001		/* bufpolicy set to "ring" */
+#define DTRACEBUF_FILL		0x0002		/* bufpolicy set to "fill" */
+#define DTRACEBUF_NOSWITCH	0x0004		/* do not switch buffer */
+#define DTRACEBUF_WRAPPED	0x0008		/* ring buffer has wrapped */
+#define DTRACEBUF_DROPPED	0x0010		/* drops occurred */
+#define DTRACEBUF_ERROR		0x0020		/* errors occurred */
+#define DTRACEBUF_FULL		0x0040		/* "fill" buffer is full */
+#define DTRACEBUF_CONSUMED	0x0080		/* buffer has been consumed */
+#define DTRACEBUF_INACTIVE	0x0100		/* buffer is not yet active */
+
+#define DTRACE_STORE(type, tomax, offset, what) \
+	do { \
+	*((type *)((uintptr_t)(tomax) + (uintptr_t)(offset))) = (type)(what); \
+	} while (0)
+
+#define KERNELBASE	(uintptr_t)_text
+
+#ifdef CONFIG_DT_DEBUG_MUTEX
+# define real_mutex_lock(x)		mutex_lock(x)
+# define real_mutex_unlock(x)		mutex_unlock(x)
+
+# define mutex_lock(x)		do {					      \
+				    pr_debug("mutex_lock(%s) at %s::%d for %p (PID %d)\n", \
+					     __stringify(x),		      \
+					     __FILE__, __LINE__, current,     \
+					     current ? current->pid : -1);    \
+				    real_mutex_lock(x);			      \
+				} while (0)
+# define mutex_unlock(x)	do {					      \
+				    pr_debug("mutex_unlock(%s) at %s::%d for %p (PID %d)\n", \
+					     __stringify(x),		      \
+					     __FILE__, __LINE__, current,     \
+					     current ? current->pid : -1);    \
+				    real_mutex_unlock(x);		      \
+				} while (0)
+#endif
+
+#define MUTEX_HELD(lock)	mutex_owned(lock)
+
+#define PDATA(mp)		((struct dtrace_module *)mp->pdata)
+
+#endif /* _LINUX_DTRACE_IMPL_DEFINES_H */
diff --git a/include/dtrace/provider.h b/include/dtrace/provider.h
new file mode 100644
index 000000000000..149ef82b3681
--- /dev/null
+++ b/include/dtrace/provider.h
@@ -0,0 +1,971 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Dynamic Tracing for Linux - Provider API
+ *
+ * Copyright (c) 2009, 2018, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _DTRACE_PROVIDER_H
+#define _DTRACE_PROVIDER_H
+
+/*
+ * The following functions are implemented by the DTrace framework and are
+ * used to implement separate in-kernel DTrace providers.
+ *
+ * The provider API has two halves:  the API that the providers consume from
+ * DTrace, and the API that providers make available to DTrace.
+ *
+ * 1 Framework-to-Provider API
+ *
+ * 1.1  Overview
+ *
+ * The Framework-to-Provider API is represented by the dtrace_pops structure
+ * that the provider passes to the framework when registering itself.  This
+ * structure consists of the following members:
+ *
+ *   dtps_provide()          <-- Provide all probes, all modules
+ *   dtps_provide_module()   <-- Provide all probes in specified module
+ *   dtps_enable()           <-- Enable specified probe
+ *   dtps_disable()          <-- Disable specified probe
+ *   dtps_suspend()          <-- Suspend specified probe
+ *   dtps_resume()           <-- Resume specified probe
+ *   dtps_getargdesc()       <-- Get the argument description for args[X]
+ *   dtps_getargval()        <-- Get the value for an argX or args[X] variable
+ *   dtps_usermode()         <-- Find out if the probe was fired in user mode
+ *   dtps_destroy()          <-- Destroy all state associated with this probe
+ *   dtps_destroy_module()   <-- Destroy per-module data
+ *
+ * 1.2  void dtps_provide(void *arg, const struct dtrace_probedesc *spec)
+ *
+ * 1.2.1  Overview
+ *
+ *   Called to indicate that the provider should provide all probes.  If the
+ *   specified description is non-NULL, dtps_provide() is being called because
+ *   no probe matched a specified probe -- if the provider has the ability to
+ *   create custom probes, it may wish to create a probe that matches the
+ *   specified description.
+ *
+ * 1.2.2  Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register().  The
+ *   second argument is a pointer to a probe description that the provider may
+ *   wish to consider when creating custom probes.  The provider is expected to
+ *   call back into the DTrace framework via dtrace_probe_create() to create
+ *   any necessary probes.  dtps_provide() may be called even if the provider
+ *   has made available all probes; the provider should check the return value
+ *   of dtrace_probe_create() to handle this case.  Note that the provider need
+ *   not implement both dtps_provide() and dtps_provide_module(); see
+ *   "Arguments and Notes" for dtrace_register(), below.
+ *
+ * 1.2.3  Return value
+ *
+ *   None.
+ *
+ * 1.2.4  Caller's context
+ *
+ *   dtps_provide() is typically called from open() or ioctl() context, but may
+ *   be called from other contexts as well.  The DTrace framework is locked in
+ *   such a way that providers may not register or unregister.  This means that
+ *   the provider may not call any DTrace API that affects its registration with
+ *   the framework, including dtrace_register(), dtrace_unregister(),
+ *   dtrace_invalidate(), and dtrace_condense().  However, the context is such
+ *   that the provider may (and indeed, is expected to) call probe-related
+ *   DTrace routines, including dtrace_probe_create(), dtrace_probe_lookup(),
+ *   and dtrace_probe_arg().
+ *
+ * 1.3  void dtps_provide_module(void *arg, struct modctl *mp)
+ *
+ * 1.3.1  Overview
+ *
+ *   Called to indicate that the provider should provide all probes in the
+ *   specified module.
+ *
+ * 1.3.2  Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register().  The
+ *   second argument is a pointer to a modctl structure that indicates the
+ *   module for which probes should be created.
+ *
+ * 1.3.3  Return value
+ *
+ *   None.
+ *
+ * 1.3.4  Caller's context
+ *
+ *   dtps_provide_module() may be called from open() or ioctl() context, but
+ *   may also be called from a module loading context.  mod_lock is held, and
+ *   the DTrace framework is locked in such a way that providers may not
+ *   register or unregister.  This means that the provider may not call any
+ *   DTrace API that affects its registration with the framework, including
+ *   dtrace_register(), dtrace_unregister(), dtrace_invalidate(), and
+ *   dtrace_condense().  However, the context is such that the provider may (and
+ *   indeed, is expected to) call probe-related DTrace routines, including
+ *   dtrace_probe_create(), dtrace_probe_lookup(), and dtrace_probe_arg().  Note
+ *   that the provider need not implement both dtps_provide() and
+ *   dtps_provide_module(); see "Arguments and Notes" for dtrace_register(),
+ *   below.
+ *
+ * 1.4  int dtps_enable(void *arg, dtrace_id_t id, void *parg)
+ *
+ * 1.4.1  Overview
+ *
+ *   Called to enable the specified probe.
+ *
+ * 1.4.2  Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register().  The
+ *   second argument is the identifier of the probe to be enabled.  The third
+ *   argument is the probe argument as passed to dtrace_probe_create().
+ *   dtps_enable() will be called when a probe transitions from not being
+ *   enabled at all to having one or more ECB.  The number of ECBs associated
+ *   with the probe may change without subsequent calls into the provider.
+ *   When the number of ECBs drops to zero, the provider will be explicitly
+ *   told to disable the probe via dtps_disable().  dtrace_probe() should never
+ *   be called for a probe identifier that hasn't been explicitly enabled via
+ *   dtps_enable().
+ *
+ * 1.4.3  Return value
+ *
+ *   On success, dtps_enable() should return 0. On failure, -1 should be
+ *   returned.
+ *
+ * 1.4.4  Caller's context
+ *
+ *   The DTrace framework is locked in such a way that it may not be called
+ *   back into at all.  cpu_lock is held.  mod_lock is not held and may not
+ *   be acquired.
+ *
+ * 1.5  void dtps_disable(void *arg, dtrace_id_t id, void *parg)
+ *
+ * 1.5.1  Overview
+ *
+ *   Called to disable the specified probe.
+ *
+ * 1.5.2  Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register().  The
+ *   second argument is the identifier of the probe to be disabled.  The third
+ *   argument is the probe argument as passed to dtrace_probe_create().
+ *   dtps_disable() will be called when a probe transitions from being enabled
+ *   to having zero ECBs.  dtrace_probe() should never be called for a probe
+ *   identifier that has been explicitly enabled via dtps_disable().
+ *
+ * 1.5.3  Return value
+ *
+ *   None.
+ *
+ * 1.5.4  Caller's context
+ *
+ *   The DTrace framework is locked in such a way that it may not be called
+ *   back into at all.  cpu_lock is held.  mod_lock is not held and may not
+ *   be acquired.
+ *
+ * 1.6  void dtps_suspend(void *arg, dtrace_id_t id, void *parg)
+ *
+ * 1.6.1  Overview
+ *
+ *   Called to suspend the specified enabled probe.  This entry point is for
+ *   providers that may need to suspend some or all of their probes when CPUs
+ *   are being powered on or when the boot monitor is being entered for a
+ *   prolonged period of time.
+ *
+ * 1.6.2  Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register().  The
+ *   second argument is the identifier of the probe to be suspended.  The
+ *   third argument is the probe argument as passed to dtrace_probe_create().
+ *   dtps_suspend will only be called on an enabled probe.  Providers that
+ *   provide a dtps_suspend entry point will want to take roughly the action
+ *   that it takes for dtps_disable.
+ *
+ * 1.6.3  Return value
+ *
+ *   None.
+ *
+ * 1.6.4  Caller's context
+ *
+ *   Interrupts are disabled.  The DTrace framework is in a state such that the
+ *   specified probe cannot be disabled or destroyed for the duration of
+ *   dtps_suspend().  As interrupts are disabled, the provider is afforded
+ *   little latitude; the provider is expected to do no more than a store to
+ *   memory.
+ *
+ * 1.7  void dtps_resume(void *arg, dtrace_id_t id, void *parg)
+ *
+ * 1.7.1  Overview
+ *
+ *   Called to resume the specified enabled probe.  This entry point is for
+ *   providers that may need to resume some or all of their probes after the
+ *   completion of an event that induced a call to dtps_suspend().
+ *
+ * 1.7.2  Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register().  The
+ *   second argument is the identifier of the probe to be resumed.  The
+ *   third argument is the probe argument as passed to dtrace_probe_create().
+ *   dtps_resume will only be called on an enabled probe.  Providers that
+ *   provide a dtps_resume entry point will want to take roughly the action
+ *   that it takes for dtps_enable.
+ *
+ * 1.7.3  Return value
+ *
+ *   None.
+ *
+ * 1.7.4  Caller's context
+ *
+ *   Interrupts are disabled.  The DTrace framework is in a state such that the
+ *   specified probe cannot be disabled or destroyed for the duration of
+ *   dtps_resume().  As interrupts are disabled, the provider is afforded
+ *   little latitude; the provider is expected to do no more than a store to
+ *   memory.
+ *
+ * 1.8  void dtps_getargdesc(void *arg, dtrace_id_t id, void *parg,
+ *           struct dtrace_argdesc *desc)
+ *
+ * 1.8.1  Overview
+ *
+ *   Called to retrieve the argument description for an args[X] variable.
+ *
+ * 1.8.2  Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register(). The
+ *   second argument is the identifier of the current probe. The third
+ *   argument is the probe argument as passed to dtrace_probe_create(). The
+ *   fourth argument is a pointer to the argument description.  This
+ *   description is both an input and output parameter:  it contains the
+ *   index of the desired argument in the dtargd_ndx field, and expects
+ *   the other fields to be filled in upon return.  If there is no argument
+ *   corresponding to the specified index, the dtargd_ndx field should be set
+ *   to DTRACE_ARGNONE.
+ *
+ * 1.8.3  Return value
+ *
+ *   None.  The dtargd_ndx, dtargd_native, dtargd_xlate and dtargd_mapping
+ *   members of the dtrace_argdesc structure are all output values.
+ *
+ * 1.8.4  Caller's context
+ *
+ *   dtps_getargdesc() is called from ioctl() context. mod_lock is held, and
+ *   the DTrace framework is locked in such a way that providers may not
+ *   register or unregister.  This means that the provider may not call any
+ *   DTrace API that affects its registration with the framework, including
+ *   dtrace_register(), dtrace_unregister(), dtrace_invalidate(), and
+ *   dtrace_condense().
+ *
+ * 1.9  uint64_t dtps_getargval(void *arg, dtrace_id_t id, void *parg,
+ *               int argno, int aframes)
+ *
+ * 1.9.1  Overview
+ *
+ *   Called to retrieve a value for an argX or args[X] variable.
+ *
+ * 1.9.2  Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register(). The
+ *   second argument is the identifier of the current probe. The third
+ *   argument is the probe argument as passed to dtrace_probe_create(). The
+ *   fourth argument is the number of the argument (the X in the example in
+ *   1.9.1). The fifth argument is the number of stack frames that were used
+ *   to get from the actual place in the code that fired the probe to
+ *   dtrace_probe() itself, the so-called artificial frames. This argument may
+ *   be used to descend an appropriate number of frames to find the correct
+ *   values. If this entry point is left NULL, the dtrace_getarg() built-in
+ *   function is used.
+ *
+ * 1.9.3  Return value
+ *
+ *   The value of the argument.
+ *
+ * 1.9.4  Caller's context
+ *
+ *   This is called from within dtrace_probe() meaning that interrupts
+ *   are disabled. No locks should be taken within this entry point.
+ *
+ * 1.10  int dtps_usermode(void *arg, dtrace_id_t id, void *parg)
+ *
+ * 1.10.1  Overview
+ *
+ *   Called to determine if the probe was fired in a user context.
+ *
+ * 1.10.2  Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register(). The
+ *   second argument is the identifier of the current probe. The third
+ *   argument is the probe argument as passed to dtrace_probe_create().  This
+ *   entry point must not be left NULL for providers whose probes allow for
+ *   mixed mode tracing, that is to say those probes that can fire during
+ *   kernel- _or_ user-mode execution
+ *
+ * 1.10.3  Return value
+ *
+ *   A boolean value.
+ *
+ * 1.10.4  Caller's context
+ *
+ *   This is called from within dtrace_probe() meaning that interrupts
+ *   are disabled. No locks should be taken within this entry point.
+ *
+ * 1.11 void dtps_destroy(void *arg, dtrace_id_t id, void *parg)
+ *
+ * 1.11.1 Overview
+ *
+ *   Called to destroy the specified probe.
+ *
+ * 1.11.2 Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register().  The
+ *   second argument is the identifier of the probe to be destroyed.  The third
+ *   argument is the probe argument as passed to dtrace_probe_create().  The
+ *   provider should free all state associated with the probe.  The framework
+ *   guarantees that dtps_destroy() is only called for probes that have either
+ *   been disabled via dtps_disable() or were never enabled via dtps_enable().
+ *   Once dtps_disable() has been called for a probe, no further call will be
+ *   made specifying the probe.
+ *
+ * 1.11.3 Return value
+ *
+ *   None.
+ *
+ * 1.11.4 Caller's context
+ *
+ *   The DTrace framework is locked in such a way that it may not be called
+ *   back into at all.  mod_lock is held.  cpu_lock is not held, and may not be
+ *   acquired.
+ *
+ * 1.12 void dtps_destroy_module(void *arg, struct modctl *mp)
+ *
+ * 1.12.1 Overview
+ *
+ *   Called to notify provider that it can remove any per-module data.
+ *
+ * 1.12.2 Arguments and notes
+ *
+ *   The first argument is the cookie as passed to dtrace_register(). The
+ *   second argument is a pointer to a struct module structure that points to
+ *   the module for which data may be cleared.
+ *
+ * 1.12.3 Return value
+ *
+ *   None.
+ *
+ *
+ * 2 Provider-to-Framework API
+ *
+ * 2.1  Overview
+ *
+ * The Provider-to-Framework API provides the mechanism for the provider to
+ * register itself with the DTrace framework, to create probes, to lookup
+ * probes and (most importantly) to fire probes.  The Provider-to-Framework
+ * consists of:
+ *
+ *   dtrace_register()       <-- Register a provider with the DTrace framework
+ *   dtrace_unregister()     <-- Remove a provider's DTrace registration
+ *   dtrace_meta_register()  <-- Register a metaprovider with the DTrace framework
+ *   dtrace_meta_unregister()<-- Remove a metaprovider's DTrace registration
+ *   dtrace_invalidate()     <-- Invalidate the specified provider
+ *   dtrace_condense()       <-- Remove a provider's unenabled probes
+ *   dtrace_attached()       <-- Indicates whether or not DTrace has attached
+ *   dtrace_probe_create()   <-- Create a DTrace probe
+ *   dtrace_probe_lookup()   <-- Lookup a DTrace probe based on its name
+ *   dtrace_probe_arg()      <-- Return the probe argument for a specific probe
+ *   dtrace_probe()          <-- Fire the specified probe
+ *
+ * 2.2  int dtrace_register(const char *name, const struct dtrace_pattr *pap,
+ *          uint32_t priv, struct cred *cr, const struct dtrace_pops *pops,
+ *          void *arg, dtrace_provider_id_t *idp)
+ *
+ * 2.2.1  Overview
+ *
+ *   dtrace_register() registers the calling provider with the DTrace
+ *   framework.  It should generally be called by DTrace providers in their
+ *   attach(9E) entry point.
+ *
+ * 2.2.2  Arguments and Notes
+ *
+ *   The first argument is the name of the provider.  The second argument is a
+ *   pointer to the stability attributes for the provider.  The third argument
+ *   is the privilege flags for the provider, and must be some combination of:
+ *
+ *     DTRACE_PRIV_NONE     <= All users may enable probes from this provider
+ *
+ *     DTRACE_PRIV_PROC     <= Any user with privilege of PRIV_DTRACE_PROC may
+ *                             enable probes from this provider
+ *
+ *     DTRACE_PRIV_USER     <= Any user with privilege of PRIV_DTRACE_USER may
+ *                             enable probes from this provider
+ *
+ *     DTRACE_PRIV_KERNEL   <= Any user with privilege of PRIV_DTRACE_KERNEL
+ *                             may enable probes from this provider
+ *
+ *     DTRACE_PRIV_OWNER    <= This flag places an additional constraint on
+ *                             the privilege requirements above. These probes
+ *                             require either (a) a user ID matching the user
+ *                             ID of the cred passed in the fourth argument
+ *                             or (b) the PRIV_PROC_OWNER privilege.
+ *
+ *   Note that these flags designate the _visibility_ of the probes, not
+ *   the conditions under which they may or may not fire.
+ *
+ *   The fourth argument is the credential that is associated with the provider.
+ *   This argument should be NULL if the privilege flags don't include
+ *   DTRACE_PRIV_OWNER. If non-NULL, the framework stashes the uid represented
+ *   by this credential for use at probe-time, in implicit predicates. These
+ *   limit visibility of the probes to users which have sufficient privilege to
+ *   access them.
+ *
+ *   The fifth argument is a DTrace provider operations vector, which provides
+ *   the implementation for the Framework-to-Provider API.  (See Section 1,
+ *   above.)  This must be non-NULL, and each member must be non-NULL.  The
+ *   exceptions to this are (1) the dtps_provide() and dtps_provide_module()
+ *   members (if the provider so desires, _one_ of these members may be left
+ *   NULL -- denoting that the provider only implements the other) and (2)
+ *   the dtps_suspend() and dtps_resume() members, which must either both be
+ *   NULL or both be non-NULL.
+ *
+ *   The sixth argument is a cookie to be specified as the first argument for
+ *   each function in the Framework-to-Provider API.  This argument may have
+ *   any value.
+ *
+ *   The final argument is a pointer to dtrace_provider_id_t.  If
+ *   dtrace_register() successfully completes, the provider identifier will be
+ *   stored in the memory pointed to be this argument.  This argument must be
+ *   non-NULL.
+ *
+ * 2.2.3  Return value
+ *
+ *   On success, dtrace_register() returns 0 and stores the new provider's
+ *   identifier into the memory pointed to by the idp argument.  On failure,
+ *   dtrace_register() returns an errno:
+ *
+ *     EINVAL   The arguments passed to dtrace_register() were somehow invalid.
+ *              This may because a parameter that must be non-NULL was NULL,
+ *              because the name was invalid (either empty or an illegal
+ *              provider name) or because the attributes were invalid.
+ *
+ *   No other failure code is returned.
+ *
+ * 2.2.4  Caller's context
+ *
+ *   dtrace_register() may induce calls to dtrace_provide(); the provider must
+ *   hold no locks across dtrace_register() that may also be acquired by
+ *   dtrace_provide().  cpu_lock and mod_lock must not be held.
+ *
+ * 2.3  int dtrace_unregister(dtrace_provider_id_t id)
+ *
+ * 2.3.1  Overview
+ *
+ *   Unregisters the specified provider from the DTrace framework.  It should
+ *   generally be called by DTrace providers in their detach(9E) entry point.
+ *
+ * 2.3.2  Arguments and Notes
+ *
+ *   The only argument is the provider identifier, as returned from a
+ *   successful call to dtrace_register().  As a result of calling
+ *   dtrace_unregister(), the DTrace framework will call back into the provider
+ *   via the dtps_destroy() entry point.  Once dtrace_unregister() successfully
+ *   completes, however, the DTrace framework will no longer make calls through
+ *   the Framework-to-Provider API.
+ *
+ * 2.3.3  Return value
+ *
+ *   On success, dtrace_unregister returns 0.  On failure, dtrace_unregister()
+ *   returns an errno:
+ *
+ *     EBUSY    There are currently processes that have the DTrace pseudodevice
+ *              open, or there exists an anonymous enabling that hasn't yet
+ *              been claimed.
+ *
+ *   No other failure code is returned.
+ *
+ * 2.3.4  Caller's context
+ *
+ *   Because a call to dtrace_unregister() may induce calls through the
+ *   Framework-to-Provider API, the caller may not hold any lock across
+ *   dtrace_register() that is also acquired in any of the Framework-to-
+ *   Provider API functions.  Additionally, mod_lock may not be held.
+ *
+ * 2.4  void dtrace_invalidate(dtrace_provider_id_t id)
+ *
+ * 2.4.1  Overview
+ *
+ *   Invalidates the specified provider.  All subsequent probe lookups for the
+ *   specified provider will fail, but its probes will not be removed.
+ *
+ * 2.4.2  Arguments and note
+ *
+ *   The only argument is the provider identifier, as returned from a
+ *   successful call to dtrace_register().  In general, a provider's probes
+ *   always remain valid; dtrace_invalidate() is a mechanism for invalidating
+ *   an entire provider, regardless of whether or not probes are enabled or
+ *   not.  Note that dtrace_invalidate() will _not_ prevent already enabled
+ *   probes from firing -- it will merely prevent any new enablings of the
+ *   provider's probes.
+ *
+ * 2.5 int dtrace_condense(dtrace_provider_id_t id)
+ *
+ * 2.5.1  Overview
+ *
+ *   Removes all the unenabled probes for the given provider. This function is
+ *   not unlike dtrace_unregister(), except that it doesn't remove the
+ *   provider just as many of its associated probes as it can.
+ *
+ * 2.5.2  Arguments and Notes
+ *
+ *   As with dtrace_unregister(), the sole argument is the provider identifier
+ *   as returned from a successful call to dtrace_register().  As a result of
+ *   calling dtrace_condense(), the DTrace framework will call back into the
+ *   given provider's dtps_destroy() entry point for each of the provider's
+ *   unenabled probes.
+ *
+ * 2.5.3  Return value
+ *
+ *   Currently, dtrace_condense() always returns 0.  However, consumers of this
+ *   function should check the return value as appropriate; its behavior may
+ *   change in the future.
+ *
+ * 2.5.4  Caller's context
+ *
+ *   As with dtrace_unregister(), the caller may not hold any lock across
+ *   dtrace_condense() that is also acquired in the provider's entry points.
+ *   Also, mod_lock may not be held.
+ *
+ * 2.6 int dtrace_attached()
+ *
+ * 2.6.1  Overview
+ *
+ *   Indicates whether or not DTrace has attached.
+ *
+ * 2.6.2  Arguments and Notes
+ *
+ *   For most providers, DTrace makes initial contact beyond registration.
+ *   That is, once a provider has registered with DTrace, it waits to hear
+ *   from DTrace to create probes.  However, some providers may wish to
+ *   proactively create probes without first being told by DTrace to do so.
+ *   If providers wish to do this, they must first call dtrace_attached() to
+ *   determine if DTrace itself has attached.  If dtrace_attached() returns 0,
+ *   the provider must not make any other Provider-to-Framework API call.
+ *
+ * 2.6.3  Return value
+ *
+ *   dtrace_attached() returns 1 if DTrace has attached, 0 otherwise.
+ *
+ * 2.7  int dtrace_probe_create(dtrace_provider_id_t id, const char *mod,
+ *	    const char *func, const char *name, int aframes, void *arg)
+ *
+ * 2.7.1  Overview
+ *
+ *   Creates a probe with specified module name, function name, and name.
+ *
+ * 2.7.2  Arguments and Notes
+ *
+ *   The first argument is the provider identifier, as returned from a
+ *   successful call to dtrace_register().  The second, third, and fourth
+ *   arguments are the module name, function name, and probe name,
+ *   respectively.  Of these, module name and function name may both be NULL
+ *   (in which case the probe is considered to be unanchored), or they may both
+ *   be non-NULL.  The name must be non-NULL, and must point to a non-empty
+ *   string.
+ *
+ *   The fifth argument is the number of artificial stack frames that will be
+ *   found on the stack when dtrace_probe() is called for the new probe.  These
+ *   artificial frames will be automatically be pruned should the stack() or
+ *   stackdepth() functions be called as part of one of the probe's ECBs.  If
+ *   the parameter doesn't add an artificial frame, this parameter should be
+ *   zero.
+ *
+ *   The final argument is a probe argument that will be passed back to the
+ *   provider when a probe-specific operation is called.  (e.g., via
+ *   dtps_enable(), dtps_disable(), etc.)
+ *
+ *   Note that it is up to the provider to be sure that the probe that it
+ *   creates does not already exist -- if the provider is unsure of the probe's
+ *   existence, it should assure its absence with dtrace_probe_lookup() before
+ *   calling dtrace_probe_create().
+ *
+ * 2.7.3  Return value
+ *
+ *   dtrace_probe_create() always succeeds, and always returns the identifier
+ *   of the newly-created probe.
+ *
+ * 2.7.4  Caller's context
+ *
+ *   While dtrace_probe_create() is generally expected to be called from
+ *   dtps_provide() and/or dtps_provide_module(), it may be called from other
+ *   non-DTrace contexts.  Neither cpu_lock nor mod_lock may be held.
+ *
+ * 2.8  dtrace_id_t dtrace_probe_lookup(dtrace_provider_id_t id,
+ *	    const char *mod, const char *func, const char *name)
+ *
+ * 2.8.1  Overview
+ *
+ *   Looks up a probe based on provdider and one or more of module name,
+ *   function name and probe name.
+ *
+ * 2.8.2  Arguments and Notes
+ *
+ *   The first argument is the provider identifier, as returned from a
+ *   successful call to dtrace_register().  The second, third, and fourth
+ *   arguments are the module name, function name, and probe name,
+ *   respectively.  Any of these may be NULL; dtrace_probe_lookup() will return
+ *   the identifier of the first probe that is provided by the specified
+ *   provider and matches all of the non-NULL matching criteria.
+ *   dtrace_probe_lookup() is generally used by a provider to be check the
+ *   existence of a probe before creating it with dtrace_probe_create().
+ *
+ * 2.8.3  Return value
+ *
+ *   If the probe exists, returns its identifier.  If the probe does not exist,
+ *   return DTRACE_IDNONE.
+ *
+ * 2.8.4  Caller's context
+ *
+ *   While dtrace_probe_lookup() is generally expected to be called from
+ *   dtps_provide() and/or dtps_provide_module(), it may also be called from
+ *   other non-DTrace contexts.  Neither cpu_lock nor mod_lock may be held.
+ *
+ * 2.9  void *dtrace_probe_arg(dtrace_provider_id_t id, dtrace_id_t probe)
+ *
+ * 2.9.1  Overview
+ *
+ *   Returns the probe argument associated with the specified probe.
+ *
+ * 2.9.2  Arguments and Notes
+ *
+ *   The first argument is the provider identifier, as returned from a
+ *   successful call to dtrace_register().  The second argument is a probe
+ *   identifier, as returned from dtrace_probe_lookup() or
+ *   dtrace_probe_create().  This is useful if a probe has multiple
+ *   provider-specific components to it:  the provider can create the probe
+ *   once with provider-specific state, and then add to the state by looking
+ *   up the probe based on probe identifier.
+ *
+ * 2.9.3  Return value
+ *
+ *   Returns the argument associated with the specified probe.  If the
+ *   specified probe does not exist, or if the specified probe is not provided
+ *   by the specified provider, NULL is returned.
+ *
+ * 2.9.4  Caller's context
+ *
+ *   While dtrace_probe_arg() is generally expected to be called from
+ *   dtps_provide() and/or dtps_provide_module(), it may also be called from
+ *   other non-DTrace contexts.  Neither cpu_lock nor mod_lock may be held.
+ *
+ * 2.10  void dtrace_probe(dtrace_id_t probe, uintptr_t arg0, uintptr_t arg1,
+ *		uintptr_t arg2, uintptr_t arg3, uintptr_t arg4)
+ *
+ * 2.10.1  Overview
+ *
+ *   The epicenter of DTrace:  fires the specified probes with the specified
+ *   arguments.
+ *
+ * 2.10.2  Arguments and Notes
+ *
+ *   The first argument is a probe identifier as returned by
+ *   dtrace_probe_create() or dtrace_probe_lookup().  The second through sixth
+ *   arguments are the values to which the D variables "arg0" through "arg4"
+ *   will be mapped.
+ *
+ *   dtrace_probe() should be called whenever the specified probe has fired --
+ *   however the provider defines it.
+ *
+ * 2.10.3  Return value
+ *
+ *   None.
+ *
+ * 2.10.4  Caller's context
+ *
+ *   dtrace_probe() may be called in virtually any context:  kernel, user,
+ *   interrupt, high-level interrupt, with arbitrary adaptive locks held, with
+ *   dispatcher locks held, with interrupts disabled, etc.  The only latitude
+ *   that must be afforded to DTrace is the ability to make calls within
+ *   itself (and to its in-kernel subroutines) and the ability to access
+ *   arbitrary (but mapped) memory.  On some platforms, this constrains
+ *   context.  For example, on UltraSPARC, dtrace_probe() cannot be called
+ *   from any context in which TL is greater than zero.  dtrace_probe() may
+ *   also not be called from any routine which may be called by dtrace_probe()
+ *   -- which includes functions in the DTrace framework and some in-kernel
+ *   DTrace subroutines.  All such functions "dtrace_"; providers that
+ *   instrument the kernel arbitrarily should be sure to not instrument these
+ *   routines.
+ */
+
+#include <dtrace/types.h>
+#include <linux/cred.h>
+#include <linux/module.h>
+#include <linux/dtrace/enabling_defines.h>
+#include <linux/dtrace/arg_defines.h>
+#include <dtrace/provider_defines.h>
+#include <linux/dtrace/stability.h>
+
+struct dtrace_pops {
+	void (*dtps_provide)(void *, const struct dtrace_probedesc *);
+	void (*dtps_provide_module)(void *, struct module *);
+	int (*dtps_enable)(void *, dtrace_id_t, void *);
+	void (*dtps_disable)(void *, dtrace_id_t, void *);
+	void (*dtps_suspend)(void *, dtrace_id_t, void *);
+	void (*dtps_resume)(void *, dtrace_id_t, void *);
+	void (*dtps_getargdesc)(void *, dtrace_id_t, void *,
+				struct dtrace_argdesc *);
+	uint64_t (*dtps_getargval)(void *, dtrace_id_t, void *, int, int);
+	int (*dtps_usermode)(void *, dtrace_id_t, void *);
+	void (*dtps_destroy)(void *, dtrace_id_t, void *);
+	void (*dtps_destroy_module)(void *, struct module *);
+};
+
+struct dtrace_helper_probedesc {
+	char *dthpb_mod;
+	char *dthpb_func;
+	char *dthpb_name;
+	uint64_t dthpb_base;
+	uint32_t *dthpb_offs;
+	uint32_t *dthpb_enoffs;
+	uint32_t dthpb_noffs;
+	uint32_t dthpb_nenoffs;
+	uint8_t *dthpb_args;
+	uint8_t dthpb_xargc;
+	uint8_t dthpb_nargc;
+	char *dthpb_xtypes;
+	char *dthpb_ntypes;
+};
+
+struct dtrace_helper_provdesc {
+	char *dthpv_provname;
+	struct dtrace_pattr dthpv_pattr;
+};
+
+struct dtrace_mops {
+	void (*dtms_create_probe)(void *, void *,
+				  struct dtrace_helper_probedesc *);
+	void *(*dtms_provide_pid)(void *, struct dtrace_helper_provdesc *,
+				  pid_t);
+	void (*dtms_remove_pid)(void *, struct dtrace_helper_provdesc *,
+				pid_t);
+};
+
+/*
+ * DTrace Provider-to-Framework API Functions
+ */
+
+struct dtrace_meta {
+	struct dtrace_mops dtm_mops;
+	char *dtm_name;
+	void *dtm_arg;
+	uint64_t dtm_count;
+};
+
+struct dtrace_mprovider {
+	char			*dtmp_name;
+	char			*dtmp_pref;
+	struct dtrace_pattr	*dtmp_attr;
+	uint32_t		dtmp_priv;
+	struct dtrace_pops	*dtmp_pops;
+	dtrace_provider_id_t	dtmp_id;
+};
+
+struct dtrace_pmod {
+	struct module		*mod;
+	struct list_head	list;
+};
+
+extern int dtrace_register(const char *, const struct dtrace_pattr *,
+			   uint32_t, const struct cred *,
+			   const struct dtrace_pops *, void *,
+			   dtrace_provider_id_t *);
+extern int dtrace_unregister(dtrace_provider_id_t);
+extern void dtrace_invalidate(dtrace_provider_id_t);
+extern int dtrace_condense(dtrace_provider_id_t);
+extern int dtrace_attached(void);
+
+extern int dtrace_meta_register(const char *, const struct dtrace_mops *,
+				void *, dtrace_meta_provider_id_t *);
+extern int dtrace_meta_unregister(dtrace_meta_provider_id_t);
+
+extern dtrace_id_t dtrace_probe_create(dtrace_provider_id_t, const char *,
+				       const char *, const char *, int,
+				       void *);
+extern void *dtrace_probe_arg(dtrace_provider_id_t, dtrace_id_t);
+extern dtrace_id_t dtrace_probe_lookup(dtrace_provider_id_t, const char *,
+				       const char *, const char *);
+extern void dtrace_probe(dtrace_id_t, uintptr_t, uintptr_t, uintptr_t,
+			 uintptr_t, uintptr_t, uintptr_t, uintptr_t);
+
+/*
+ * Provider creation.
+ */
+#ifdef DTRACE_HAVE_PROV_EXIT
+# define DT_PROV_EXIT(name)						\
+  extern int name##_prov_exit(void);
+#else
+# define DT_PROV_EXIT(name)						\
+  static int name##_prov_exit(void)					\
+  {									\
+	return (dtrace_unregister(name##_id) == 0);			\
+  }
+#endif
+
+#define DT_PROVIDER_MODULE(name, priv)					\
+  dtrace_provider_id_t	name##_id = DTRACE_PROVNONE;			\
+									\
+  DT_PROV_EXIT(name)							\
+									\
+  static int __init name##_pinit(void)					\
+  {									\
+	int	ret = -ENOMEM;						\
+	struct dtrace_module *pdata = THIS_MODULE->pdata;		\
+									\
+	if (pdata == NULL)						\
+		goto failed;						\
+									\
+	ret = name##_dev_init();					\
+	if (ret)							\
+		goto failed;						\
+									\
+	ret = dtrace_register(__stringify(name), &name##_attr, priv,	\
+			      NULL, &name##_pops, NULL, &name##_id);	\
+	if (ret)							\
+		goto failed;						\
+									\
+	pdata->prov_exit = name##_prov_exit;				\
+									\
+	return 0;							\
+									\
+  failed:								\
+	return ret;							\
+  }									\
+									\
+  static void __exit name##_pexit(void)					\
+  {									\
+	name##_dev_exit();						\
+  }									\
+									\
+  module_init(name##_pinit);						\
+  module_exit(name##_pexit);
+
+#ifdef DTRACE_HAVE_PROV_EXIT
+# define DT_META_PROV_EXIT(name)					\
+  extern int name##_prov_exit(void);
+#else
+# define DT_META_PROV_EXIT(name)					\
+  static int name##_prov_exit(void)					\
+  {									\
+	return (dtrace_meta_unregister(name##_id) == 0);		\
+  }
+#endif
+
+#define DT_META_PROVIDER_MODULE(name)					\
+  dtrace_meta_provider_id_t	name##_id = DTRACE_METAPROVNONE;	\
+									\
+  DT_META_PROV_EXIT(name)						\
+									\
+  static int __init name##_init(void)					\
+  {									\
+	int	ret = -ENOMEM;						\
+	struct dtrace_module *pdata = THIS_MODULE->pdata;		\
+									\
+	if (pdata == NULL)						\
+		goto failed;						\
+									\
+	ret = name##_dev_init();					\
+	if (ret)							\
+		goto failed;						\
+									\
+	ret = dtrace_meta_register(__stringify(name), &name##_mops,	\
+				   NULL, &name##_id);			\
+	if (ret)							\
+		goto failed;						\
+									\
+	pdata->prov_exit = name##_prov_exit;				\
+									\
+	return 0;							\
+									\
+  failed:								\
+	return ret;							\
+  }									\
+									\
+  static void __exit name##_exit(void)					\
+  {									\
+	name##_dev_exit();						\
+  }									\
+									\
+  module_init(name##_init);						\
+  module_exit(name##_exit);
+
+#define DT_MULTI_PROVIDER_MODULE(name, plist)				\
+  static int name##_prov_exit(void)					\
+  {									\
+	int			ret = 0;				\
+	struct dtrace_mprovider	*prov;					\
+									\
+	for (prov = plist; prov->dtmp_name != NULL; prov++) {		\
+		if (prov->dtmp_id != DTRACE_PROVNONE) {			\
+			ret = dtrace_unregister(prov->dtmp_id);		\
+			if (ret != 0) {					\
+				pr_warn("Failed to unregister "		\
+					"provider %s: %d",		\
+					prov->dtmp_name, ret);		\
+				break;					\
+			}						\
+									\
+			prov->dtmp_id = DTRACE_PROVNONE;		\
+		}							\
+	}								\
+									\
+	return (ret == 0);						\
+  }									\
+									\
+  static int __init name##_init(void)					\
+  {									\
+	int			ret = -ENOMEM;				\
+	struct dtrace_mprovider	*prov;					\
+	struct dtrace_module	*pdata = THIS_MODULE->pdata;		\
+									\
+	if (pdata == NULL)						\
+		goto failed;						\
+									\
+	ret = name##_dev_init();					\
+	if (ret)							\
+		goto failed;						\
+									\
+	for (prov = plist; prov->dtmp_name != NULL; prov++) {		\
+		if (dtrace_register(prov->dtmp_name, prov->dtmp_attr,	\
+				    prov->dtmp_priv, NULL,		\
+				    prov->dtmp_pops, prov,		\
+				    &prov->dtmp_id) != 0)		\
+			pr_warn("Failed to register provider %s",	\
+				   prov->dtmp_name);			\
+	}								\
+									\
+	pdata->prov_exit = name##_prov_exit;				\
+									\
+	return 0;							\
+									\
+  failed:								\
+	return ret;							\
+  }									\
+									\
+  static void __exit name##_exit(void)					\
+  {									\
+	name##_dev_exit();						\
+  }									\
+									\
+  module_init(name##_init);						\
+  module_exit(name##_exit);
+
+
+#endif /* _DTRACE_PROVIDER_H */
diff --git a/include/dtrace/provider_defines.h b/include/dtrace/provider_defines.h
new file mode 100644
index 000000000000..104514e1261b
--- /dev/null
+++ b/include/dtrace/provider_defines.h
@@ -0,0 +1,41 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Dynamic Tracing for Linux - Provider defines
+ *
+ * Copyright (c) 2009, 2017, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _DTRACE_PROVIDER_DEFINES_H
+#define _DTRACE_PROVIDER_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/in6.h>
+
+typedef uintptr_t		dtrace_provider_id_t;
+typedef uintptr_t		dtrace_meta_provider_id_t;
+typedef __be32		ipaddr_t;
+typedef ipaddr_t	*ipaddr_t_p;
+typedef struct in6_addr	in6_addr_t;
+
+struct dtrace_pops;
+struct dtrace_helper_probedesc;
+struct dtrace_helper_provdesc;
+struct dtrace_mops;
+struct dtrace_meta;
+
+#endif /* _DTRACE_PROVIDER_DEFINES_H */
diff --git a/include/dtrace/types.h b/include/dtrace/types.h
new file mode 100644
index 000000000000..7f8d0d7efcc7
--- /dev/null
+++ b/include/dtrace/types.h
@@ -0,0 +1,131 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Dynamic Tracing for Linux - Kernel Types
+ *
+ * Copyright (c) 2009, 2017, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _DTRACE_TYPES_H
+#define _DTRACE_TYPES_H
+
+/*
+ * This file contains types needed to parse the DTrace shared userspace/ kernel
+ * headers, and a few others (it has not been gardened to remove constants used
+ * only by the DTrace core).  Userspace has its own version of these types
+ * (mostly from <unistd.h>).
+ *
+ * This file is compiled both in a normal kernel environment and in a peculiar
+ * halfway-house environment used for headers_checking of <ioctl.h>, in which
+ * among other things, no config.h symbols are available.  As a result, you
+ * should be careful about #including kernel headers here: many will break
+ * headers_check if added.  So far, it has always been sufficient to add them to
+ * dtrace/dtrace.h instead; if this turns out to be insufficient later (perhaps
+ * because DTrace core files cease to #include all of <dtrace.h>), the
+ * HEADERS_CHECK #define may prove useful to disable kernel-only portions of
+ * this file.
+ */
+
+#include <asm/bitsperlong.h>
+#include <linux/dtrace_os.h>
+
+typedef unsigned char	uchar_t;
+typedef unsigned int	uint_t;
+typedef unsigned long	ulong_t;
+
+typedef long		intptr_t;
+
+#define UINT8_MAX		(0xff)
+#define UINT8_MIN		0
+#define UINT16_MAX		(0xffff)
+#define UINT16_MIN		0
+#define UINT32_MAX		(0xffffffff)
+#define UINT32_MIN		0
+#define UINT64_MAX		(~0ULL)
+#define UINT64_MIN		(0)
+#define INT64_MAX		((long long)(~0ULL>>1))
+#define INT64_MIN		(-INT64_MAX - 1LL)
+
+#define NBBY			(__BITS_PER_LONG / sizeof(long))
+
+/*
+ * This is a bit unusual, but OpenSolaris seems to like it.  Basically, the
+ * values below are the number of time units (sec, milli, micro, nano) that
+ * comprise 1 second.  As such, it is the value of the respective multiplier.
+ */
+#define SEC			1
+#define MILLISEC		1000
+#define MICROSEC		1000000
+#define NANOSEC			1000000000
+
+typedef enum {
+	TRUE = -1,
+	FALSE = 0
+} boolean_t;
+
+
+#define DTRACE_ACCESS_KERNEL	0x1
+
+#define DTRACE_CRA_PROC				0x0001
+#define DTRACE_CRA_PROC_CONTROL			0x0002
+#define DTRACE_CRA_PROC_DESTRUCTIVE_ALLUSER	0x0004
+#define DTRACE_CRA_PROC_DESTRUCTIVE_CREDCHG	0x0010
+#define DTRACE_CRA_KERNEL			0x0020
+#define DTRACE_CRA_KERNEL_DESTRUCTIVE		0x0040
+
+#define DTRACE_CRA_ALL		(DTRACE_CRA_PROC | \
+				 DTRACE_CRA_PROC_CONTROL | \
+				 DTRACE_CRA_PROC_DESTRUCTIVE_ALLUSER | \
+				 DTRACE_CRA_PROC_DESTRUCTIVE_CREDCHG | \
+				 DTRACE_CRA_KERNEL | \
+				 DTRACE_CRA_KERNEL_DESTRUCTIVE)
+
+#define DTRACE_CRV_ALLPROC	0x01
+#define DTRACE_CRV_KERNEL	0x02
+#define DTRACE_CRV_ALL		(DTRACE_CRV_ALLPROC | DTRACE_CRV_KERNEL)
+
+#define DTRACE_MATCH_FAIL	-1
+#define DTRACE_MATCH_NEXT	0
+#define DTRACE_MATCH_DONE	1
+
+#define DTRACE_COND_OWNER	0x01
+#define DTRACE_COND_USERMODE	0x02
+
+#define P2ROUNDUP(x, a)	(-(-(x) & -(a)))
+
+#if (BITS_PER_LONG == 64) || defined(CONFIG_KTIME_SCALAR)
+#define KTIME_INIT(s, ns)	((s64)(s) * NSEC_PER_SEC + (s64)(ns))
+#else
+# define KTIME_INIT(n, ns)	{ .sec = (s), .nsec = (ns) }
+#endif
+#define ktime_lt(t0, t1)	(t0 < t1)
+#define ktime_le(t0, t1)	(t0 <= t1)
+#define ktime_ge(t0, t1)	(t0 >= t1)
+#define ktime_gt(t0, t1)	(t0 > t1)
+#define ktime_cp(t0, t1)	(t0 = t1)
+
+/*
+ * Translate between kernel config options and userspace-compatible definitions.
+ */
+#ifdef CONFIG_64BIT
+#define _LP64 1
+#endif
+#ifdef __LITTLE_ENDIAN
+#define _LITTLE_ENDIAN 1
+#endif
+
+#endif /* _DTRACE_TYPES_H */
diff --git a/include/linux/cpuhotplug.h b/include/linux/cpuhotplug.h
index 0042ef362511..9dfdd725a773 100644
--- a/include/linux/cpuhotplug.h
+++ b/include/linux/cpuhotplug.h
@@ -107,6 +107,7 @@ enum cpuhp_state {
 	CPUHP_AP_IRQ_SIFIVE_PLIC_STARTING,
 	CPUHP_AP_ARM_MVEBU_COHERENCY,
 	CPUHP_AP_MICROCODE_LOADER,
+	CPUHP_AP_CYCLIC_STARTING,
 	CPUHP_AP_PERF_X86_AMD_UNCORE_STARTING,
 	CPUHP_AP_PERF_X86_STARTING,
 	CPUHP_AP_PERF_X86_AMD_IBS_STARTING,
diff --git a/include/linux/cyclic.h b/include/linux/cyclic.h
new file mode 100644
index 000000000000..12ab85dc185b
--- /dev/null
+++ b/include/linux/cyclic.h
@@ -0,0 +1,49 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2010, 2017, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _CYCLIC_H_
+#define _CYCLIC_H_
+
+#include <linux/ktime.h>
+#include <linux/types.h>
+
+#define CY_LOW_LEVEL	0
+#define CY_LOCK_LEVEL	1
+#define CY_HIGH_LEVEL	2
+#define CY_SOFT_LEVELS	2
+#define CY_LEVELS	3
+
+typedef uintptr_t	cyclic_id_t;
+typedef uint16_t	cyc_level_t;
+typedef void		(*cyc_func_t)(uintptr_t);
+
+#define CYCLIC_NONE	((cyclic_id_t)0)
+
+struct cyc_handler {
+	cyc_func_t cyh_func;
+	uintptr_t cyh_arg;
+	cyc_level_t cyh_level;
+};
+
+#define CY_INTERVAL_INF (-1)
+
+struct cyc_time {
+	ktime_t cyt_when;
+	ktime_t cyt_interval;
+};
+
+struct cyc_omni_handler {
+	void (*cyo_online)(void *, uint32_t, struct cyc_handler *,
+			   struct cyc_time *);
+	void (*cyo_offline)(void *, uint32_t, void *);
+	void *cyo_arg;
+};
+
+extern cyclic_id_t cyclic_add(struct cyc_handler *, struct cyc_time *);
+extern cyclic_id_t cyclic_add_omni(struct cyc_omni_handler *);
+extern void cyclic_remove(cyclic_id_t);
+extern void cyclic_reprogram(cyclic_id_t, ktime_t);
+
+#endif /* _CYCLIC_H_ */
diff --git a/include/linux/dtrace/cpu_defines.h b/include/linux/dtrace/cpu_defines.h
new file mode 100644
index 000000000000..c8719378da80
--- /dev/null
+++ b/include/linux/dtrace/cpu_defines.h
@@ -0,0 +1,61 @@
+/* Copyright (C) 2011-2014 Oracle, Inc. */
+
+#ifndef _LINUX_DTRACE_CPU_DEFINES_H_
+#define _LINUX_DTRACE_CPU_DEFINES_H_
+
+#include <linux/percpu.h>
+
+#define	CPUC_SIZE	(sizeof (uint16_t) + sizeof(uint8_t) + \
+			 sizeof(uintptr_t) + sizeof(struct mutex))
+#define CPUC_PADSIZE	(192 - CPUC_SIZE)
+
+#define per_cpu_core(cpu)	(&per_cpu(dtrace_cpu_core, (cpu)))
+#if 0
+# define this_cpu_core		(this_cpu_ptr(&dtrace_cpu_core))
+#else
+# define this_cpu_core		(per_cpu_core(smp_processor_id()))
+#endif
+
+#define DTRACE_CPUFLAG_ISSET(flag) \
+	(this_cpu_core->cpuc_dtrace_flags & (flag))
+
+#define DTRACE_CPUFLAG_SET(flag) \
+	(this_cpu_core->cpuc_dtrace_flags |= (flag))
+
+#define DTRACE_CPUFLAG_CLEAR(flag) \
+	(this_cpu_core->cpuc_dtrace_flags &= ~(flag))
+
+#define CPU_DTRACE_NOFAULT	0x0001
+#define CPU_DTRACE_DROP		0x0002
+#define CPU_DTRACE_BADADDR	0x0004
+#define CPU_DTRACE_BADALIGN	0x0008
+#define CPU_DTRACE_DIVZERO	0x0010
+#define CPU_DTRACE_ILLOP	0x0020
+#define CPU_DTRACE_NOSCRATCH	0x0040
+#define CPU_DTRACE_KPRIV	0x0080
+#define CPU_DTRACE_UPRIV	0x0100
+#define CPU_DTRACE_TUPOFLOW	0x0200
+#define CPU_DTRACE_ENTRY	0x0800
+#define CPU_DTRACE_BADSTACK	0x1000
+#define CPU_DTRACE_NOPF		0x2000
+#define CPU_DTRACE_PF_TRAPPED	0x4000
+
+#define CPU_DTRACE_FAULT	(CPU_DTRACE_BADADDR | CPU_DTRACE_BADALIGN | \
+				 CPU_DTRACE_DIVZERO | CPU_DTRACE_ILLOP | \
+				 CPU_DTRACE_NOSCRATCH | CPU_DTRACE_KPRIV | \
+				 CPU_DTRACE_UPRIV | CPU_DTRACE_TUPOFLOW | \
+				 CPU_DTRACE_BADSTACK | CPU_DTRACE_PF_TRAPPED)
+#define CPU_DTRACE_ERROR	(CPU_DTRACE_FAULT | CPU_DTRACE_DROP)
+
+typedef uint32_t	processorid_t;
+typedef uint32_t	psetid_t;
+typedef uint32_t	chipid_t;
+typedef uint32_t	lgrp_id_t;
+
+struct cpu_core;
+struct cpuinfo;
+
+#define per_cpu_info(cpu)	(&per_cpu(dtrace_cpu_info, (cpu)))
+#define this_cpu_info		(this_cpu_ptr(&dtrace_cpu_info))
+
+#endif /* _LINUX_DTRACE_CPU_DEFINES_H_ */
diff --git a/include/linux/dtrace_cpu.h b/include/linux/dtrace_cpu.h
new file mode 100644
index 000000000000..6b3dc7219f49
--- /dev/null
+++ b/include/linux/dtrace_cpu.h
@@ -0,0 +1,53 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2004, 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_CPU_H_
+#define _LINUX_DTRACE_CPU_H_
+
+#ifdef CONFIG_DTRACE
+
+#include <linux/ktime.h>
+#include <linux/mutex.h>
+#include <linux/spinlock.h>
+#include <linux/dtrace_types.h>
+#include <linux/dtrace_cpu_defines.h>
+#include <asm/dtrace_cpuinfo.h>
+
+struct cpu_core {
+	uint16_t	cpuc_dtrace_flags;
+	uint8_t		cpuc_dcpc_intr_state;
+	uint8_t		cpuc_pad[CPUC_PADSIZE];
+	uintptr_t	cpuc_dtrace_illval;
+	struct mutex	cpuc_pid_lock;
+
+	uintptr_t	cpu_dtrace_caller;
+	struct pt_regs	*cpu_dtrace_regs;
+	ktime_t		cpu_dtrace_chillmark;
+	ktime_t		cpu_dtrace_chilled;
+	rwlock_t	cpu_ft_lock;
+	atomic64_t	cpuc_sync_requests;
+	atomic64_t	cpuc_in_probe_ctx;
+	dtrace_id_t	cpuc_current_probe;
+};
+
+DECLARE_PER_CPU_SHARED_ALIGNED(struct cpu_core, dtrace_cpu_core);
+
+struct cpuinfo {
+	processorid_t	cpu_id;
+	psetid_t	cpu_pset;
+	chipid_t	cpu_chip;
+	lgrp_id_t	cpu_lgrp;
+	cpuinfo_arch_t	*cpu_info;
+};
+
+DECLARE_PER_CPU_SHARED_ALIGNED(struct cpuinfo, dtrace_cpu_info);
+
+/* ABI requirement: type names compiled into DTrace userspace.  */
+typedef struct cpuinfo cpuinfo_t;
+
+extern void dtrace_cpu_init(void);
+
+#endif /* CONFIG_DTRACE */
+#endif /* _LINUX_DTRACE_CPU_H_ */
diff --git a/include/linux/dtrace_cpu_defines.h b/include/linux/dtrace_cpu_defines.h
new file mode 100644
index 000000000000..f5866a6e95b8
--- /dev/null
+++ b/include/linux/dtrace_cpu_defines.h
@@ -0,0 +1,2 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+#include <linux/dtrace/cpu_defines.h>
diff --git a/include/linux/dtrace_os.h b/include/linux/dtrace_os.h
new file mode 100644
index 000000000000..5bcd77e08a14
--- /dev/null
+++ b/include/linux/dtrace_os.h
@@ -0,0 +1,120 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2011, 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_OS_H_
+#define _LINUX_DTRACE_OS_H_
+
+#ifndef HEADERS_CHECK
+
+#ifdef CONFIG_DTRACE
+
+#include <linux/ktime.h>
+#include <linux/mm.h>
+#include <linux/notifier.h>
+#include <linux/timekeeper_internal.h>
+#include <asm/unistd.h>
+#include <linux/dtrace_cpu.h>
+#include <linux/dtrace_task.h>
+#include <linux/dtrace_psinfo.h>
+
+extern struct module	*dtrace_kmod;
+
+extern void __init dtrace_os_init(void);
+extern void __init dtrace_psinfo_os_init(void);
+extern void __init dtrace_task_os_init(void);
+
+extern void dtrace_mod_pdata_alloc(struct module *);
+extern void dtrace_mod_pdata_free(struct module *);
+extern int dtrace_destroy_prov(struct module *);
+
+extern int dtrace_enable(void);
+extern void dtrace_disable(void);
+
+extern ktime_t dtrace_gethrtime(void);
+extern ktime_t dtrace_getwalltime(void);
+
+enum dtrace_vtime_state {
+	DTRACE_VTIME_INACTIVE = 0,
+	DTRACE_VTIME_ACTIVE
+};
+
+extern enum dtrace_vtime_state dtrace_vtime_active;
+
+typedef void for_each_module_fn(void *, struct module *);
+extern void dtrace_for_each_module(for_each_module_fn *fn, void *arg);
+
+extern void dtrace_update_time(struct timekeeper *);
+extern ktime_t dtrace_get_walltime(void);
+
+extern void dtrace_vtime_enable(void);
+extern void dtrace_vtime_disable(void);
+extern void dtrace_vtime_switch(struct task_struct *, struct task_struct *);
+
+#include <asm/dtrace_util.h>
+
+extern int dtrace_instr_size(const asm_instr_t *);
+
+extern int dtrace_die_notifier(struct notifier_block *, unsigned long, void *);
+
+#define STACKTRACE_KERNEL	0x01
+#define STACKTRACE_USER		0x02
+#define STACKTRACE_TYPE		0x0f
+
+struct stacktrace_state {
+	uint64_t	*pcs;
+	uint64_t	*fps;
+	int		limit;
+	int		depth;
+	int		flags;
+};
+
+extern void dtrace_stacktrace(struct stacktrace_state *);
+extern void dtrace_user_stacktrace(struct stacktrace_state *);
+extern void dtrace_handle_badaddr(struct pt_regs *);
+extern void dtrace_mod_pdata_init(struct dtrace_module *pdata);
+extern void dtrace_mod_pdata_cleanup(struct dtrace_module *pdata);
+
+/*
+ * This is only safe to call if we know this is a userspace fault
+ * or that the call happens after early boot.
+ */
+static inline int dtrace_no_pf(struct pt_regs *regs)
+{
+	if (unlikely(DTRACE_CPUFLAG_ISSET(CPU_DTRACE_NOFAULT))) {
+		dtrace_handle_badaddr(regs);
+		return 1;
+	}
+
+	return 0;
+}
+
+extern void (*dtrace_helpers_cleanup)(struct task_struct *);
+extern void (*dtrace_helpers_fork)(struct task_struct *, struct task_struct *);
+
+#else
+
+/*
+ * See arch/x86/mm/fault.c.
+ */
+
+#define dtrace_no_pf(ignore) 0
+
+/*
+ * See kernel/timekeeper.c
+ */
+#define	dtrace_update_time(ignore)
+
+/*
+ * See kernel/dtrace/dtrace_os.c
+ */
+#define dtrace_mod_pdata_alloc(ignore)
+#define dtrace_mod_pdata_free(ignore)
+#define dtrace_destroy_prov(ignore) 1
+
+#endif /* CONFIG_DTRACE */
+
+#endif /* !HEADERS_CHECK */
+
+#endif /* _LINUX_DTRACE_OS_H_ */
diff --git a/include/linux/dtrace_psinfo.h b/include/linux/dtrace_psinfo.h
new file mode 100644
index 000000000000..53a9c317a8a3
--- /dev/null
+++ b/include/linux/dtrace_psinfo.h
@@ -0,0 +1,59 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2011, 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_PSINFO_H_
+#define _LINUX_DTRACE_PSINFO_H_
+
+#ifdef CONFIG_DTRACE
+
+#define PR_PSARGS_SZ		80
+#define PR_ARGV_SZ		512
+#define PR_ENVP_SZ		512
+
+/*
+ * DTrace's per-process info (per-tgid).
+ *
+ * All threads in a process share the same structure instance.
+ */
+struct dtrace_psinfo {
+	atomic_t	dtps_usage;
+	unsigned long	dtps_argc;
+	char		**dtps_argv;
+	unsigned long	dtps_envc;
+	char		**dtps_envp;
+	char		dtps_psargs[PR_PSARGS_SZ];
+};
+
+/*
+ * DTrace psinfo API. Requires struct dtrace_task as its argument.
+ */
+
+extern void dtrace_psinfo_alloc(struct task_struct *);
+extern void dtrace_psinfo_free(struct dtrace_psinfo *);
+
+static inline void dtrace_psinfo_get(struct dtrace_psinfo *psinfo)
+{
+	if (likely(psinfo))
+		atomic_inc(&(psinfo)->dtps_usage);
+}
+
+static inline void dtrace_psinfo_put(struct dtrace_psinfo *psinfo)
+{
+	if (likely((psinfo))) {
+		if (atomic_dec_and_test(&(psinfo)->dtps_usage))
+			dtrace_psinfo_free(psinfo);
+	}
+}
+
+#else /* CONFIG_DTRACE */
+
+#define dtrace_psinfo_alloc(ignore)
+#define dtrace_psinfo_free(ignore)
+#define dtrace_psinfo_get(ignore)
+#define dtrace_psinfo_put(ignore)
+
+#endif /* CONFIG_DTRACE */
+
+#endif /* _LINUX_DTRACE_PSINFO_H_ */
diff --git a/include/linux/dtrace_task.h b/include/linux/dtrace_task.h
new file mode 100644
index 000000000000..ce7111223788
--- /dev/null
+++ b/include/linux/dtrace_task.h
@@ -0,0 +1,38 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_TASK_H_
+#define _LINUX_DTRACE_TASK_H_
+
+#ifdef CONFIG_DTRACE
+
+#include <linux/sched.h>
+
+/*
+ * Opaque handle for per-task data.
+ */
+struct dtrace_task;
+
+/*
+ * DTrace's kernel API for per-task data manipulation.
+ */
+
+extern void dtrace_task_init(struct task_struct *);
+extern void dtrace_task_exec(struct task_struct *);
+extern void dtrace_task_copy(struct task_struct *, struct task_struct *);
+extern void dtrace_task_free(struct task_struct *);
+extern void dtrace_task_dup(struct task_struct *, struct task_struct *);
+
+#else /* CONFIG_DTRACE */
+
+#define	dtrace_task_init(ignore)
+#define	dtrace_task_exec(ignore)
+#define	dtrace_task_copy(ignore1, ignore2)
+#define	dtrace_task_free(ignore)
+#define	dtrace_task_dup(ignore1, ignore2)
+
+#endif /* CONFIG_DTRACE */
+
+#endif /* _LINUX_DTRACE_TASK_H_ */
diff --git a/include/linux/dtrace_task_impl.h b/include/linux/dtrace_task_impl.h
new file mode 100644
index 000000000000..2f76b475c2f8
--- /dev/null
+++ b/include/linux/dtrace_task_impl.h
@@ -0,0 +1,28 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+#ifndef	_LINUX_DTRACE_TASK_IMPL_H_
+#define _LINUX_DTRACE_TASK_IMPL_H_
+
+#ifdef CONFIG_DTRACE
+
+#include <linux/dtrace_task.h>
+#include <linux/dtrace_psinfo.h>
+
+struct dtrace_task {
+	uint32_t	dt_predcache;
+	ktime_t		dt_vtime;
+	ktime_t		dt_start;
+	uint8_t		dt_stop;
+	uint8_t		dt_sig;
+	struct dtrace_psinfo	*dt_psinfo;
+	void		*dt_helpers;
+	uint32_t	dt_probes;
+	uint64_t	dt_tp_count;
+	void		*dt_ustack;
+};
+
+#endif /* CONFIG_DTRACE */
+#endif /* _LINUX_DTRACE_TASK_IMPL_H_ */
+
diff --git a/include/linux/dtrace_types.h b/include/linux/dtrace_types.h
new file mode 100644
index 000000000000..4484dc58e188
--- /dev/null
+++ b/include/linux/dtrace_types.h
@@ -0,0 +1,13 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _DTRACE_TYPES_H_
+#define _DTRACE_TYPES_H_
+
+typedef uint32_t dtrace_id_t;
+
+#define	DTRACE_IDNONE	0
+
+#endif /* _DTRACE_TYPES_H_ */
diff --git a/include/linux/ktime.h b/include/linux/ktime.h
index 73f20deb497d..a0395de55fcb 100644
--- a/include/linux/ktime.h
+++ b/include/linux/ktime.h
@@ -156,6 +156,14 @@ static inline s64 ktime_divns(const ktime_t kt, s64 div)
 }
 #endif
 
+/*
+ * ktime_nz - Check whether a ktime_v variable is non-zero
+ */
+static inline int ktime_nz(const ktime_t kt)
+{
+	return kt != 0LL;
+}
+
 static inline s64 ktime_to_us(const ktime_t kt)
 {
 	return ktime_divns(kt, NSEC_PER_USEC);
diff --git a/include/linux/module.h b/include/linux/module.h
index 566bd262a06e..54aca4dac0c1 100644
--- a/include/linux/module.h
+++ b/include/linux/module.h
@@ -516,6 +516,9 @@ struct module {
 	struct klp_modinfo *klp_info;
 #endif
 
+#ifdef CONFIG_DTRACE
+	void *pdata;
+#endif
 #ifdef CONFIG_MODULE_UNLOAD
 	/* What modules depend on me? */
 	struct list_head source_list;
diff --git a/include/linux/mutex.h b/include/linux/mutex.h
index 4d671fba3cab..55eeaeebb04b 100644
--- a/include/linux/mutex.h
+++ b/include/linux/mutex.h
@@ -20,6 +20,10 @@
 #include <linux/osq_lock.h>
 #include <linux/debug_locks.h>
 
+#ifdef CONFIG_SMP
+# include <asm/current.h>
+#endif
+
 struct ww_acquire_ctx;
 
 /*
@@ -224,4 +228,16 @@ enum mutex_trylock_recursive_enum {
 extern /* __deprecated */ __must_check enum mutex_trylock_recursive_enum
 mutex_trylock_recursive(struct mutex *lock);
 
+#if defined(CONFIG_DEBUG_MUTEXES) || defined(CONFIG_SMP)
+static inline int mutex_owned(struct mutex *lock)
+{
+	return mutex_is_locked(lock) && __mutex_owner(lock) == current;
+}
+#else
+static inline int mutex_owned(struct mutex *lock)
+{
+	return mutex_is_locked(lock);
+}
+#endif
+
 #endif /* __LINUX_MUTEX_H */
diff --git a/include/linux/rwlock.h b/include/linux/rwlock.h
index 3dcd617e65ae..a7e72774f17e 100644
--- a/include/linux/rwlock.h
+++ b/include/linux/rwlock.h
@@ -59,6 +59,13 @@ do {								\
 # define do_raw_write_unlock(rwlock)	do {arch_write_unlock(&(rwlock)->raw_lock); __release(lock); } while (0)
 #endif
 
+#ifdef CONFIG_DTRACE
+#define peek_read_can_lock(rwlock) \
+	arch_peek_read_can_lock(&(rwlock)->raw_lock)
+#define peek_write_can_lock(rwlock) \
+	arch_peek_write_can_lock(&(rwlock)->raw_lock)
+#endif /* CONFIG_DTRACE */
+
 /*
  * Define the various rw_lock methods.  Note we define these
  * regardless of whether CONFIG_SMP or CONFIG_PREEMPT are set. The various
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 6e3a5eeec509..c5a3af98dd05 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -36,6 +36,7 @@
 #include <linux/seqlock.h>
 #include <linux/kcsan.h>
 #include <asm/kmap_size.h>
+#include <linux/dtrace_task.h>
 
 /* task_struct member predeclarations (sorted alphabetically): */
 struct audit_context;
@@ -1319,6 +1320,9 @@ struct task_struct {
 	struct request_queue		*throttle_queue;
 #endif
 
+#ifdef CONFIG_DTRACE
+	struct dtrace_task		*dt_task;
+#endif
 #ifdef CONFIG_UPROBES
 	struct uprobe_task		*utask;
 #endif
diff --git a/include/linux/spinlock_up.h b/include/linux/spinlock_up.h
index 0ac9112c1bbe..cfd00c13f2aa 100644
--- a/include/linux/spinlock_up.h
+++ b/include/linux/spinlock_up.h
@@ -69,4 +69,9 @@ static inline void arch_spin_unlock(arch_spinlock_t *lock)
 
 #define arch_spin_is_contended(lock)	(((void)(lock), 0))
 
+#ifdef CONFIG_DTRACE
+#define arch_peek_read_can_lock(lock)	(((void)(lock), 1))
+#define arch_peek_write_can_lock(lock)	(((void)(lock), 1))
+#endif /* CONFIG_DTRACE */
+
 #endif /* __LINUX_SPINLOCK_UP_H */
diff --git a/include/uapi/linux/dtrace/Kbuild b/include/uapi/linux/dtrace/Kbuild
new file mode 100644
index 000000000000..0cb5b941b72b
--- /dev/null
+++ b/include/uapi/linux/dtrace/Kbuild
@@ -0,0 +1,35 @@
+# UAPI Header export list
+header-y += actions_defines.h
+header-y += actions.h
+header-y += arg_defines.h
+header-y += arg.h
+header-y += buffer_defines.h
+header-y += buffer.h
+header-y += conf_defines.h
+header-y += conf.h
+header-y += cpu_defines.h
+header-y += dif_defines.h
+header-y += dif.h
+header-y += difo_defines.h
+header-y += difo.h
+header-y += dof_defines.h
+header-y += dof.h
+header-y += dtrace.h
+header-y += enabling_defines.h
+header-y += enabling.h
+header-y += fasttrap_defines.h
+header-y += fasttrap.h
+header-y += fasttrap_ioctl.h
+header-y += faults_defines.h
+header-y += faults.h
+header-y += helpers_defines.h
+header-y += helpers.h
+header-y += ioctl.h
+header-y += metadesc_defines.h
+header-y += metadesc.h
+header-y += options_defines.h
+header-y += options.h
+header-y += stability_defines.h
+header-y += stability.h
+header-y += status.h
+header-y += universal.h
diff --git a/include/uapi/linux/dtrace/actions.h b/include/uapi/linux/dtrace/actions.h
new file mode 100644
index 000000000000..9b47343271ba
--- /dev/null
+++ b/include/uapi/linux/dtrace/actions.h
@@ -0,0 +1,14 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_ACTIONS_H
+#define _LINUX_DTRACE_ACTIONS_H
+
+#include <linux/dtrace/actions_defines.h>
+
+#endif /* _LINUX_DTRACE_ACTIONS_H */
diff --git a/include/uapi/linux/dtrace/actions_defines.h b/include/uapi/linux/dtrace/actions_defines.h
new file mode 100644
index 000000000000..4512c291f58a
--- /dev/null
+++ b/include/uapi/linux/dtrace/actions_defines.h
@@ -0,0 +1,181 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_ACTIONS_DEFINES_H
+#define _LINUX_DTRACE_ACTIONS_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+/*
+ * The upper byte determines the class of the action; the low bytes determines
+ * the specific action within that class.  The classes of actions are as
+ * follows:
+ *
+ *   [ no class ]                  <= May record process- or kernel-related data
+ *   DTRACEACT_PROC                <= Only records process-related data
+ *   DTRACEACT_PROC_DESTRUCTIVE    <= Potentially destructive to processes
+ *   DTRACEACT_KERNEL              <= Only records kernel-related data
+ *   DTRACEACT_KERNEL_DESTRUCTIVE  <= Potentially destructive to the kernel
+ *   DTRACEACT_SPECULATIVE         <= Speculation-related action
+ *   DTRACEACT_AGGREGATION         <= Aggregating action
+ */
+#define	DTRACEACT_NONE			0	/* no action */
+#define	DTRACEACT_DIFEXPR		1	/* action is DIF expression */
+#define	DTRACEACT_EXIT			2	/* exit() action */
+#define	DTRACEACT_PRINTF		3	/* printf() action */
+#define	DTRACEACT_PRINTA		4	/* printa() action */
+#define	DTRACEACT_LIBACT		5	/* library-controlled action */
+#define	DTRACEACT_TRACEMEM		6	/* tracemem() action */
+#define	DTRACEACT_PCAP			7	/* pcap() action */
+
+#define DTRACEACT_PROC			0x0100
+#define DTRACEACT_USTACK		(DTRACEACT_PROC + 1)
+#define DTRACEACT_JSTACK		(DTRACEACT_PROC + 2)
+#define DTRACEACT_USYM			(DTRACEACT_PROC + 3)
+#define DTRACEACT_UMOD			(DTRACEACT_PROC + 4)
+#define DTRACEACT_UADDR			(DTRACEACT_PROC + 5)
+
+#define DTRACEACT_PROC_DESTRUCTIVE	0x0200
+#define DTRACEACT_STOP			(DTRACEACT_PROC_DESTRUCTIVE + 1)
+#define DTRACEACT_RAISE			(DTRACEACT_PROC_DESTRUCTIVE + 2)
+#define DTRACEACT_SYSTEM		(DTRACEACT_PROC_DESTRUCTIVE + 3)
+#define DTRACEACT_FREOPEN		(DTRACEACT_PROC_DESTRUCTIVE + 4)
+
+#define DTRACEACT_PROC_CONTROL		0x0300
+
+#define DTRACEACT_KERNEL		0x0400
+#define DTRACEACT_STACK			(DTRACEACT_KERNEL + 1)
+#define DTRACEACT_SYM			(DTRACEACT_KERNEL + 2)
+#define DTRACEACT_MOD			(DTRACEACT_KERNEL + 3)
+
+#define DTRACEACT_KERNEL_DESTRUCTIVE	0x0500
+#define DTRACEACT_BREAKPOINT		(DTRACEACT_KERNEL_DESTRUCTIVE + 1)
+#define DTRACEACT_PANIC			(DTRACEACT_KERNEL_DESTRUCTIVE + 2)
+#define DTRACEACT_CHILL			(DTRACEACT_KERNEL_DESTRUCTIVE + 3)
+
+#define DTRACEACT_SPECULATIVE           0x0600
+#define DTRACEACT_SPECULATE		(DTRACEACT_SPECULATIVE + 1)
+#define DTRACEACT_COMMIT		(DTRACEACT_SPECULATIVE + 2)
+#define DTRACEACT_DISCARD		(DTRACEACT_SPECULATIVE + 3)
+
+#define DTRACEACT_CLASS(x)		((x) & 0xff00)
+
+#define DTRACEACT_ISAGG(x)		\
+		(DTRACEACT_CLASS(x) == DTRACEACT_AGGREGATION)
+
+#define DTRACEACT_ISDESTRUCTIVE(x)	\
+		(DTRACEACT_CLASS(x) == DTRACEACT_PROC_DESTRUCTIVE || \
+		 DTRACEACT_CLASS(x) == DTRACEACT_KERNEL_DESTRUCTIVE)
+
+#define DTRACEACT_ISSPECULATIVE(x)	\
+		(DTRACEACT_CLASS(x) == DTRACEACT_SPECULATIVE)
+
+#define DTRACEACT_ISPRINTFLIKE(x)	\
+		((x) == DTRACEACT_PRINTF || (x) == DTRACEACT_PRINTA || \
+		 (x) == DTRACEACT_SYSTEM || (x) == DTRACEACT_FREOPEN)
+
+/*
+ * DTrace Aggregating Actions
+ *
+ * These are functions f(x) for which the following is true:
+ *
+ *    f(f(x_0) U f(x_1) U ... U f(x_n)) = f(x_0 U x_1 U ... U x_n)
+ *
+ * where x_n is a set of arbitrary data.  Aggregating actions are in their own
+ * DTrace action class, DTTRACEACT_AGGREGATION.  The macros provided here allow
+ * for easier processing of the aggregation argument and data payload for a few
+ * aggregating actions (notably:  quantize(), lquantize(), and ustack()).
+ */
+
+#define DTRACEACT_AGGREGATION		0x0700
+#define DTRACEAGG_COUNT			(DTRACEACT_AGGREGATION + 1)
+#define DTRACEAGG_MIN			(DTRACEACT_AGGREGATION + 2)
+#define DTRACEAGG_MAX			(DTRACEACT_AGGREGATION + 3)
+#define DTRACEAGG_AVG			(DTRACEACT_AGGREGATION + 4)
+#define DTRACEAGG_SUM			(DTRACEACT_AGGREGATION + 5)
+#define DTRACEAGG_STDDEV		(DTRACEACT_AGGREGATION + 6)
+#define DTRACEAGG_QUANTIZE		(DTRACEACT_AGGREGATION + 7)
+#define DTRACEAGG_LQUANTIZE		(DTRACEACT_AGGREGATION + 8)
+#define DTRACEAGG_LLQUANTIZE		(DTRACEACT_AGGREGATION + 9)
+
+#define DTRACE_QUANTIZE_NBUCKETS		\
+		(((sizeof(uint64_t) * NBBY) - 1) * 2 + 1)
+
+#define DTRACE_QUANTIZE_ZEROBUCKET	((sizeof(uint64_t) * NBBY) - 1)
+
+#define DTRACE_QUANTIZE_BUCKETVAL(buck)		\
+	(int64_t)((buck) < DTRACE_QUANTIZE_ZEROBUCKET ? \
+		  -(1LL << (DTRACE_QUANTIZE_ZEROBUCKET - 1 - (buck))) : \
+		  (buck) == DTRACE_QUANTIZE_ZEROBUCKET ? 0 : \
+		  1LL << ((buck) - DTRACE_QUANTIZE_ZEROBUCKET - 1))
+
+#define DTRACE_LQUANTIZE_STEPSHIFT	48
+#define DTRACE_LQUANTIZE_STEPMASK	((uint64_t)UINT16_MAX << 48)
+#define DTRACE_LQUANTIZE_LEVELSHIFT	32
+#define DTRACE_LQUANTIZE_LEVELMASK	((uint64_t)UINT16_MAX << 32)
+#define DTRACE_LQUANTIZE_BASESHIFT	0
+#define DTRACE_LQUANTIZE_BASEMASK	UINT32_MAX
+
+#define DTRACE_LQUANTIZE_STEP(x)		\
+		(uint16_t)(((x) & DTRACE_LQUANTIZE_STEPMASK) >> \
+			   DTRACE_LQUANTIZE_STEPSHIFT)
+
+#define DTRACE_LQUANTIZE_LEVELS(x)		\
+		(uint16_t)(((x) & DTRACE_LQUANTIZE_LEVELMASK) >> \
+			   DTRACE_LQUANTIZE_LEVELSHIFT)
+
+#define DTRACE_LQUANTIZE_BASE(x)		\
+		(int32_t)(((x) & DTRACE_LQUANTIZE_BASEMASK) >> \
+			  DTRACE_LQUANTIZE_BASESHIFT)
+
+#define DTRACE_LLQUANTIZE_STEPSSHIFT	48
+#define DTRACE_LLQUANTIZE_STEPSMASK	((uint64_t)UINT16_MAX << 48)
+#define DTRACE_LLQUANTIZE_HMAGSHIFT	32
+#define DTRACE_LLQUANTIZE_HMAGMASK	((uint64_t)UINT16_MAX << 32)
+#define DTRACE_LLQUANTIZE_LMAGSHIFT	16
+#define DTRACE_LLQUANTIZE_LMAGMASK	((uint64_t)UINT16_MAX << 16)
+#define DTRACE_LLQUANTIZE_FACTORSHIFT	0
+#define DTRACE_LLQUANTIZE_FACTORMASK	UINT16_MAX
+
+#define DTRACE_LLQUANTIZE_STEPS(x)		\
+		(uint16_t)(((x) & DTRACE_LLQUANTIZE_STEPSMASK) >> \
+			DTRACE_LLQUANTIZE_STEPSSHIFT)
+
+#define DTRACE_LLQUANTIZE_HMAG(x)		\
+		(uint16_t)(((x) & DTRACE_LLQUANTIZE_HMAGMASK) >> \
+			DTRACE_LLQUANTIZE_HMAGSHIFT)
+
+#define DTRACE_LLQUANTIZE_LMAG(x)		\
+		(uint16_t)(((x) & DTRACE_LLQUANTIZE_LMAGMASK) >> \
+			DTRACE_LLQUANTIZE_LMAGSHIFT)
+
+#define DTRACE_LLQUANTIZE_FACTOR(x)		\
+		(uint16_t)(((x) & DTRACE_LLQUANTIZE_FACTORMASK) >> \
+			DTRACE_LLQUANTIZE_FACTORSHIFT)
+
+#define DTRACE_USTACK_NFRAMES(x)	(uint32_t)((x) & UINT32_MAX)
+#define DTRACE_USTACK_STRSIZE(x)	(uint32_t)((x) >> 32)
+#define DTRACE_USTACK_ARG(x, y)		\
+		((((uint64_t)(y)) << 32) | ((x) & UINT32_MAX))
+
+#ifndef _LP64
+# ifndef _LITTLE_ENDIAN
+#  define DTRACE_PTR(type, name)	uint32_t name##pad; type *name
+# else
+#  define DTRACE_PTR(type, name)	type *name; uint32_t name##pad
+# endif
+#else
+# define DTRACE_PTR(type, name)		type *name
+#endif
+
+#endif /* _LINUX_DTRACE_ACTIONS_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/arg.h b/include/uapi/linux/dtrace/arg.h
new file mode 100644
index 000000000000..4a9099a816e6
--- /dev/null
+++ b/include/uapi/linux/dtrace/arg.h
@@ -0,0 +1,42 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_ARG_H
+#define _LINUX_DTRACE_ARG_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/arg_defines.h>
+
+/*
+ * Because it would waste both space and time, argument types do not reside
+ * with the probe.  In order to determine argument types for args[X]
+ * variables, the D compiler queries for argument types on a probe-by-probe
+ * basis.  (This optimizes for the common case that arguments are either not
+ * used or used in an untyped fashion.)  Typed arguments are specified with a
+ * string of the type name in the dtragd_native member of the argument
+ * description structure.  Typed arguments may be further translated to types
+ * of greater stability; the provider indicates such a translated argument by
+ * filling in the dtargd_xlate member with the string of the translated type.
+ * Finally, the provider may indicate which argument value a given argument
+ * maps to by setting the dtargd_mapping member -- allowing a single argument
+ * to map to multiple args[X] variables.
+ */
+typedef struct dtrace_argdesc {
+	dtrace_id_t dtargd_id;
+	int dtargd_ndx;
+	int dtargd_mapping;
+	char dtargd_native[DTRACE_ARGTYPELEN];
+	char dtargd_xlate[DTRACE_ARGTYPELEN];
+} dtrace_argdesc_t;
+
+#endif /* _LINUX_DTRACE_ARG_H */
diff --git a/include/uapi/linux/dtrace/arg_defines.h b/include/uapi/linux/dtrace/arg_defines.h
new file mode 100644
index 000000000000..72862cd1b8e6
--- /dev/null
+++ b/include/uapi/linux/dtrace/arg_defines.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_ARG_DEFINES_H
+#define _LINUX_DTRACE_ARG_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+struct dtrace_argdesc;
+
+#endif /* _LINUX_DTRACE_ARG_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/buffer.h b/include/uapi/linux/dtrace/buffer.h
new file mode 100644
index 000000000000..9bbbc4f1f14b
--- /dev/null
+++ b/include/uapi/linux/dtrace/buffer.h
@@ -0,0 +1,43 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_BUFFER_H
+#define _LINUX_DTRACE_BUFFER_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/actions_defines.h>
+#include <linux/dtrace/buffer_defines.h>
+
+/*
+ * In order to get a snapshot of the principal or aggregation buffer,
+ * user-level passes a buffer description to the kernel with the dtrace_bufdesc
+ * structure.  This describes which CPU user-level is interested in, and
+ * where user-level wishes the kernel to snapshot the buffer to (the
+ * dtbd_data field).  The kernel uses the same structure to pass back some
+ * information regarding the buffer:  the size of data actually copied out, the
+ * number of drops, the number of errors, and the offset of the oldest record.
+ * If the buffer policy is a "switch" policy, taking a snapshot of the
+ * principal buffer has the additional effect of switching the active and
+ * inactive buffers.  Taking a snapshot of the aggregation buffer _always_ has
+ * the additional effect of switching the active and inactive buffers.
+ */
+typedef struct dtrace_bufdesc {
+	uint64_t dtbd_size;			/* size of buffer */
+	uint32_t dtbd_cpu;			/* CPU or DTRACE_CPUALL */
+	uint32_t dtbd_errors;			/* number of errors */
+	uint64_t dtbd_drops;			/* number of drops */
+	DTRACE_PTR(char, dtbd_data);		/* data */
+	uint64_t dtbd_oldest;			/* offset of oldest record */
+} dtrace_bufdesc_t;
+
+#endif /* _LINUX_DTRACE_BUFFER_H */
diff --git a/include/uapi/linux/dtrace/buffer_defines.h b/include/uapi/linux/dtrace/buffer_defines.h
new file mode 100644
index 000000000000..16c3c193618a
--- /dev/null
+++ b/include/uapi/linux/dtrace/buffer_defines.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_BUFFER_DEFINES_H
+#define _LINUX_DTRACE_BUFFER_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+struct dtrace_bufdesc;
+
+#endif /* _LINUX_DTRACE_BUFFER_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/conf.h b/include/uapi/linux/dtrace/conf.h
new file mode 100644
index 000000000000..95b201958f4c
--- /dev/null
+++ b/include/uapi/linux/dtrace/conf.h
@@ -0,0 +1,35 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_CONF_H
+#define _LINUX_DTRACE_CONF_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/conf_defines.h>
+
+/*
+ * User-level may need to understand some elements of the kernel DTrace
+ * configuration in order to generate correct DIF.  This information is
+ * conveyed via the dtrace_conf structure.
+ */
+typedef struct dtrace_conf {
+	uint_t dtc_difversion;			/* supported DIF version */
+	uint_t dtc_difintregs;			/* # of DIF integer registers */
+	uint_t dtc_diftupregs;			/* # of DIF tuple registers */
+	uint_t dtc_ctfmodel;			/* CTF data model */
+	/* Deviation from Solaris...  Used to just be 8 padding entries. */
+	uint_t dtc_maxbufs;			/* max # of buffers */
+	uint_t dtc_pad[7];			/* reserved for future use */
+} dtrace_conf_t;
+
+#endif /* _LINUX_DTRACE_CONF_H */
diff --git a/include/uapi/linux/dtrace/conf_defines.h b/include/uapi/linux/dtrace/conf_defines.h
new file mode 100644
index 000000000000..5c4a1cb5d37c
--- /dev/null
+++ b/include/uapi/linux/dtrace/conf_defines.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_CONF_DEFINES_H
+#define _LINUX_DTRACE_CONF_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+struct dtrace_conf;
+
+#endif /* _LINUX_DTRACE_CONF_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/cpu_defines.h b/include/uapi/linux/dtrace/cpu_defines.h
new file mode 100644
index 000000000000..a1cd3e410ccc
--- /dev/null
+++ b/include/uapi/linux/dtrace/cpu_defines.h
@@ -0,0 +1,17 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2011, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_CPU_DEFINES_H_
+#define _LINUX_DTRACE_CPU_DEFINES_H_
+
+typedef uint32_t	processorid_t;
+typedef uint32_t	psetid_t;
+typedef uint32_t	chipid_t;
+typedef uint32_t	lgrp_id_t;
+
+#endif /* _LINUX_DTRACE_CPU_DEFINES_H_ */
diff --git a/include/uapi/linux/dtrace/dif.h b/include/uapi/linux/dtrace/dif.h
new file mode 100644
index 000000000000..92daea17a1f1
--- /dev/null
+++ b/include/uapi/linux/dtrace/dif.h
@@ -0,0 +1,60 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_DIF_H
+#define _LINUX_DTRACE_DIF_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/dif_defines.h>
+
+/*
+ * The following definitions describe the DTrace Intermediate Format (DIF), a a
+ * RISC-like instruction set and program encoding used to represent predicates
+ * and actions that can be bound to DTrace probes.  The constants below defining
+ * the number of available registers are suggested minimums; the compiler should
+ * use DTRACEIOC_CONF to dynamically obtain the number of registers provided by
+ * the current DTrace implementation.
+ */
+
+/*
+ * A DTrace Intermediate Format Type (DIF Type) is used to represent the types
+ * of variables, function and associative array arguments, and the return type
+ * for each DIF object (shown below).  It contains a description of the type,
+ * its size in bytes, and a module identifier.
+ */
+
+typedef struct dtrace_diftype {
+	uint8_t dtdt_kind;
+	uint8_t dtdt_ckind;
+	uint8_t dtdt_flags;
+	uint8_t dtdt_pad;
+	uint32_t dtdt_size;
+} dtrace_diftype_t;
+
+/*
+ * A DTrace Intermediate Format variable record is used to describe each of the
+ * variables referenced by a given DIF object.  It contains an integer variable
+ * identifier along with variable scope and properties, as shown below.  The
+ * size of this structure must be sizeof (int) aligned.
+ */
+
+typedef struct dtrace_difv {
+	uint32_t dtdv_name;
+	uint32_t dtdv_id;
+	uint8_t dtdv_kind;
+	uint8_t dtdv_scope;
+	uint16_t dtdv_flags;
+	struct dtrace_diftype dtdv_type;
+} dtrace_difv_t;
+
+#endif /* _LINUX_DTRACE_DIF_H */
diff --git a/include/uapi/linux/dtrace/dif_defines.h b/include/uapi/linux/dtrace/dif_defines.h
new file mode 100644
index 000000000000..80b913f097a2
--- /dev/null
+++ b/include/uapi/linux/dtrace/dif_defines.h
@@ -0,0 +1,288 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2017, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_DIF_DEFINES_H
+#define _LINUX_DTRACE_DIF_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+/*
+ * The following definitions describe the DTrace Intermediate Format (DIF), a a
+ * RISC-like instruction set and program encoding used to represent predicates
+ * and actions that can be bound to DTrace probes.  The constants below defining
+ * the number of available registers are suggested minimums; the compiler should
+ * use DTRACEIOC_CONF to dynamically obtain the number of registers provided by
+ * the current DTrace implementation.
+ */
+
+#define DIF_VERSION_1	1
+#define DIF_VERSION_2	2
+#define DIF_VERSION	DIF_VERSION_2
+#define	DIF_DIR_NREGS	8		/* number of DIF integer registers */
+#define	DIF_DTR_NREGS	8		/* number of DIF tuple registers */
+
+#define DIF_OP_OR	1		/* or   r1, r2, rd */
+#define DIF_OP_XOR	2		/* xor  r1, r2, rd */
+#define DIF_OP_AND	3		/* and  r1, r2, rd */
+#define DIF_OP_SLL	4		/* sll  r1, r2, rd */
+#define DIF_OP_SRL	5		/* srl  r1, r2, rd */
+#define DIF_OP_SUB	6		/* sub  r1, r2, rd */
+#define DIF_OP_ADD	7		/* add  r1, r2, rd */
+#define DIF_OP_MUL	8		/* mul  r1, r2, rd */
+#define DIF_OP_SDIV	9		/* sdiv r1, r2, rd */
+#define DIF_OP_UDIV	10		/* udiv r1, r2, rd */
+#define DIF_OP_SREM	11		/* srem r1, r2, rd */
+#define DIF_OP_UREM	12		/* urem r1, r2, rd */
+#define DIF_OP_NOT	13		/* not  r1, rd */
+#define DIF_OP_MOV	14		/* mov  r1, rd */
+#define DIF_OP_CMP	15		/* cmp  r1, r2 */
+#define DIF_OP_TST	16		/* tst  r1 */
+#define DIF_OP_BA	17		/* ba   label */
+#define DIF_OP_BE	18		/* be   label */
+#define DIF_OP_BNE	19		/* bne  label */
+#define DIF_OP_BG	20		/* bg   label */
+#define DIF_OP_BGU	21		/* bgu  label */
+#define DIF_OP_BGE	22		/* bge  label */
+#define DIF_OP_BGEU	23		/* bgeu label */
+#define DIF_OP_BL	24		/* bl   label */
+#define DIF_OP_BLU	25		/* blu  label */
+#define DIF_OP_BLE	26		/* ble  label */
+#define DIF_OP_BLEU	27		/* bleu label */
+#define DIF_OP_LDSB	28		/* ldsb [r1], rd */
+#define DIF_OP_LDSH	29		/* ldsh [r1], rd */
+#define DIF_OP_LDSW	30		/* ldsw [r1], rd */
+#define DIF_OP_LDUB	31		/* ldub [r1], rd */
+#define DIF_OP_LDUH	32		/* lduh [r1], rd */
+#define DIF_OP_LDUW	33		/* lduw [r1], rd */
+#define DIF_OP_LDX	34		/* ldx  [r1], rd */
+#define DIF_OP_RET	35		/* ret  rd */
+#define DIF_OP_NOP	36		/* nop */
+#define DIF_OP_SETX	37		/* setx intindex, rd */
+#define DIF_OP_SETS	38		/* sets strindex, rd */
+#define DIF_OP_SCMP	39		/* scmp r1, r2 */
+#define DIF_OP_LDGA	40		/* ldga var, ri, rd */
+#define DIF_OP_LDGS	41		/* ldgs var, rd */
+#define DIF_OP_STGS	42		/* stgs var, rs */
+#define DIF_OP_LDTA	43		/* ldta var, ri, rd */
+#define DIF_OP_LDTS	44		/* ldts var, rd */
+#define DIF_OP_STTS	45		/* stts var, rs */
+#define DIF_OP_SRA	46		/* sra  r1, r2, rd */
+#define DIF_OP_CALL	47		/* call subr, rd */
+#define DIF_OP_PUSHTR	48		/* pushtr type, rs, rr */
+#define DIF_OP_PUSHTV	49		/* pushtv type, rs, rv */
+#define DIF_OP_POPTS	50		/* popts */
+#define DIF_OP_FLUSHTS	51		/* flushts */
+#define DIF_OP_LDGAA	52		/* ldgaa var, rd */
+#define DIF_OP_LDTAA	53		/* ldtaa var, rd */
+#define DIF_OP_STGAA	54		/* stgaa var, rs */
+#define DIF_OP_STTAA	55		/* sttaa var, rs */
+#define DIF_OP_LDLS	56		/* ldls var, rd */
+#define DIF_OP_STLS	57		/* stls var, rs */
+#define DIF_OP_ALLOCS	58		/* allocs r1, rd */
+#define DIF_OP_COPYS	59		/* copys  r1, r2, rd */
+#define DIF_OP_STB	60		/* stb  r1, [rd] */
+#define DIF_OP_STH	61		/* sth  r1, [rd] */
+#define DIF_OP_STW	62		/* stw  r1, [rd] */
+#define DIF_OP_STX	63		/* stx  r1, [rd] */
+#define DIF_OP_ULDSB	64		/* uldsb [r1], rd */
+#define DIF_OP_ULDSH	65		/* uldsh [r1], rd */
+#define DIF_OP_ULDSW	66		/* uldsw [r1], rd */
+#define DIF_OP_ULDUB	67		/* uldub [r1], rd */
+#define DIF_OP_ULDUH	68		/* ulduh [r1], rd */
+#define DIF_OP_ULDUW	69		/* ulduw [r1], rd */
+#define DIF_OP_ULDX	70		/* uldx  [r1], rd */
+#define DIF_OP_RLDSB	71		/* rldsb [r1], rd */
+#define DIF_OP_RLDSH	72		/* rldsh [r1], rd */
+#define DIF_OP_RLDSW	73		/* rldsw [r1], rd */
+#define DIF_OP_RLDUB	74		/* rldub [r1], rd */
+#define DIF_OP_RLDUH	75		/* rlduh [r1], rd */
+#define DIF_OP_RLDUW	76		/* rlduw [r1], rd */
+#define DIF_OP_RLDX	77		/* rldx  [r1], rd */
+#define DIF_OP_XLATE	78		/* xlate xlrindex, rd */
+#define DIF_OP_XLARG	79		/* xlarg xlrindex, rd */
+
+#define	DIF_INTOFF_MAX		0xffff	/* highest integer table offset */
+#define	DIF_STROFF_MAX		0xffff	/* highest string table offset */
+#define	DIF_REGISTER_MAX	0xff	/* highest register number */
+#define	DIF_VARIABLE_MAX	0xffff	/* highest variable identifier */
+#define	DIF_SUBROUTINE_MAX	0xffff	/* highest subroutine code */
+
+#define	DIF_VAR_ARRAY_MIN	0x0000	/* lowest numbered array variable */
+#define	DIF_VAR_ARRAY_UBASE	0x0080	/* lowest user-defined array */
+#define	DIF_VAR_ARRAY_MAX	0x00ff	/* highest numbered array variable */
+
+#define	DIF_VAR_OTHER_MIN	0x0100	/* lowest numbered scalar or assc */
+#define	DIF_VAR_OTHER_UBASE	0x0500	/* lowest user-defined scalar or assc */
+#define	DIF_VAR_OTHER_MAX	0xffff	/* highest numbered scalar or assc */
+
+#define DIF_VAR_ARGS		0x0000
+#define DIF_VAR_REGS		0x0001
+#define DIF_VAR_UREGS		0x0002
+#define DIF_VAR_CURTHREAD	0x0100
+#define DIF_VAR_TIMESTAMP	0x0101
+#define DIF_VAR_VTIMESTAMP	0x0102
+#define DIF_VAR_IPL		0x0103
+#define DIF_VAR_EPID		0x0104
+#define DIF_VAR_ID		0x0105
+#define DIF_VAR_ARG0		0x0106
+#define DIF_VAR_ARG1		0x0107
+#define DIF_VAR_ARG2		0x0108
+#define DIF_VAR_ARG3		0x0109
+#define DIF_VAR_ARG4		0x010a
+#define DIF_VAR_ARG5		0x010b
+#define DIF_VAR_ARG6		0x010c
+#define DIF_VAR_ARG7		0x010d
+#define DIF_VAR_ARG8		0x010e
+#define DIF_VAR_ARG9		0x010f
+#define DIF_VAR_STACKDEPTH	0x0110
+#define DIF_VAR_CALLER		0x0111
+#define DIF_VAR_PROBEPROV	0x0112
+#define DIF_VAR_PROBEMOD	0x0113
+#define DIF_VAR_PROBEFUNC	0x0114
+#define DIF_VAR_PROBENAME	0x0115
+#define DIF_VAR_PID		0x0116
+#define DIF_VAR_TID		0x0117
+#define DIF_VAR_EXECNAME	0x0118
+#define DIF_VAR_ZONENAME	0x0119
+#define DIF_VAR_WALLTIMESTAMP	0x011a
+#define DIF_VAR_USTACKDEPTH	0x011b
+#define DIF_VAR_UCALLER		0x011c
+#define DIF_VAR_PPID		0x011d
+#define DIF_VAR_UID		0x011e
+#define DIF_VAR_GID		0x011f
+#define DIF_VAR_ERRNO		0x0120
+#define DIF_VAR_CURCPU		0x0121
+
+#define DIF_SUBR_RAND			0
+#define DIF_SUBR_MUTEX_OWNED		1
+#define DIF_SUBR_MUTEX_OWNER		2
+#define DIF_SUBR_MUTEX_TYPE_ADAPTIVE	3
+#define DIF_SUBR_MUTEX_TYPE_SPIN	4
+#define DIF_SUBR_RW_READ_HELD		5
+#define DIF_SUBR_RW_WRITE_HELD		6
+#define DIF_SUBR_RW_ISWRITER		7
+#define DIF_SUBR_COPYIN			8
+#define DIF_SUBR_COPYINSTR		9
+#define DIF_SUBR_SPECULATION		10
+#define DIF_SUBR_PROGENYOF		11
+#define DIF_SUBR_STRLEN			12
+#define DIF_SUBR_COPYOUT		13
+#define DIF_SUBR_COPYOUTSTR		14
+#define DIF_SUBR_ALLOCA			15
+#define DIF_SUBR_BCOPY			16
+#define DIF_SUBR_COPYINTO		17
+#define DIF_SUBR_MSGDSIZE		18
+#define DIF_SUBR_MSGSIZE		19
+#define DIF_SUBR_GETMAJOR		20
+#define DIF_SUBR_GETMINOR		21
+#define DIF_SUBR_DDI_PATHNAME		22
+#define DIF_SUBR_STRJOIN		23
+#define DIF_SUBR_LLTOSTR		24
+#define DIF_SUBR_BASENAME		25
+#define DIF_SUBR_DIRNAME		26
+#define DIF_SUBR_CLEANPATH		27
+#define DIF_SUBR_STRCHR			28
+#define DIF_SUBR_STRRCHR		29
+#define DIF_SUBR_STRSTR			30
+#define DIF_SUBR_STRTOK			31
+#define DIF_SUBR_SUBSTR			32
+#define DIF_SUBR_INDEX			33
+#define DIF_SUBR_RINDEX			34
+#define DIF_SUBR_HTONS			35
+#define DIF_SUBR_HTONL			36
+#define DIF_SUBR_HTONLL			37
+#define DIF_SUBR_NTOHS			38
+#define DIF_SUBR_NTOHL			39
+#define DIF_SUBR_NTOHLL			40
+#define DIF_SUBR_INET_NTOP		41
+#define DIF_SUBR_INET_NTOA		42
+#define DIF_SUBR_INET_NTOA6		43
+#define DIF_SUBR_D_PATH			44
+#define DIF_SUBR_LINK_NTOP		45
+
+#define DIF_SUBR_MAX			45
+
+typedef uint32_t	dif_instr_t;
+
+#define DIF_INSTR_OP(i)			(((i) >> 24) & 0xff)
+#define DIF_INSTR_R1(i)			(((i) >> 16) & 0xff)
+#define DIF_INSTR_R2(i)			(((i) >>  8) & 0xff)
+#define DIF_INSTR_RD(i)			((i) & 0xff)
+#define DIF_INSTR_RS(i)			((i) & 0xff)
+#define DIF_INSTR_LABEL(i)		((i) & 0xffffff)
+#define DIF_INSTR_VAR(i)		(((i) >>  8) & 0xffff)
+#define DIF_INSTR_INTEGER(i)		(((i) >>  8) & 0xffff)
+#define DIF_INSTR_STRING(i)		(((i) >>  8) & 0xffff)
+#define DIF_INSTR_SUBR(i)		(((i) >>  8) & 0xffff)
+#define DIF_INSTR_TYPE(i)		(((i) >> 16) & 0xff)
+#define DIF_INSTR_XLREF(i)		(((i) >>  8) & 0xffff)
+#define DIF_INSTR_FMT(op, r1, r2, d) \
+			(((op) << 24) | ((r1) << 16) | ((r2) << 8) | (d))
+
+#define DIF_INSTR_NOT(r1, d)		(DIF_INSTR_FMT(DIF_OP_NOT, r1, 0, d))
+#define DIF_INSTR_MOV(r1, d)		(DIF_INSTR_FMT(DIF_OP_MOV, r1, 0, d))
+#define DIF_INSTR_CMP(op, r1, r2)	(DIF_INSTR_FMT(op, r1, r2, 0))
+#define DIF_INSTR_TST(r1)		(DIF_INSTR_FMT(DIF_OP_TST, r1, 0, 0))
+#define DIF_INSTR_BRANCH(op, label)	(((op) << 24) | (label))
+#define DIF_INSTR_LOAD(op, r1, d)	(DIF_INSTR_FMT(op, r1, 0, d))
+#define DIF_INSTR_STORE(op, r1, d)	(DIF_INSTR_FMT(op, r1, 0, d))
+#define DIF_INSTR_SETX(i, d)		((DIF_OP_SETX << 24) | ((i) << 8) | (d))
+#define DIF_INSTR_SETS(s, d)		((DIF_OP_SETS << 24) | ((s) << 8) | (d))
+#define DIF_INSTR_RET(d)		(DIF_INSTR_FMT(DIF_OP_RET, 0, 0, d))
+#define DIF_INSTR_NOP			(DIF_OP_NOP << 24)
+#define DIF_INSTR_LDA(op, v, r, d)	(DIF_INSTR_FMT(op, v, r, d))
+#define DIF_INSTR_LDV(op, v, d)		(((op) << 24) | ((v) << 8) | (d))
+#define DIF_INSTR_STV(op, v, rs)	(((op) << 24) | ((v) << 8) | (rs))
+#define DIF_INSTR_CALL(s, d)		((DIF_OP_CALL << 24) | ((s) << 8) | (d))
+#define DIF_INSTR_PUSHTS(op, t, r2, rs)	(DIF_INSTR_FMT(op, t, r2, rs))
+#define DIF_INSTR_POPTS			(DIF_OP_POPTS << 24)
+#define DIF_INSTR_FLUSHTS		(DIF_OP_FLUSHTS << 24)
+#define DIF_INSTR_ALLOCS(r1, d)		(DIF_INSTR_FMT(DIF_OP_ALLOCS, r1, 0, d))
+#define DIF_INSTR_COPYS(r1, r2, d)	(DIF_INSTR_FMT(DIF_OP_COPYS, r1, r2, d))
+#define DIF_INSTR_XLATE(op, r, d)	(((op) << 24) | ((r) << 8) | (d))
+
+#define DIF_REG_R0		0
+
+/*
+ * A DTrace Intermediate Format Type (DIF Type) is used to represent the types
+ * of variables, function and associative array arguments, and the return type
+ * for each DIF object (shown below).  It contains a description of the type,
+ * its size in bytes, and a module identifier.
+ */
+
+#define DIF_TYPE_CTF		0
+#define DIF_TYPE_STRING		1
+
+#define DIF_TF_BYREF		0x1
+
+/*
+ * A DTrace Intermediate Format variable record is used to describe each of the
+ * variables referenced by a given DIF object.  It contains an integer variable
+ * identifier along with variable scope and properties, as shown below.  The
+ * size of this structure must be sizeof (int) aligned.
+ */
+
+#define DIFV_KIND_ARRAY		0
+#define DIFV_KIND_SCALAR	1
+
+#define DIFV_SCOPE_GLOBAL	0
+#define DIFV_SCOPE_THREAD	1
+#define DIFV_SCOPE_LOCAL	2
+
+#define DIFV_F_REF		0x1
+#define DIFV_F_MOD		0x2
+
+struct dtrace_diftype;
+struct dtrace_difv;
+
+#endif /* _LINUX_DTRACE_DIF_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/difo.h b/include/uapi/linux/dtrace/difo.h
new file mode 100644
index 000000000000..6e9efd7f0a43
--- /dev/null
+++ b/include/uapi/linux/dtrace/difo.h
@@ -0,0 +1,57 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_DIFO_H
+#define _LINUX_DTRACE_DIFO_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/dif.h>
+#include <linux/dtrace/dof_defines.h>
+
+/*
+ * A DIFO is used to store the compiled DIF for a D expression, its return
+ * type, and its string and variable tables.  The string table is a single
+ * buffer of character data into which sets instructions and variable
+ * references can reference strings using a byte offset.  The variable table
+ * is an array of dtrace_difv_t structures that describe the name and type of
+ * each variable and the id used in the DIF code.  This structure is described
+ * above in the DIF section of this header file.  The DIFO is used at both
+ * user-level (in the library) and in the kernel, but the structure is never
+ * passed between the two: the DOF structures form the only interface.  As a
+ * result, the definition can change depending on the presence of _KERNEL.
+ */
+
+typedef struct dtrace_difo {
+	dif_instr_t *dtdo_buf;		/* instruction buffer */
+	uint64_t *dtdo_inttab;		/* integer table (optional) */
+	char *dtdo_strtab;		/* string table (optional) */
+	struct dtrace_difv *dtdo_vartab; /* variable table (optional) */
+	uint_t dtdo_len;		/* length of instruction buffer */
+	uint_t dtdo_intlen;		/* length of integer table */
+	uint_t dtdo_strlen;		/* length of string table */
+	uint_t dtdo_varlen;		/* length of variable table */
+	struct dtrace_diftype dtdo_rtype; /* return type */
+	uint_t dtdo_refcnt;		/* owner reference count */
+	uint_t dtdo_destructive;	/* invokes destructive subroutines */
+#ifndef _KERNEL
+	struct dtrace_diftype orig_dtdo_rtype;	/* original return type */
+	struct dof_relodesc *dtdo_kreltab;	/* kernel relocations */
+	struct dof_relodesc *dtdo_ureltab;	/* user relocations */
+	struct dt_node **dtdo_xlmtab;		/* translator references */
+	uint_t dtdo_krelen;			/* length of krelo table */
+	uint_t dtdo_urelen;			/* length of urelo table */
+	uint_t dtdo_xlmlen;			/* length of translator table */
+#endif
+} dtrace_difo_t;
+
+#endif /* _LINUX_DTRACE_DIFO_H */
diff --git a/include/uapi/linux/dtrace/difo_defines.h b/include/uapi/linux/dtrace/difo_defines.h
new file mode 100644
index 000000000000..fdd25f2b7691
--- /dev/null
+++ b/include/uapi/linux/dtrace/difo_defines.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_DIFO_DEFINES_H
+#define _LINUX_DTRACE_DIFO_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+struct dtrace_difo;
+
+#endif /* _LINUX_DTRACE_DIFO_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/dof.h b/include/uapi/linux/dtrace/dof.h
new file mode 100644
index 000000000000..54c6ca710443
--- /dev/null
+++ b/include/uapi/linux/dtrace/dof.h
@@ -0,0 +1,196 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_DOF_H
+#define _LINUX_DTRACE_DOF_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/dif.h>
+#include <linux/dtrace/dof_defines.h>
+
+/*
+ * DTrace programs can be persistently encoded in the DOF format so that they
+ * may be embedded in other programs (for example, in an ELF file) or in the
+ * dtrace driver configuration file for use in anonymous tracing.  The DOF
+ * format is versioned and extensible so that it can be revised and so that
+ * internal data structures can be modified or extended compatibly.  All DOF
+ * structures use fixed-size types, so the 32-bit and 64-bit representations
+ * are identical and consumers can use either data model transparently.
+ *
+ * The file layout is structured as follows:
+ *
+ * +---------------+-------------------+----- ... ----+---- ... ------+
+ * |   dof_hdr_t   |  dof_sec_t[ ... ] |   loadable   | non-loadable  |
+ * | (file header) | (section headers) | section data | section data  |
+ * +---------------+-------------------+----- ... ----+---- ... ------+
+ * |<------------ dof_hdr.dofh_loadsz --------------->|               |
+ * |<------------ dof_hdr.dofh_filesz ------------------------------->|
+ *
+ * The file header stores meta-data including a magic number, data model for
+ * the instrumentation, data encoding, and properties of the DIF code within.
+ * The header describes its own size and the size of the section headers.  By
+ * convention, an array of section headers follows the file header, and then
+ * the data for all loadable sections and unloadable sections.  This permits
+ * consumer code to easily download the headers and all loadable data into the
+ * DTrace driver in one contiguous chunk, omitting other extraneous sections.
+ *
+ * The section headers describe the size, offset, alignment, and section type
+ * for each section.  Sections are described using a set of #defines that tell
+ * the consumer what kind of data is expected.  Sections can contain links to
+ * other sections by storing a dof_secidx_t, an index into the section header
+ * array, inside of the section data structures.  The section header includes
+ * an entry size so that sections with data arrays can grow their structures.
+ *
+ * The DOF data itself can contain many snippets of DIF (i.e. >1 DIFOs), which
+ * are represented themselves as a collection of related DOF sections.  This
+ * permits us to change the set of sections associated with a DIFO over time,
+ * and also permits us to encode DIFOs that contain different sets of sections.
+ * When a DOF section wants to refer to a DIFO, it stores the dof_secidx_t of a
+ * section of type DOF_SECT_DIFOHDR.  This section's data is then an array of
+ * dof_secidx_t's which in turn denote the sections associated with this DIFO.
+ *
+ * This loose coupling of the file structure (header and sections) to the
+ * structure of the DTrace program itself (ECB descriptions, action
+ * descriptions, and DIFOs) permits activities such as relocation processing
+ * to occur in a single pass without having to understand D program structure.
+ *
+ * Finally, strings are always stored in ELF-style string tables along with a
+ * string table section index and string table offset.  Therefore strings in
+ * DOF are always arbitrary-length and not bound to the current implementation.
+ */
+
+typedef struct dof_hdr {
+	uint8_t dofh_ident[DOF_ID_SIZE];/* ident bytes (see defines) */
+	uint32_t dofh_flags;		/* file attribute flags (if any) */
+	uint32_t dofh_hdrsize;		/* size of file header in bytes */
+	uint32_t dofh_secsize;		/* size of section header in bytes */
+	uint32_t dofh_secnum;		/* number of section headers */
+	uint64_t dofh_secoff;		/* file offset of section headers */
+	uint64_t dofh_loadsz;		/* file size of loadable portion */
+	uint64_t dofh_filesz;		/* file size of entire DOF file */
+	uint64_t dofh_pad;		/* reserved for future use */
+} dof_hdr_t;
+
+typedef struct dof_sec {
+	uint32_t dofs_type;	/* section type (see defines) */
+	uint32_t dofs_align;	/* section data memory alignment */
+	uint32_t dofs_flags;	/* section flags (if any) */
+	uint32_t dofs_entsize;	/* size of section entry (if table) */
+	uint64_t dofs_offset;	/* offset of section data within file */
+	uint64_t dofs_size;	/* size of section data in bytes */
+} dof_sec_t;
+
+
+typedef struct dof_ecbdesc {
+	dof_secidx_t dofe_probes;	/* link to DOF_SECT_PROBEDESC */
+	dof_secidx_t dofe_pred;		/* link to DOF_SECT_DIFOHDR */
+	dof_secidx_t dofe_actions;	/* link to DOF_SECT_ACTDESC */
+	uint32_t dofe_pad;		/* reserved for future use */
+	uint64_t dofe_uarg;		/* user-supplied library argument */
+} dof_ecbdesc_t;
+
+typedef struct dof_probedesc {
+	dof_secidx_t dofp_strtab;	/* link to DOF_SECT_STRTAB section */
+	dof_stridx_t dofp_provider;	/* provider string */
+	dof_stridx_t dofp_mod;		/* module string */
+	dof_stridx_t dofp_func;		/* function string */
+	dof_stridx_t dofp_name;		/* name string */
+	uint32_t dofp_id;		/* probe identifier (or zero) */
+} dof_probedesc_t;
+
+typedef struct dof_actdesc {
+	dof_secidx_t dofa_difo;		/* link to DOF_SECT_DIFOHDR */
+	dof_secidx_t dofa_strtab;	/* link to DOF_SECT_STRTAB section */
+	uint32_t dofa_kind;		/* action kind (DTRACEACT_* constant) */
+	uint32_t dofa_ntuple;		/* number of subsequent tuple actions */
+	uint64_t dofa_arg;		/* kind-specific argument */
+	uint64_t dofa_uarg;		/* user-supplied argument */
+} dof_actdesc_t;
+
+typedef struct dof_difohdr {
+	struct dtrace_diftype dofd_rtype; /* return type for this fragment */
+	dof_secidx_t dofd_links[1];	/* variable length array of indices */
+} dof_difohdr_t;
+
+typedef struct dof_relohdr {
+	dof_secidx_t dofr_strtab;	/* link to DOF_SECT_STRTAB for names */
+	dof_secidx_t dofr_relsec;	/* link to DOF_SECT_RELTAB for relos */
+	dof_secidx_t dofr_tgtsec;	/* link to section we are relocating */
+} dof_relohdr_t;
+
+typedef struct dof_relodesc {
+	dof_stridx_t dofr_name;		/* string name of relocation symbol */
+	uint32_t dofr_type;		/* relo type (DOF_RELO_* constant) */
+	uint64_t dofr_offset;		/* byte offset for relocation */
+	uint64_t dofr_data;		/* additional type-specific data */
+} dof_relodesc_t;
+
+typedef struct dof_optdesc {
+	uint32_t dofo_option;		/* option identifier */
+	dof_secidx_t dofo_strtab;	/* string table, if string option */
+	uint64_t dofo_value;		/* option value or string index */
+} dof_optdesc_t;
+
+typedef struct dof_provider {
+	dof_secidx_t dofpv_strtab;	/* link to DOF_SECT_STRTAB section */
+	dof_secidx_t dofpv_probes;	/* link to DOF_SECT_PROBES section */
+	dof_secidx_t dofpv_prargs;	/* link to DOF_SECT_PRARGS section */
+	dof_secidx_t dofpv_proffs;	/* link to DOF_SECT_PROFFS section */
+	dof_stridx_t dofpv_name;	/* provider name string */
+	dof_attr_t dofpv_provattr;	/* provider attributes */
+	dof_attr_t dofpv_modattr;	/* module attributes */
+	dof_attr_t dofpv_funcattr;	/* function attributes */
+	dof_attr_t dofpv_nameattr;	/* name attributes */
+	dof_attr_t dofpv_argsattr;	/* args attributes */
+	dof_secidx_t dofpv_prenoffs;	/* link to DOF_SECT_PRENOFFS section */
+} dof_provider_t;
+
+typedef struct dof_probe {
+	uint64_t dofpr_addr;		/* probe base address or offset */
+	dof_stridx_t dofpr_func;	/* probe function string */
+	dof_stridx_t dofpr_name;	/* probe name string */
+	dof_stridx_t dofpr_nargv;	/* native argument type strings */
+	dof_stridx_t dofpr_xargv;	/* translated argument type strings */
+	uint32_t dofpr_argidx;		/* index of first argument mapping */
+	uint32_t dofpr_offidx;		/* index of first offset entry */
+	uint8_t dofpr_nargc;		/* native argument count */
+	uint8_t dofpr_xargc;		/* translated argument count */
+	uint16_t dofpr_noffs;		/* number of offset entries for probe */
+	uint32_t dofpr_enoffidx;	/* index of first is-enabled offset */
+	uint16_t dofpr_nenoffs;		/* number of is-enabled offsets */
+	uint16_t dofpr_pad1;		/* reserved for future use */
+	uint32_t dofpr_pad2;		/* reserved for future use */
+} dof_probe_t;
+
+typedef struct dof_xlator {
+	dof_secidx_t dofxl_members;	/* link to DOF_SECT_XLMEMBERS section */
+	dof_secidx_t dofxl_strtab;	/* link to DOF_SECT_STRTAB section */
+	dof_stridx_t dofxl_argv;	/* input parameter type strings */
+	uint32_t dofxl_argc;		/* input parameter list length */
+	dof_stridx_t dofxl_type;	/* output type string name */
+	dof_attr_t dofxl_attr;		/* output stability attributes */
+} dof_xlator_t;
+
+typedef struct dof_xlmember {
+	dof_secidx_t dofxm_difo;	/* member link to DOF_SECT_DIFOHDR */
+	dof_stridx_t dofxm_name;	/* member name */
+	struct dtrace_diftype dofxm_type; /* member type */
+} dof_xlmember_t;
+
+typedef struct dof_xlref {
+	dof_secidx_t dofxr_xlator;	/* link to DOF_SECT_XLATORS section */
+	uint32_t dofxr_member;		/* index of referenced dof_xlmember */
+	uint32_t dofxr_argn;		/* index of argument for DIF_OP_XLARG */
+} dof_xlref_t;
+
+#endif /* _LINUX_DTRACE_DOF_H */
diff --git a/include/uapi/linux/dtrace/dof_defines.h b/include/uapi/linux/dtrace/dof_defines.h
new file mode 100644
index 000000000000..5357d5e099cc
--- /dev/null
+++ b/include/uapi/linux/dtrace/dof_defines.h
@@ -0,0 +1,192 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_DOF_DEFINES_H
+#define _LINUX_DTRACE_DOF_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+/*
+ * DTrace programs can be persistently encoded in the DOF format so that they
+ * may be embedded in other programs (for example, in an ELF file) or in the
+ * dtrace driver configuration file for use in anonymous tracing.  The DOF
+ * format is versioned and extensible so that it can be revised and so that
+ * internal data structures can be modified or extended compatibly.  All DOF
+ * structures use fixed-size types, so the 32-bit and 64-bit representations
+ * are identical and consumers can use either data model transparently.
+ *
+ * The file layout is structured as follows:
+ *
+ * +---------------+-------------------+----- ... ----+---- ... ------+
+ * |   dof_hdr_t   |  dof_sec_t[ ... ] |   loadable   | non-loadable  |
+ * | (file header) | (section headers) | section data | section data  |
+ * +---------------+-------------------+----- ... ----+---- ... ------+
+ * |<------------ dof_hdr.dofh_loadsz --------------->|               |
+ * |<------------ dof_hdr.dofh_filesz ------------------------------->|
+ *
+ * The file header stores meta-data including a magic number, data model for
+ * the instrumentation, data encoding, and properties of the DIF code within.
+ * The header describes its own size and the size of the section headers.  By
+ * convention, an array of section headers follows the file header, and then
+ * the data for all loadable sections and unloadable sections.  This permits
+ * consumer code to easily download the headers and all loadable data into the
+ * DTrace driver in one contiguous chunk, omitting other extraneous sections.
+ *
+ * The section headers describe the size, offset, alignment, and section type
+ * for each section.  Sections are described using a set of #defines that tell
+ * the consumer what kind of data is expected.  Sections can contain links to
+ * other sections by storing a dof_secidx_t, an index into the section header
+ * array, inside of the section data structures.  The section header includes
+ * an entry size so that sections with data arrays can grow their structures.
+ *
+ * The DOF data itself can contain many snippets of DIF (i.e. >1 DIFOs), which
+ * are represented themselves as a collection of related DOF sections.  This
+ * permits us to change the set of sections associated with a DIFO over time,
+ * and also permits us to encode DIFOs that contain different sets of sections.
+ * When a DOF section wants to refer to a DIFO, it stores the dof_secidx_t of a
+ * section of type DOF_SECT_DIFOHDR.  This section's data is then an array of
+ * dof_secidx_t's which in turn denote the sections associated with this DIFO.
+ *
+ * This loose coupling of the file structure (header and sections) to the
+ * structure of the DTrace program itself (ECB descriptions, action
+ * descriptions, and DIFOs) permits activities such as relocation processing
+ * to occur in a single pass without having to understand D program structure.
+ *
+ * Finally, strings are always stored in ELF-style string tables along with a
+ * string table section index and string table offset.  Therefore strings in
+ * DOF are always arbitrary-length and not bound to the current implementation.
+ */
+
+#define DOF_ID_SIZE     16      /* total size of dofh_ident[] in bytes */
+
+#define DOF_ID_MAG0	0
+#define DOF_ID_MAG1	1
+#define DOF_ID_MAG2	2
+#define DOF_ID_MAG3	3
+#define DOF_ID_MODEL	4
+#define DOF_ID_ENCODING	5
+#define DOF_ID_VERSION	6
+#define DOF_ID_DIFVERS	7
+#define	DOF_ID_DIFIREG	8	/* DIF integer registers used by compiler */
+#define	DOF_ID_DIFTREG	9	/* DIF tuple registers used by compiler */
+#define	DOF_ID_PAD	10	/* start of padding bytes (all zeroes) */
+
+#define DOF_MAG_MAG0	0x7F	/* DOF_ID_MAG[0-3] */
+#define DOF_MAG_MAG1	'D'
+#define DOF_MAG_MAG2	'O'
+#define DOF_MAG_MAG3	'F'
+
+#define DOF_MAG_STRING	"\177DOF"
+#define DOF_MAG_STRLEN	4
+
+#define DOF_MODEL_NONE	0	/* DOF_ID_MODEL */
+#define DOF_MODEL_ILP32	1
+#define DOF_MODEL_LP64	2
+
+#ifdef _LP64
+#define DOF_MODEL_NATIVE	DOF_MODEL_LP64
+#else
+#define DOF_MODEL_NATIVE	DOF_MODEL_ILP32
+#endif
+
+#define DOF_ENCODE_NONE	0	/* DOF_ID_ENCODING */
+#define DOF_ENCODE_LSB	1
+#define DOF_ENCODE_MSB	2
+
+#ifndef _LITTLE_ENDIAN
+#define DOF_ENCODE_NATIVE	DOF_ENCODE_MSB
+#else
+#define DOF_ENCODE_NATIVE	DOF_ENCODE_LSB
+#endif
+
+#define DOF_VERSION_1	1
+#define DOF_VERSION_2	2
+#define DOF_VERSION	DOF_VERSION_2
+
+#define DOF_FL_VALID	0	/* mask of all valid dofh_flags bits */
+
+typedef uint32_t dof_secidx_t;	/* section header table index type */
+typedef uint32_t dof_stridx_t;	/* string table index type */
+
+#define	DOF_SECIDX_NONE	-1U	/* null value for section indices */
+#define	DOF_STRIDX_NONE	-1U	/* null value for string indices */
+
+#define	DOF_SECT_NONE		0	/* null section */
+#define	DOF_SECT_COMMENTS	1	/* compiler comments */
+#define	DOF_SECT_SOURCE		2	/* D program source code */
+#define	DOF_SECT_ECBDESC	3	/* dof_ecbdesc_t */
+#define	DOF_SECT_PROBEDESC	4	/* dof_probedesc_t */
+#define	DOF_SECT_ACTDESC	5	/* dof_actdesc_t array */
+#define	DOF_SECT_DIFOHDR	6	/* dof_difohdr_t (variable length) */
+#define	DOF_SECT_DIF		7	/* uint32_t array of byte code */
+#define	DOF_SECT_STRTAB		8	/* string table */
+#define	DOF_SECT_VARTAB		9	/* dtrace_difv_t array */
+#define	DOF_SECT_RELTAB		10	/* dof_relodesc_t array */
+#define	DOF_SECT_TYPTAB		11	/* dtrace_diftype_t array */
+#define	DOF_SECT_URELHDR	12	/* dof_relohdr_t (user relocations) */
+#define	DOF_SECT_KRELHDR	13	/* dof_relohdr_t (kernel relocations) */
+#define	DOF_SECT_OPTDESC	14	/* dof_optdesc_t array */
+#define	DOF_SECT_PROVIDER	15	/* dof_provider_t */
+#define	DOF_SECT_PROBES		16	/* dof_probe_t array */
+#define	DOF_SECT_PRARGS		17	/* uint8_t array (probe arg mappings) */
+#define	DOF_SECT_PROFFS		18	/* uint32_t array (probe arg offsets) */
+#define	DOF_SECT_INTTAB		19	/* uint64_t array */
+#define	DOF_SECT_UTSNAME	20	/* struct utsname */
+#define	DOF_SECT_XLTAB		21	/* dof_xlref_t array */
+#define	DOF_SECT_XLMEMBERS	22	/* dof_xlmember_t array */
+#define	DOF_SECT_XLIMPORT	23	/* dof_xlator_t */
+#define	DOF_SECT_XLEXPORT	24	/* dof_xlator_t */
+#define	DOF_SECT_PREXPORT	25	/* dof_secidx_t array (exported objs) */
+#define	DOF_SECT_PRENOFFS	26	/* uint32_t array (enabled offsets) */
+
+#define	DOF_SECF_LOAD		1	/* section should be loaded */
+
+#define DOF_SEC_ISLOADABLE(x)						      \
+		(((x) == DOF_SECT_ECBDESC) || ((x) == DOF_SECT_PROBEDESC) ||  \
+		((x) == DOF_SECT_ACTDESC) || ((x) == DOF_SECT_DIFOHDR) ||     \
+		((x) == DOF_SECT_DIF) || ((x) == DOF_SECT_STRTAB) ||	      \
+		((x) == DOF_SECT_VARTAB) || ((x) == DOF_SECT_RELTAB) ||	      \
+		((x) == DOF_SECT_TYPTAB) || ((x) == DOF_SECT_URELHDR) ||      \
+		((x) == DOF_SECT_KRELHDR) || ((x) == DOF_SECT_OPTDESC) ||     \
+		((x) == DOF_SECT_PROVIDER) || ((x) == DOF_SECT_PROBES) ||     \
+		((x) == DOF_SECT_PRARGS) || ((x) == DOF_SECT_PROFFS) ||	      \
+		((x) == DOF_SECT_INTTAB) || ((x) == DOF_SECT_XLTAB) ||	      \
+		((x) == DOF_SECT_XLMEMBERS) || ((x) == DOF_SECT_XLIMPORT) ||  \
+		((x) == DOF_SECT_XLIMPORT) || ((x) == DOF_SECT_XLEXPORT) ||   \
+		((x) == DOF_SECT_PREXPORT) || ((x) == DOF_SECT_PRENOFFS))
+
+#define	DOF_RELO_NONE	0		/* empty relocation entry */
+#define	DOF_RELO_SETX	1		/* relocate setx value */
+
+typedef uint32_t dof_attr_t;		/* encoded stability attributes */
+
+#define DOF_ATTR(n, d, c)	(((n) << 24) | ((d) << 16) | ((c) << 8))
+#define DOF_ATTR_NAME(a)	(((a) >> 24) & 0xff)
+#define DOF_ATTR_DATA(a)	(((a) >> 16) & 0xff)
+#define DOF_ATTR_CLASS(a)	(((a) >>  8) & 0xff)
+
+struct dof_hdr;
+struct dof_sec;
+struct dof_ecbdesc;
+struct dof_probedesc;
+struct dof_actdesc;
+struct dof_difohdr;
+struct dof_relohdr;
+struct dof_relodesc;
+struct dof_optdesc;
+struct dof_provider;
+struct dof_xlator;
+struct dof_xlmember;
+struct dof_xlref;
+
+#endif /* _LINUX_DTRACE_DOF_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/dtrace.h b/include/uapi/linux/dtrace/dtrace.h
new file mode 100644
index 000000000000..0ee9d35876ef
--- /dev/null
+++ b/include/uapi/linux/dtrace/dtrace.h
@@ -0,0 +1,33 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_H_
+#define _LINUX_DTRACE_H_
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/dif.h>
+#include <linux/dtrace/actions.h>
+#include <linux/dtrace/dof.h>
+#include <linux/dtrace/difo.h>
+#include <linux/dtrace/enabling.h>
+#include <linux/dtrace/metadesc.h>
+#include <linux/dtrace/options.h>
+#include <linux/dtrace/buffer.h>
+#include <linux/dtrace/status.h>
+#include <linux/dtrace/conf.h>
+#include <linux/dtrace/faults.h>
+#include <linux/dtrace/arg.h>
+#include <linux/dtrace/stability.h>
+#include <linux/dtrace/helpers.h>
+
+#endif /* _LINUX_DTRACE_H_ */
diff --git a/include/uapi/linux/dtrace/enabling.h b/include/uapi/linux/dtrace/enabling.h
new file mode 100644
index 000000000000..8aac2ab9ea8d
--- /dev/null
+++ b/include/uapi/linux/dtrace/enabling.h
@@ -0,0 +1,76 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_ENABLING_H
+#define _LINUX_DTRACE_ENABLING_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/difo_defines.h>
+#include <linux/dtrace/enabling_defines.h>
+
+/*
+ * When DTrace is tracking the description of a DTrace enabling entity (probe,
+ * predicate, action, ECB, record, etc.), it does so in a description
+ * structure.  These structures all end in "desc", and are used at both
+ * user-level and in the kernel -- but (with the exception of
+ * dtrace_probedesc_t) they are never passed between them.  Typically,
+ * user-level will use the description structures when assembling an enabling.
+ * It will then distill those description structures into a DOF object (see
+ * above), and send it into the kernel.  The kernel will again use the
+ * description structures to create a description of the enabling as it reads
+ * the DOF.  When the description is complete, the enabling will be actually
+ * created -- turning it into the structures that represent the enabling
+ * instead of merely describing it.  Not surprisingly, the description
+ * structures bear a strong resemblance to the DOF structures that act as their
+ * conduit.
+ */
+
+struct dtrace_predicate;
+
+typedef struct dtrace_probedesc {
+	dtrace_id_t dtpd_id;			/* probe identifier */
+	char dtpd_provider[DTRACE_PROVNAMELEN]; /* probe provider name */
+	char dtpd_mod[DTRACE_MODNAMELEN];	/* probe module name */
+	char dtpd_func[DTRACE_FUNCNAMELEN];	/* probe function name */
+	char dtpd_name[DTRACE_NAMELEN];		/* probe name */
+} dtrace_probedesc_t;
+
+typedef struct dtrace_repldesc {
+	struct dtrace_probedesc dtrpd_match;	/* probe descr. to match */
+	struct dtrace_probedesc dtrpd_create;	/* probe descr. to create */
+} dtrace_repldesc_t;
+
+typedef struct dtrace_preddesc {
+	struct dtrace_difo *dtpdd_difo;		/* pointer to DIF object */
+	struct dtrace_predicate *dtpdd_predicate; /* pointer to predicate */
+} dtrace_preddesc_t;
+
+typedef struct dtrace_actdesc {
+	struct dtrace_difo *dtad_difo;		/* pointer to DIF object */
+	struct dtrace_actdesc *dtad_next;	/* next action */
+	dtrace_actkind_t dtad_kind;		/* kind of action */
+	uint32_t dtad_ntuple;			/* number in tuple */
+	uint64_t dtad_arg;			/* action argument */
+	uint64_t dtad_uarg;			/* user argument */
+	int dtad_refcnt;			/* reference count */
+} dtrace_actdesc_t;
+
+typedef struct dtrace_ecbdesc {
+	struct dtrace_actdesc *dted_action;	/* action description(s) */
+	struct dtrace_preddesc dted_pred;	/* predicate description */
+	struct dtrace_probedesc dted_probe;	/* probe description */
+	uint64_t dted_uarg;			/* library argument */
+	int dted_refcnt;			/* reference count */
+} dtrace_ecbdesc_t;
+
+#endif /* _LINUX_DTRACE_ENABLING_H */
diff --git a/include/uapi/linux/dtrace/enabling_defines.h b/include/uapi/linux/dtrace/enabling_defines.h
new file mode 100644
index 000000000000..221c3efca015
--- /dev/null
+++ b/include/uapi/linux/dtrace/enabling_defines.h
@@ -0,0 +1,25 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_ENABLING_DEFINES_H
+#define _LINUX_DTRACE_ENABLING_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+struct dtrace_probedesc;
+struct dtrace_repldesc;
+struct dtrace_preddesc;
+struct dtrace_actdesc;
+struct dtrace_ecbdesc;
+
+#endif /* _LINUX_DTRACE_ENABLING_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/fasttrap.h b/include/uapi/linux/dtrace/fasttrap.h
new file mode 100644
index 000000000000..4dbf1a2a35cd
--- /dev/null
+++ b/include/uapi/linux/dtrace/fasttrap.h
@@ -0,0 +1,56 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_FASTTRAP_H
+#define _LINUX_DTRACE_FASTTRAP_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/fasttrap_defines.h>
+
+typedef enum fasttrap_probe_type {
+	DTFTP_NONE = 0,
+	DTFTP_ENTRY,
+	DTFTP_RETURN,
+	DTFTP_OFFSETS,
+	DTFTP_POST_OFFSETS,
+	DTFTP_IS_ENABLED
+} fasttrap_probe_type_t;
+
+typedef struct fasttrap_probe_spec {
+	pid_t ftps_pid;				/* task PID */
+	enum fasttrap_probe_type ftps_type;	/* probe type */
+	char ftps_func[DTRACE_FUNCNAMELEN];	/* probe function */
+	char ftps_mod[DTRACE_MODNAMELEN];	/* probe module */
+	uint64_t ftps_pc;			/* probe address */
+	uint64_t ftps_size;			/* function size (in bytes) */
+	uint8_t ftps_glen;			/* glob pattern length */
+	char ftps_gstr[1];			/* glob pattern string */
+} fasttrap_probe_spec_t;
+
+typedef uint8_t		fasttrap_instr_t;
+
+typedef struct fasttrap_instr_query {
+	uint64_t ftiq_pc;
+	pid_t ftiq_pid;
+	fasttrap_instr_t ftiq_instr;
+} fasttrap_instr_query_t;
+
+/*
+ * Include after the definitions, to get ioctl()s when fasttrap.h is included.
+ * fasttrap_ioctl.h also #includes this header, to get structures when it is
+ * included itself, as is done by headers_check.
+ */
+
+#include <linux/dtrace/fasttrap_ioctl.h>
+
+#endif /* _LINUX_DTRACE_FASTTRAP_H */
diff --git a/include/uapi/linux/dtrace/fasttrap_defines.h b/include/uapi/linux/dtrace/fasttrap_defines.h
new file mode 100644
index 000000000000..4bb07564e1c4
--- /dev/null
+++ b/include/uapi/linux/dtrace/fasttrap_defines.h
@@ -0,0 +1,25 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2019, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_FASTTRAP_DEFINES_H
+#define _LINUX_DTRACE_FASTTRAP_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+#ifndef __cplusplus
+enum fasttrap_probe_type;
+#endif
+struct fasttrap_probe_spec;
+struct fasttrap_instr_query;
+
+#endif /* _LINUX_DTRACE_FASTTRAP_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/fasttrap_ioctl.h b/include/uapi/linux/dtrace/fasttrap_ioctl.h
new file mode 100644
index 000000000000..b5a8b0731fb6
--- /dev/null
+++ b/include/uapi/linux/dtrace/fasttrap_ioctl.h
@@ -0,0 +1,19 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_FASTRRAP_IOCTL_H_
+#define _LINUX_DTRACE_FASTTRAP_IOCTL_H_
+
+#include <linux/ioctl.h>
+#include <linux/dtrace/fasttrap.h>
+
+#define FASTTRAPIOC		0xf4
+#define FASTTRAPIOC_MAKEPROBE	_IOW(FASTTRAPIOC, 1, struct fasttrap_probe_spec)
+#define FASTTRAPIOC_GETINSTR	_IOR(FASTTRAPIOC, 2, struct fasttrap_instr_query)
+
+#endif /* _LINUX_DTRACE_FASTTRAP_IOCTL_H_ */
diff --git a/include/uapi/linux/dtrace/faults.h b/include/uapi/linux/dtrace/faults.h
new file mode 100644
index 000000000000..afa2ae548fa6
--- /dev/null
+++ b/include/uapi/linux/dtrace/faults.h
@@ -0,0 +1,20 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_FAULTS_H
+#define _LINUX_DTRACE_FAULTS_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/faults_defines.h>
+
+#endif /* _LINUX_DTRACE_FAULTS_H */
diff --git a/include/uapi/linux/dtrace/faults_defines.h b/include/uapi/linux/dtrace/faults_defines.h
new file mode 100644
index 000000000000..d225f2e847e4
--- /dev/null
+++ b/include/uapi/linux/dtrace/faults_defines.h
@@ -0,0 +1,39 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_FAULTS_DEFINES_H
+#define _LINUX_DTRACE_FAULTS_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+/*
+ * The constants below DTRACEFLT_LIBRARY indicate probe processing faults;
+ * constants at or above DTRACEFLT_LIBRARY indicate faults in probe
+ * postprocessing at user-level.  Probe processing faults induce an ERROR
+ * probe and are replicated in unistd.d to allow users' ERROR probes to decode
+ * the error condition using thse symbolic labels.
+ */
+#define DTRACEFLT_UNKNOWN		0	/* Unknown fault */
+#define DTRACEFLT_BADADDR		1	/* Bad address */
+#define DTRACEFLT_BADALIGN		2	/* Bad alignment */
+#define DTRACEFLT_ILLOP			3	/* Illegal operation */
+#define DTRACEFLT_DIVZERO		4	/* Divide-by-zero */
+#define DTRACEFLT_NOSCRATCH		5	/* Out of scratch space */
+#define DTRACEFLT_KPRIV			6	/* Illegal kernel access */
+#define DTRACEFLT_UPRIV			7	/* Illegal user access */
+#define DTRACEFLT_TUPOFLOW		8	/* Tuple stack overflow */
+#define DTRACEFLT_BADSTACK		9	/* Bad stack */
+
+#define DTRACEFLT_LIBRARY		1000	/* Library-level fault */
+
+#endif /* _LINUX_DTRACE_FAULTS_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/helpers.h b/include/uapi/linux/dtrace/helpers.h
new file mode 100644
index 000000000000..553f23994881
--- /dev/null
+++ b/include/uapi/linux/dtrace/helpers.h
@@ -0,0 +1,101 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_HELPERS_H
+#define _LINUX_DTRACE_HELPERS_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/helpers_defines.h>
+
+/*
+ * DTrace Helpers
+ *
+ * In general, DTrace establishes probes in processes and takes actions on
+ * processes without knowing their specific user-level structures.  Instead of
+ * existing in the framework, process-specific knowledge is contained by the
+ * enabling D program -- which can apply process-specific knowledge by making
+ * appropriate use of DTrace primitives like copyin() and copyinstr() to
+ * operate on user-level data.  However, there may exist some specific probes
+ * of particular semantic relevance that the application developer may wish to
+ * explicitly export.  For example, an application may wish to export a probe
+ * at the point that it begins and ends certain well-defined transactions.  In
+ * addition to providing probes, programs may wish to offer assistance for
+ * certain actions.  For example, in highly dynamic environments (e.g., Java),
+ * it may be difficult to obtain a stack trace in terms of meaningful symbol
+ * names (the translation from instruction addresses to corresponding symbol
+ * names may only be possible in situ); these environments may wish to define
+ * a series of actions to be applied in situ to obtain a meaningful stack
+ * trace.
+ *
+ * These two mechanisms -- user-level statically defined tracing and assisting
+ * DTrace actions -- are provided via DTrace _helpers_.  Helpers are specified
+ * via DOF, but unlike enabling DOF, helper DOF may contain definitions of
+ * providers, probes and their arguments.  If a helper wishes to provide
+ * action assistance, probe descriptions and corresponding DIF actions may be
+ * specified in the helper DOF.  For such helper actions, however, the probe
+ * description describes the specific helper:  all DTrace helpers have the
+ * provider name "dtrace" and the module name "helper", and the name of the
+ * helper is contained in the function name (for example, the ustack() helper
+ * is named "ustack").  Any helper-specific name may be contained in the name
+ * (for example, if a helper were to have a constructor, it might be named
+ * "dtrace:helper:<helper>:init").  Helper actions are only called when the
+ * action that they are helping is taken.  Helper actions may only return DIF
+ * expressions, and may only call the following subroutines:
+ *
+ *    alloca()      <= Allocates memory out of the consumer's scratch space
+ *    bcopy()       <= Copies memory to scratch space
+ *    copyin()      <= Copies memory from user-level into consumer's scratch
+ *    copyinto()    <= Copies memory into a specific location in scratch
+ *    copyinstr()   <= Copies a string into a specific location in scratch
+ *
+ * Helper actions may only access the following built-in variables:
+ *
+ *    curthread     <= Current kthread_t pointer
+ *    tid           <= Current thread identifier
+ *    pid           <= Current process identifier
+ *    ppid          <= Parent process identifier
+ *    uid           <= Current user ID
+ *    gid           <= Current group ID
+ *    execname      <= Current executable name
+ *    zonename      <= Current zone name
+ *
+ * Helper actions may not manipulate or allocate dynamic variables, but they
+ * may have clause-local and statically-allocated global variables.  The
+ * helper action variable state is specific to the helper action -- variables
+ * used by the helper action may not be accessed outside of the helper
+ * action, and the helper action may not access variables that like outside
+ * of it.  Helper actions may not load from kernel memory at-large; they are
+ * restricting to loading current user state (via copyin() and variants) and
+ * scratch space.  As with probe enablings, helper actions are executed in
+ * program order.  The result of the helper action is the result of the last
+ * executing helper expression.
+ *
+ * Helpers -- composed of either providers/probes or probes/actions (or both)
+ * -- are added by opening the "helper" minor node, and issuing an ioctl(2)
+ * (DTRACEHIOC_ADDDOF) that specifies the dof_helper_t structure. This
+ * encapsulates the name and base address of the user-level library or
+ * executable publishing the helpers and probes as well as the DOF that
+ * contains the definitions of those helpers and probes.
+ *
+ * The DTRACEHIOC_ADD and DTRACEHIOC_REMOVE are left in place for legacy
+ * helpers and should no longer be used.  No other ioctls are valid on the
+ * helper minor node.
+ */
+
+typedef struct dof_helper {
+	char dofhp_mod[DTRACE_MODNAMELEN];	/* executable or library name */
+	uint64_t dofhp_addr;			/* base address of object */
+	uint64_t dofhp_dof;			/* address of helper DOF */
+} dof_helper_t;
+
+#endif /* _LINUX_DTRACE_HELPERS_H */
diff --git a/include/uapi/linux/dtrace/helpers_defines.h b/include/uapi/linux/dtrace/helpers_defines.h
new file mode 100644
index 000000000000..8bf52f058001
--- /dev/null
+++ b/include/uapi/linux/dtrace/helpers_defines.h
@@ -0,0 +1,21 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_HELPERS_DEFINES_H
+#define _LINUX_DTRACE_HELPERS_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+struct dof_helper;
+
+#endif /* _LINUX_DTRACE_HELPERS_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/ioctl.h b/include/uapi/linux/dtrace/ioctl.h
new file mode 100644
index 000000000000..ef2476af2629
--- /dev/null
+++ b/include/uapi/linux/dtrace/ioctl.h
@@ -0,0 +1,47 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+#ifndef _LINUX_DTRACE_IOCTL_H_
+#define _LINUX_DTRACE_IOCTL_H_
+
+#include <linux/ioctl.h>
+#include <linux/dtrace/arg.h>
+#include <linux/dtrace/buffer.h>
+#include <linux/dtrace/conf.h>
+#include <linux/dtrace/dof.h>
+#include <linux/dtrace/enabling.h>
+#include <linux/dtrace/helpers.h>
+#include <linux/dtrace/metadesc.h>
+#include <linux/dtrace/stability.h>
+#include <linux/dtrace/status.h>
+#include <linux/dtrace/cpu_defines.h>
+
+#define DTRACEIOC		0xd4
+#define DTRACEIOC_PROVIDER	_IOR(DTRACEIOC, 1, struct dtrace_providerdesc)
+#define DTRACEIOC_PROBES	_IOR(DTRACEIOC, 2, struct dtrace_probedesc)
+#define DTRACEIOC_BUFSNAP	_IOR(DTRACEIOC, 4, struct dtrace_bufdesc)
+#define DTRACEIOC_PROBEMATCH	_IOR(DTRACEIOC, 5, struct dtrace_probedesc)
+#define DTRACEIOC_ENABLE	_IOW(DTRACEIOC, 6, void *)
+#define DTRACEIOC_AGGSNAP	_IOR(DTRACEIOC, 7, struct dtrace_bufdesc)
+#define DTRACEIOC_EPROBE	_IOW(DTRACEIOC, 8, struct dtrace_eprobedesc)
+#define DTRACEIOC_PROBEARG	_IOR(DTRACEIOC, 9, struct dtrace_argdesc)
+#define DTRACEIOC_CONF		_IOR(DTRACEIOC, 10, struct dtrace_conf)
+#define DTRACEIOC_STATUS	_IOR(DTRACEIOC, 11, struct dtrace_status)
+#define DTRACEIOC_GO		_IOW(DTRACEIOC, 12, processorid_t)
+#define DTRACEIOC_STOP		_IOW(DTRACEIOC, 13, processorid_t)
+#define DTRACEIOC_AGGDESC	_IOR(DTRACEIOC, 15, struct dtrace_aggdesc)
+#define DTRACEIOC_FORMAT	_IOR(DTRACEIOC, 16, struct dtrace_fmtdesc)
+#define DTRACEIOC_DOFGET	_IOR(DTRACEIOC, 17, struct dof_hdr)
+#define DTRACEIOC_REPLICATE	_IOR(DTRACEIOC, 18, void *)
+
+#define DTRACEHIOC		0xd8
+#define DTRACEHIOC_ADD		_IOW(DTRACEHIOC, 1, struct dof_hdr)
+#define DTRACEHIOC_REMOVE	_IOW(DTRACEHIOC, 2, int)
+#define DTRACEHIOC_ADDDOF	_IOW(DTRACEHIOC, 3, struct dof_helper)
+
+#endif /* _LINUX_DTRACE_IOCTL_H */
diff --git a/include/uapi/linux/dtrace/metadesc.h b/include/uapi/linux/dtrace/metadesc.h
new file mode 100644
index 000000000000..a6b3d82b2c97
--- /dev/null
+++ b/include/uapi/linux/dtrace/metadesc.h
@@ -0,0 +1,81 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_METADESC_H
+#define _LINUX_DTRACE_METADESC_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/actions_defines.h>
+#include <linux/dtrace/metadesc_defines.h>
+
+/*
+ * DTrace separates the trace data stream from the metadata stream.  The only
+ * metadata tokens placed in the data stream are enabled probe identifiers
+ * (EPIDs) or (in the case of aggregations) aggregation identifiers.  In order
+ * to determine the structure of the data, DTrace consumers pass the token to
+ * the kernel, and receive in return a corresponding description of the enabled
+ * probe (via the dtrace_eprobedesc structure) or the aggregation (via the
+ * dtrace_aggdesc structure).  Both of these structures are expressed in terms
+ * of record descriptions (via the dtrace_recdesc structure) that describe the
+ * exact structure of the data.  Some record descriptions may also contain a
+ * format identifier; this additional bit of metadata can be retrieved from the
+ * kernel, for which a format description is returned via the dtrace_fmtdesc
+ * structure.  Note that all four of these structures must be bitness-neutral
+ * to allow for a 32-bit DTrace consumer on a 64-bit kernel.
+ */
+typedef struct dtrace_recdesc {
+	dtrace_actkind_t dtrd_action;		/* kind of action */
+	uint32_t dtrd_size;			/* size of record */
+	uint32_t dtrd_offset;			/* offset in ECB's data */
+	uint16_t dtrd_alignment;		/* required alignment */
+	uint16_t dtrd_format;			/* format, if any */
+	uint64_t dtrd_arg;			/* action argument */
+	uint64_t dtrd_uarg;			/* user argument */
+} dtrace_recdesc_t;
+
+typedef struct dtrace_eprobedesc {
+	dtrace_epid_t dtepd_epid;		/* enabled probe ID */
+	dtrace_id_t dtepd_probeid;		/* probe ID */
+	uint64_t dtepd_uarg;			/* library argument */
+	uint32_t dtepd_size;			/* total size */
+	int dtepd_nrecs;			/* number of records */
+	struct dtrace_recdesc dtepd_rec[1];	/* records themselves */
+} dtrace_eprobedesc_t;
+
+typedef struct dtrace_aggdesc {
+	DTRACE_PTR(char, dtagd_name);		/* not filled in by kernel */
+	dtrace_aggvarid_t dtagd_varid;		/* not filled in by kernel */
+	int dtagd_flags;			/* not filled in by kernel */
+	dtrace_aggid_t dtagd_id;		/* aggregation ID */
+	dtrace_epid_t dtagd_epid;		/* enabled probe ID */
+	uint32_t dtagd_size;			/* size in bytes */
+	int dtagd_nrecs;			/* number of records */
+	uint32_t dtagd_pad;			/* explicit padding */
+	struct dtrace_recdesc dtagd_rec[1];	/* record descriptions */
+} dtrace_aggdesc_t;
+
+typedef struct dtrace_fmtdesc {
+	DTRACE_PTR(char, dtfd_string);		/* format string */
+	int dtfd_length;			/* length of format string */
+	uint16_t dtfd_format;			/* format identifier */
+} dtrace_fmtdesc_t;
+
+#define DTRACE_SIZEOF_EPROBEDESC(desc)				\
+	(sizeof(struct dtrace_eprobedesc) + ((desc)->dtepd_nrecs ?  \
+	(((desc)->dtepd_nrecs - 1) * sizeof(struct dtrace_recdesc)) : 0))
+
+#define	DTRACE_SIZEOF_AGGDESC(desc)			       \
+	(sizeof(struct dtrace_aggdesc) + ((desc)->dtagd_nrecs ?     \
+	(((desc)->dtagd_nrecs - 1) * sizeof(struct dtrace_recdesc)) : 0))
+
+#endif /* _LINUX_DTRACE_METADESC_H */
diff --git a/include/uapi/linux/dtrace/metadesc_defines.h b/include/uapi/linux/dtrace/metadesc_defines.h
new file mode 100644
index 000000000000..b27cc28822c8
--- /dev/null
+++ b/include/uapi/linux/dtrace/metadesc_defines.h
@@ -0,0 +1,24 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_METADESC_DEFINES_H
+#define _LINUX_DTRACE_METADESC_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+struct dtrace_recdesc;
+struct dtrace_eprobedesc;
+struct dtrace_aggdesc;
+struct dtrace_fmtdesc;
+
+#endif /* _LINUX_DTRACE_METADESC_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/options.h b/include/uapi/linux/dtrace/options.h
new file mode 100644
index 000000000000..0a652ca2a148
--- /dev/null
+++ b/include/uapi/linux/dtrace/options.h
@@ -0,0 +1,20 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_OPTIONS_H
+#define _LINUX_DTRACE_OPTIONS_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/options_defines.h>
+
+#endif /* _LINUX_DTRACE_OPTIONS_H */
diff --git a/include/uapi/linux/dtrace/options_defines.h b/include/uapi/linux/dtrace/options_defines.h
new file mode 100644
index 000000000000..26009c84437e
--- /dev/null
+++ b/include/uapi/linux/dtrace/options_defines.h
@@ -0,0 +1,72 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2018, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_OPTIONS_DEFINES_H
+#define _LINUX_DTRACE_OPTIONS_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+/*
+ * Run-time DTrace options are set and retrieved via DOF_SECT_OPTDESC sections
+ * in a DOF image.  The dof_optdesc structure contains an option identifier and
+ * an option value.  The valid option identifiers are found below; the mapping
+ * between option identifiers and option identifying strings is maintained at
+ * user-level.  Note that the value of DTRACEOPT_UNSET is such that all of the
+ * following are potentially valid option values:  all positive integers, zero
+ * and negative one.  Some options (notably "bufpolicy" and "bufresize") take
+ * predefined tokens as their values; these are defined with
+ * DTRACEOPT_{option}_{token}.
+ */
+
+#define	DTRACEOPT_BUFSIZE	0	/* buffer size */
+#define	DTRACEOPT_BUFPOLICY	1	/* buffer policy */
+#define	DTRACEOPT_DYNVARSIZE	2	/* dynamic variable size */
+#define	DTRACEOPT_AGGSIZE	3	/* aggregation size */
+#define	DTRACEOPT_SPECSIZE	4	/* speculation size */
+#define	DTRACEOPT_NSPEC		5	/* number of speculations */
+#define	DTRACEOPT_STRSIZE	6	/* string size */
+#define	DTRACEOPT_CLEANRATE	7	/* dynvar cleaning rate */
+#define	DTRACEOPT_CPU		8	/* CPU to trace */
+#define	DTRACEOPT_BUFRESIZE	9	/* buffer resizing policy */
+#define	DTRACEOPT_GRABANON	10	/* grab anonymous state, if any */
+#define	DTRACEOPT_FLOWINDENT	11	/* indent function entry/return */
+#define	DTRACEOPT_QUIET		12	/* only output explicitly traced data */
+#define	DTRACEOPT_STACKFRAMES	13	/* number of stack frames */
+#define	DTRACEOPT_USTACKFRAMES	14	/* number of user stack frames */
+#define	DTRACEOPT_AGGRATE	15	/* aggregation snapshot rate */
+#define	DTRACEOPT_SWITCHRATE	16	/* buffer switching rate */
+#define	DTRACEOPT_STATUSRATE	17	/* status rate */
+#define	DTRACEOPT_DESTRUCTIVE	18	/* destructive actions allowed */
+#define	DTRACEOPT_STACKINDENT	19	/* output indent for stack traces */
+#define	DTRACEOPT_RAWBYTES	20	/* always print bytes in raw form */
+#define	DTRACEOPT_JSTACKFRAMES	21	/* number of jstack() frames */
+#define	DTRACEOPT_JSTACKSTRSIZE	22	/* size of jstack() string table */
+#define	DTRACEOPT_AGGSORTKEY	23	/* sort aggregations by key */
+#define	DTRACEOPT_AGGSORTREV	24	/* reverse-sort aggregations */
+#define	DTRACEOPT_AGGSORTPOS	25	/* agg. position to sort on */
+#define	DTRACEOPT_AGGSORTKEYPOS	26	/* agg. key position to sort on */
+#define	DTRACEOPT_QUIETRESIZE	27      /* quieten buffer-resize messages */
+#define	DTRACEOPT_NORESOLVE	28      /* prevent resolution of symbols */
+#define	DTRACEOPT_PCAPSIZE	29	/* number of bytes to be captured */
+#define	DTRACEOPT_MAX		30      /* number of options */
+
+#define	DTRACEOPT_UNSET		(dtrace_optval_t)-2	/* unset option */
+
+#define	DTRACEOPT_BUFPOLICY_RING	0	/* ring buffer */
+#define	DTRACEOPT_BUFPOLICY_FILL	1	/* fill buffer, then stop */
+#define	DTRACEOPT_BUFPOLICY_SWITCH	2	/* switch buffers */
+
+#define	DTRACEOPT_BUFRESIZE_AUTO	0	/* automatic resizing */
+#define	DTRACEOPT_BUFRESIZE_MANUAL	1	/* manual resizing */
+
+#endif /* _LINUX_DTRACE_OPTIONS_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/stability.h b/include/uapi/linux/dtrace/stability.h
new file mode 100644
index 000000000000..380effdab291
--- /dev/null
+++ b/include/uapi/linux/dtrace/stability.h
@@ -0,0 +1,52 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2015, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_STABILITY_H
+#define _LINUX_DTRACE_STABILITY_H
+
+#include <linux/dtrace/universal.h>
+#include <linux/dtrace/stability_defines.h>
+
+/*
+ * Each DTrace provider advertises the name and data stability of each of its
+ * probe description components, as well as its architectural dependencies.  The
+ * D compiler can query the provider attributes (dtrace_pattr_t) in order to
+ * compute the properties of an input program and report them.
+ */
+
+typedef struct dtrace_ppriv {
+	uint32_t dtpp_flags;			/* privilege flags */
+	uid_t dtpp_uid;				/* user ID */
+} dtrace_ppriv_t;
+
+typedef struct dtrace_attribute {
+	dtrace_stability_t dtat_name;		/* entity name stability */
+	dtrace_stability_t dtat_data;		/* entity data stability */
+	dtrace_class_t dtat_class;		/* entity data dependency */
+} dtrace_attribute_t;
+
+typedef struct dtrace_pattr {
+	struct dtrace_attribute dtpa_provider;	/* provider attributes */
+	struct dtrace_attribute dtpa_mod;	/* module attributes */
+	struct dtrace_attribute dtpa_func;	/* function attributes */
+	struct dtrace_attribute dtpa_name;	/* name attributes */
+	struct dtrace_attribute dtpa_args;	/* args[] attributes */
+} dtrace_pattr_t;
+
+typedef struct dtrace_providerdesc {
+	char dtvd_name[DTRACE_PROVNAMELEN];	/* provider name */
+	struct dtrace_pattr dtvd_attr;		/* stability attributes */
+	struct dtrace_ppriv dtvd_priv;		/* privileges required */
+} dtrace_providerdesc_t;
+
+#endif /* _LINUX_DTRACE_STABILITY_H */
diff --git a/include/uapi/linux/dtrace/stability_defines.h b/include/uapi/linux/dtrace/stability_defines.h
new file mode 100644
index 000000000000..ca58c5c03c2b
--- /dev/null
+++ b/include/uapi/linux/dtrace/stability_defines.h
@@ -0,0 +1,53 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_STABILITY_DEFINES_H
+#define _LINUX_DTRACE_STABILITY_DEFINES_H
+
+#include <linux/dtrace/universal.h>
+
+typedef uint8_t dtrace_stability_t;	/* stability code */
+typedef uint8_t dtrace_class_t;		/* architectural dependency class */
+
+#define	DTRACE_STABILITY_INTERNAL	0	/* private to DTrace itself */
+#define	DTRACE_STABILITY_PRIVATE	1	/* private to Sun (see docs) */
+#define	DTRACE_STABILITY_OBSOLETE	2	/* scheduled for removal */
+#define	DTRACE_STABILITY_EXTERNAL	3	/* not controlled by Sun */
+#define	DTRACE_STABILITY_UNSTABLE	4	/* new or rapidly changing */
+#define	DTRACE_STABILITY_EVOLVING	5	/* less rapidly changing */
+#define	DTRACE_STABILITY_STABLE		6	/* mature interface from Sun */
+#define	DTRACE_STABILITY_STANDARD	7	/* industry standard */
+#define	DTRACE_STABILITY_MAX		7	/* maximum valid stability */
+
+#define	DTRACE_CLASS_UNKNOWN	0	/* unknown architectural dependency */
+#define	DTRACE_CLASS_CPU	1	/* CPU-module-specific */
+#define	DTRACE_CLASS_PLATFORM	2	/* platform-specific (uname -i) */
+#define	DTRACE_CLASS_GROUP	3	/* hardware-group-specific (uname -m) */
+#define	DTRACE_CLASS_ISA	4	/* ISA-specific (uname -p) */
+#define	DTRACE_CLASS_COMMON	5	/* common to all systems */
+#define	DTRACE_CLASS_MAX	5	/* maximum valid class */
+
+#define DTRACE_PRIV_NONE	0x0000
+#define DTRACE_PRIV_KERNEL	0x0001
+#define DTRACE_PRIV_USER	0x0002
+#define DTRACE_PRIV_PROC	0x0004
+#define DTRACE_PRIV_OWNER	0x0008
+#define DTRACE_PRIV_ALL		(DTRACE_PRIV_KERNEL | DTRACE_PRIV_USER | \
+				 DTRACE_PRIV_PROC | DTRACE_PRIV_OWNER)
+
+struct dtrace_ppriv;
+struct dtrace_attribute;
+struct dtrace_pattr;
+struct dtrace_providerdesc;
+
+#endif /* _LINUX_DTRACE_STABILITY_DEFINES_H */
diff --git a/include/uapi/linux/dtrace/status.h b/include/uapi/linux/dtrace/status.h
new file mode 100644
index 000000000000..dc324199f170
--- /dev/null
+++ b/include/uapi/linux/dtrace/status.h
@@ -0,0 +1,50 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_STATUS_H
+#define _LINUX_DTRACE_STATUS_H
+
+#include <linux/dtrace/universal.h>
+
+/*
+ * The status of DTrace is relayed via the dtrace_status structure.  This
+ * structure contains members to count drops other than the capacity drops
+ * available via the buffer interface (see above).  This consists of dynamic
+ * drops (including capacity dynamic drops, rinsing drops and dirty drops), and
+ * speculative drops (including capacity speculative drops, drops due to busy
+ * speculative buffers and drops due to unavailable speculative buffers).
+ * Additionally, the status structure contains a field to indicate the number
+ * of "fill"-policy buffers have been filled and a boolean field to indicate
+ * that exit() has been called.  If the dtst_exiting field is non-zero, no
+ * further data will be generated until tracing is stopped (at which time any
+ * enablings of the END action will be processed); if user-level sees that
+ * this field is non-zero, tracing should be stopped as soon as possible.
+ */
+
+typedef struct dtrace_status {
+	uint64_t dtst_dyndrops;			/* dynamic drops */
+	uint64_t dtst_dyndrops_rinsing;		/* dyn drops due to rinsing */
+	uint64_t dtst_dyndrops_dirty;		/* dyn drops due to dirty */
+	uint64_t dtst_specdrops;		/* speculative drops */
+	uint64_t dtst_specdrops_busy;		/* spec drops due to busy */
+	uint64_t dtst_specdrops_unavail;	/* spec drops due to unavail */
+	uint64_t dtst_errors;			/* total errors */
+	uint64_t dtst_filled;			/* number of filled bufs */
+	uint64_t dtst_stkstroverflows;		/* stack string tab overflows */
+	uint64_t dtst_dblerrors;		/* errors in ERROR probes */
+	char dtst_killed;			/* non-zero if killed */
+	char dtst_exiting;			/* non-zero if exit() called */
+	char dtst_pad[6];			/* pad out to 64-bit align */
+} dtrace_status_t;
+
+#endif /* _LINUX_DTRACE_STATUS_H */
diff --git a/include/uapi/linux/dtrace/universal.h b/include/uapi/linux/dtrace/universal.h
new file mode 100644
index 000000000000..5c2f3f838fef
--- /dev/null
+++ b/include/uapi/linux/dtrace/universal.h
@@ -0,0 +1,47 @@
+/* SPDX-License-Identifier: UPL-1.0 */
+/*
+ * Licensed under the Universal Permissive License v 1.0 as shown at
+ * http://oss.oracle.com/licenses/upl.
+ *
+ * Copyright (c) 2009, 2013, Oracle and/or its affiliates. All rights reserved.
+ */
+
+/*
+ * Note: The contents of this file are private to the implementation of the
+ * DTrace subsystem and are subject to change at any time without notice.
+ */
+
+#ifndef _LINUX_DTRACE_UNIVERSAL_H_
+#define _LINUX_DTRACE_UNIVERSAL_H_
+
+#define	DTRACE_CPUALL		-1	/* all CPUs */
+#define	DTRACE_IDNONE		0	/* invalid probe identifier */
+#define	DTRACE_EPIDNONE		0	/* invalid enabled probe identifier */
+#define	DTRACE_AGGIDNONE	0	/* invalid aggregation identifier */
+#define	DTRACE_AGGVARIDNONE	0	/* invalid aggregation variable ID */
+#define	DTRACE_CACHEIDNONE	0	/* invalid predicate cache */
+#define	DTRACE_PROVNONE		0	/* invalid provider identifier */
+#define	DTRACE_METAPROVNONE	0	/* invalid meta-provider identifier */
+#define	DTRACE_ARGNONE		-1	/* invalid argument index */
+
+#define DTRACE_PROVNAMELEN	64
+#define DTRACE_MODNAMELEN	64
+#define DTRACE_FUNCNAMELEN	128
+#define DTRACE_NAMELEN		64
+#define DTRACE_FULLNAMELEN	(DTRACE_PROVNAMELEN + DTRACE_MODNAMELEN + \
+				 DTRACE_FUNCNAMELEN + DTRACE_NAMELEN + 4)
+#define DTRACE_ARGTYPELEN	128
+
+typedef uint16_t	dtrace_actkind_t;	/* action kind */
+
+typedef uint32_t	dtrace_aggid_t;		/* aggregation identifier */
+typedef uint32_t	dtrace_cacheid_t;	/* predicate cache identifier */
+typedef uint32_t	dtrace_epid_t;		/* enabled probe identifier */
+typedef uint32_t	dtrace_optid_t;		/* option identifier */
+typedef uint32_t	dtrace_specid_t;	/* speculation identifier */
+
+typedef uint64_t	dtrace_aggvarid_t;	/* aggregation variable id */
+typedef uint64_t	dtrace_genid_t;		/* generation identifier */
+typedef uint64_t	dtrace_optval_t;	/* option value */
+
+#endif /* _LINUX_DTRACE_UNIVERSAL_H_ */
diff --git a/init/Kconfig b/init/Kconfig
index 32fb3e9d5d39..bd2230906b99 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -2061,6 +2061,8 @@ config PROFILING
 	  Say Y here to enable the extended profiling support mechanisms used
 	  by profilers such as OProfile.
 
+source "kernel/dtrace/Kconfig"
+
 #
 # Place an empty function call at each tracepoint site. Can be
 # dynamically changed for a probe function.
diff --git a/init/main.c b/init/main.c
index aeef291bf28d..7b28a88120c9 100644
--- a/init/main.c
+++ b/init/main.c
@@ -97,6 +97,8 @@
 #include <linux/mem_encrypt.h>
 #include <linux/kcsan.h>
 #include <linux/init_syscalls.h>
+#include <linux/dtrace_cpu.h>
+#include <linux/dtrace_os.h>
 
 #include <asm/io.h>
 #include <asm/bugs.h>
@@ -1057,6 +1059,10 @@ asmlinkage __visible void __init __no_sanitize_address start_kernel(void)
 	sfi_init_late();
 	kcsan_init();
 
+#ifdef CONFIG_DTRACE
+	dtrace_os_init();
+#endif
+
 	/* Do the rest non-__init'ed, we're now alive */
 	arch_call_rest_init();
 
@@ -1519,6 +1525,10 @@ static noinline void __init kernel_init_freeable(void)
 
 	init_mm_internals();
 
+#ifdef CONFIG_DTRACE
+	dtrace_cpu_init();
+#endif
+
 	rcu_init_tasks_generic();
 	do_pre_smp_initcalls();
 	lockup_detector_init();
diff --git a/kernel/Makefile b/kernel/Makefile
index 320f1f3941b7..82734baba80c 100644
--- a/kernel/Makefile
+++ b/kernel/Makefile
@@ -124,6 +124,7 @@ obj-$(CONFIG_TORTURE_TEST) += torture.o
 obj-$(CONFIG_HAS_IOMEM) += iomem.o
 obj-$(CONFIG_RSEQ) += rseq.o
 obj-$(CONFIG_WATCH_QUEUE) += watch_queue.o
+obj-$(CONFIG_DTRACE) += dtrace/
 
 obj-$(CONFIG_RESOURCE_KUNIT_TEST) += resource_kunit.o
 obj-$(CONFIG_SYSCTL_KUNIT_TEST) += sysctl-test.o
diff --git a/kernel/dtrace/Kconfig b/kernel/dtrace/Kconfig
new file mode 100644
index 000000000000..854e4411343f
--- /dev/null
+++ b/kernel/dtrace/Kconfig
@@ -0,0 +1,54 @@
+#
+# Copyright (c) 2010, 2017, Oracle and/or its affiliates. All rights reserved.
+#
+
+menuconfig DTRACE
+	bool "DTrace (Dynamic Tracing) Support"
+	default y
+	depends on ARCH_SUPPORTS_DTRACE
+	select KALLSYMS
+	select KALLMODSYMS
+	select WAITFD
+	select CTF
+	help
+	  The DTrace dynamic tracing framework.
+
+if DTRACE
+
+config DT_CORE
+	tristate "DTrace core"
+	default m
+	help
+	  The core of DTrace: needed for all providers.
+
+if DT_CORE
+
+config DT_DT_TEST
+	tristate "DTrace Test Probe"
+	default m
+	help
+	  A test provider used by the testsuite.
+
+config DT_DEBUG
+	bool "DTrace debugging"
+	default m
+	help
+	  This controls the inclusion of various piece of code that perform
+	  internal checks within the DTrace core.  It also enables all the
+	  assertions within the DTrace code.
+
+if DT_DEBUG
+
+config DT_DEBUG_MUTEX
+	bool "DTrace mutex debugging"
+	default n
+	help
+	  This controls the use of DTrace specific wrappers to output debug
+	  messages whenever a mutex is locked or unlocked within the DTrace
+	  code (core and providers).
+
+endif	# DT_DEBUG
+
+endif	# DT_CORE
+
+endif   #DTRACE
diff --git a/kernel/dtrace/Makefile b/kernel/dtrace/Makefile
new file mode 100644
index 000000000000..872785327c3d
--- /dev/null
+++ b/kernel/dtrace/Makefile
@@ -0,0 +1,12 @@
+#
+# Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.
+#
+
+DT_CORE_ARCH_OBJS		= $(addprefix ../../arch/$(SRCARCH)/kernel/, \
+				    dtrace_util.o)
+
+ifdef CONFIG_DT_CORE
+obj-y				+= cyclic.o dtrace_os.o dtrace_cpu.o \
+				   dtrace_task.o dtrace_psinfo.o \
+				   $(DT_CORE_ARCH_OBJS)
+endif
diff --git a/kernel/dtrace/cyclic.c b/kernel/dtrace/cyclic.c
new file mode 100644
index 000000000000..6497ceee3782
--- /dev/null
+++ b/kernel/dtrace/cyclic.c
@@ -0,0 +1,526 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:	cyclic.c
+ * DESCRIPTION:	Minimal cyclic implementation
+ *
+ * Copyright (c) 2010, 2018, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/cpu.h>
+#include <linux/cyclic.h>
+#include <linux/hrtimer.h>
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/workqueue.h>
+
+static int		omni_enabled;
+
+#define _CYCLIC_CPU_UNDEF		(-1)
+#define _CYCLIC_CPU_OMNI		(-2)
+#define CYCLIC_IS_OMNI(cyc)		((cyc)->cpu == _CYCLIC_CPU_OMNI)
+
+struct cyclic_work {
+	struct work_struct	work;
+	struct cyclic		*cyc;
+};
+
+struct cyclic {
+	struct list_head		list;
+	int				cpu;
+	union {
+		struct {
+			struct cyc_time		when;
+			struct cyc_handler	hdlr;
+			uint32_t		pend;
+			struct hrtimer		timr;
+			struct cyclic_work	work;
+		} cyc;
+		struct {
+			struct cyc_omni_handler	hdlr;
+			struct list_head	cycl;
+		} omni;
+	};
+};
+
+static LIST_HEAD(cyclics);
+
+static void cyclic_fire(struct work_struct *work)
+{
+	struct cyclic_work *cwork = (struct cyclic_work *)work;
+	struct cyclic	   *cyc = cwork->cyc;
+	uint32_t	   cpnd, npnd;
+
+	do {
+		/*
+		 * We know that the 'pend' counter for the cyclic is non-zero.
+		 * So, we can start with calling the handler at least once.
+		 */
+		(*cyc->cyc.hdlr.cyh_func)(cyc->cyc.hdlr.cyh_arg);
+
+again:
+		/*
+		 * The 'pend' counter may be modified by cyclic_expire() while
+		 * we go through this loop.  We use an atomic compare-and-set
+		 * instruction to determine whether it got changed.  If so, we
+		 * retrieve the updated 'pend' value and try this again.
+		 *
+		 * Note that when the cyclic is being removed, the hrtimer will
+		 * be cancelled first, which ensures that 'pend' will no longer
+		 * be incremented.  When that happens, this loop will simply
+		 * run through the remaining pending calls, and terminate.
+		 */
+		cpnd = cyc->cyc.pend;
+		npnd = cpnd - 1;
+		if (cmpxchg(&cyc->cyc.pend, cpnd, npnd) != cpnd)
+			goto again;
+	} while (npnd > 0);
+}
+
+/*
+ * Timer expiration handler for cyclic hrtimers.  Cyclic worker functions must
+ * be able to perform a variety of tasks (including calling functions that
+ * could sleep), and therefore they cannot be called from interrupt context.
+ *
+ * We schedule a workqueue to do the actual work.
+ *
+ * But... under heavy load it is possible that the hrtimer will expire again
+ * before the workqueue had a chance to run.  That would lead to missed events
+ * which isn't quite acceptable.  Therefore, we use a counter to record how
+ * many times the timer has expired vs how many times the handler has been
+ * called.  The counter is incremented by this function upon hrtimer expiration
+ * and decremented by the cyclic_fire.  Note that the workqueue is responsible
+ * for calling the handler multiple times if the counter indicates that multiple
+ * invocation are pending.
+ *
+ * This function is called as hrtimer handler, and therefore runs in interrupt
+ * context, which by definition will ensure that manipulation of the 'pend'
+ * counter in the cyclic can be done without locking, and changes will appear
+ * atomic to the cyclic_fire().
+ *
+ * Moral of the story: the handler may not get called at the absolute times as
+ * requested, but it will be called the correct number of times.
+ */
+static enum hrtimer_restart cyclic_expire(struct hrtimer *timr)
+{
+	struct cyclic *cyc = container_of(timr, struct cyclic, cyc.timr);
+
+	/*
+	 * High priority cyclics call directly into their handler.  This means
+	 * that the handler must satisfy all requirements for executing code in
+	 * interrupt context.
+	 */
+	if (cyc->cyc.hdlr.cyh_level == CY_HIGH_LEVEL) {
+		(*cyc->cyc.hdlr.cyh_func)(cyc->cyc.hdlr.cyh_arg);
+		goto done;
+	}
+
+	/*
+	 * Increment the 'pend' counter, in case the work is already set to
+	 * run.  If the counter was 0 upon entry, we need to schedule the
+	 * work.  If the increment wraps the counter back to 0, we admit
+	 * defeat, and reset it to its max value.
+	 */
+	if (cyc->cyc.pend++ == 0)
+		schedule_work_on(cyc->cpu,
+				 (struct work_struct *)&cyc->cyc.work);
+	else if (cyc->cyc.pend == 0)
+		cyc->cyc.pend = UINT_MAX;
+
+done:
+	/*
+	 * Prepare the timer for the next expiration.
+	 */
+	if (cyc->cyc.when.cyt_interval == CY_INTERVAL_INF)
+		return HRTIMER_NORESTART;
+
+	hrtimer_forward_now(timr, cyc->cyc.when.cyt_interval);
+
+	return HRTIMER_RESTART;
+}
+
+struct cyclic *cyclic_new(int omni)
+{
+	struct cyclic *cyc;
+
+	cyc = kmalloc(sizeof(struct cyclic), GFP_KERNEL);
+	if (cyc == NULL)
+		return NULL;
+
+	INIT_LIST_HEAD(&cyc->list);
+
+	if (!omni) {
+		cyc->cpu = _CYCLIC_CPU_UNDEF;
+		cyc->cyc.pend = 0;
+		hrtimer_init(&cyc->cyc.timr, CLOCK_MONOTONIC,
+			     HRTIMER_MODE_REL_PINNED);
+		cyc->cyc.timr.function = cyclic_expire;
+		cyc->cyc.work.cyc = cyc;
+		INIT_WORK((struct work_struct *)&cyc->cyc.work, cyclic_fire);
+	} else {
+		cyc->cpu = _CYCLIC_CPU_OMNI;
+		INIT_LIST_HEAD(&cyc->omni.cycl);
+	}
+
+	return cyc;
+}
+
+static inline void cyclic_restart(struct cyclic *cyc)
+{
+	if (cyc->cyc.when.cyt_interval == CY_INTERVAL_INF)
+		return;
+
+	if (cyc->cyc.when.cyt_when == 0)
+		hrtimer_start(&cyc->cyc.timr, cyc->cyc.when.cyt_interval,
+			      HRTIMER_MODE_REL_PINNED);
+	else
+		hrtimer_start(&cyc->cyc.timr, cyc->cyc.when.cyt_when,
+			      HRTIMER_MODE_ABS_PINNED);
+}
+
+/*
+ * Add a new cyclic to the system.
+ */
+cyclic_id_t cyclic_add(struct cyc_handler *hdlr, struct cyc_time *when)
+{
+	struct cyclic *cyc;
+
+	if (hdlr == NULL || when == NULL)
+		return CYCLIC_NONE;
+
+	cyc = cyclic_new(0);
+	if (cyc == NULL)
+		return CYCLIC_NONE;
+
+	list_add(&cyc->list, &cyclics);
+	cyc->cpu = smp_processor_id();
+	cyc->cyc.when = *when;
+	cyc->cyc.hdlr = *hdlr;
+
+	cyclic_restart(cyc);
+
+	return (cyclic_id_t)cyc;
+}
+EXPORT_SYMBOL(cyclic_add);
+
+static void cyclic_omni_xcall(struct cyclic *cyc)
+{
+	cyclic_restart(cyc);
+}
+
+/*
+ * Add a new cyclic to the system.
+ */
+static void cyclic_add_pinned(int cpu, struct cyclic *omni,
+			      struct cyc_handler *hdlr, struct cyc_time *when)
+{
+	struct cyclic *cyc;
+
+	cyc = cyclic_new(0);
+	if (cyc == NULL)
+		return;
+
+	list_add(&cyc->list, &omni->omni.cycl);
+	cyc->cpu = cpu;
+	cyc->cyc.when = *when;
+	cyc->cyc.hdlr = *hdlr;
+
+	smp_call_function_single(cpu, (smp_call_func_t)cyclic_omni_xcall,
+				 cyc, 1);
+}
+
+/*
+ * Start a cyclic on a specific CPU as sub-cyclic to an omni-present cyclic.
+ */
+static void cyclic_omni_start(struct cyclic *omni, int cpu)
+{
+	struct cyc_time		when;
+	struct cyc_handler	hdlr;
+
+	omni->omni.hdlr.cyo_online(omni->omni.hdlr.cyo_arg, cpu, &hdlr, &when);
+	cyclic_add_pinned(cpu, omni, &hdlr, &when);
+}
+
+#ifdef CONFIG_HOTPLUG_CPU
+static int cyclic_cpu_offline(unsigned int cpu)
+{
+	struct cyclic *cyc;
+
+	list_for_each_entry(cyc, &cyclics, list) {
+		struct cyclic *c, *n;
+
+		if (!CYCLIC_IS_OMNI(cyc))
+			continue;
+
+		list_for_each_entry_safe(c, n, &cyc->omni.cycl, list) {
+			if (c->cpu == cpu)
+				cyclic_remove((cyclic_id_t)c);
+		}
+	}
+	return 0;
+}
+
+static int cyclic_cpu_online(unsigned int cpu)
+{
+	struct cyclic *cyc;
+
+	list_for_each_entry(cyc, &cyclics, list) {
+		struct cyclic *c, *n;
+
+		if (!CYCLIC_IS_OMNI(cyc))
+			continue;
+
+		list_for_each_entry_safe(c, n, &cyc->omni.cycl, list) {
+			if (c->cpu == cpu)
+				break;
+		}
+
+		if (c->cpu == cpu)
+			continue;
+
+		cyclic_omni_start(cyc, cpu);
+	}
+	return 0;
+}
+#endif
+
+/*
+ * Add a new omnipresent cyclic to the system.
+ */
+cyclic_id_t cyclic_add_omni(struct cyc_omni_handler *omni)
+{
+	int		cpu;
+	struct cyclic	*cyc;
+
+	cyc = cyclic_new(1);
+	if (cyc == NULL)
+		return CYCLIC_NONE;
+
+	list_add(&cyc->list, &cyclics);
+	cyc->omni.hdlr = *omni;
+
+	for_each_online_cpu(cpu)
+		cyclic_omni_start(cyc, cpu);
+
+	return (cyclic_id_t)cyc;
+}
+EXPORT_SYMBOL(cyclic_add_omni);
+
+/*
+ * Remove a specific cyclic from the system.
+ */
+void cyclic_remove(cyclic_id_t id)
+{
+	struct cyclic	*cyc = (struct cyclic *)id;
+
+	if (CYCLIC_IS_OMNI(cyc)) {
+		struct cyclic *child, *n;
+
+		/*
+		 * If this is an omni-present cyclic, we first need to remove
+		 * all the associated per-CPU cyclics.  Note that the recursive
+		 * call into cyclic_remove() for a child cyclic will remove it
+		 * from the list of per-CPU cyclics associated with the
+		 * omni-present cyclic, so we do not need to handle that here.
+		 */
+		list_for_each_entry_safe(child, n, &cyc->omni.cycl, list)
+			cyclic_remove((cyclic_id_t)child);
+	} else {
+		/*
+		 * We know that hrtimer_cancel() will wait for the timer
+		 * callback to finish if it is being executed at the time of
+		 * making this call.  It is therefore guaranteed that 'pend'
+		 * will no longer get incremented.
+		 *
+		 * The call to cancel_work_sync() will wait for the workqueue
+		 * handler to finish also, and since the handler always brings
+		 * 'pend' down to zero prior to returning, it is guaranteed that
+		 * (1) all pending handler calls will be made before
+		 *     cyclic_remove() returns
+		 * (2) the amount of work to do before returning is finite.
+		 */
+		hrtimer_cancel(&cyc->cyc.timr);
+		cancel_work_sync((struct work_struct *)&cyc->cyc.work);
+	}
+
+	list_del(&cyc->list);
+	kfree(cyc);
+}
+EXPORT_SYMBOL(cyclic_remove);
+
+struct cyclic_reprog {
+	cyclic_id_t	cycid;
+	ktime_t		delta;
+};
+
+static void cyclic_reprogram_xcall(struct cyclic_reprog *creprog)
+{
+	cyclic_reprogram(creprog->cycid, creprog->delta);
+}
+
+/*
+ * Reprogram cyclic to fire with given delta from now.
+ *
+ * The underlying design makes it safe to call cyclic_reprogram from whithin a
+ * cyclic handler without race with cyclic_remove. If called from outside of the
+ * cyclic handler it is up to the owner to ensure to not call cyclic_reprogram
+ * after call to cyclic_remove.
+ *
+ * This function cannot be called from interrupt/bottom half contexts.
+ */
+void cyclic_reprogram(cyclic_id_t id, ktime_t delta)
+{
+	struct cyclic *cyc = (struct cyclic *)id;
+
+	/*
+	 * For omni present cyclic we reprogram child for current CPU.
+	 */
+	if (CYCLIC_IS_OMNI(cyc)) {
+		struct cyclic *c, *n;
+
+		list_for_each_entry_safe(c, n, &cyc->omni.cycl, list) {
+			if (c->cpu != smp_processor_id())
+				continue;
+
+			hrtimer_start(&c->cyc.timr, delta,
+				      HRTIMER_MODE_ABS_PINNED);
+
+			break;
+		}
+
+		return;
+	}
+
+	/*
+	 * Regular cyclic reprogram must ensure that the timer remains bound
+	 * to the CPU it was registered on. In case we are called from
+	 * different CPU we use xcall to trigger reprogram from correct cpu.
+	 */
+	if (cyc->cpu != smp_processor_id()) {
+		struct cyclic_reprog creprog = {
+			.cycid = id,
+			.delta = delta,
+		};
+
+		smp_call_function_single(cyc->cpu, (smp_call_func_t)
+					 cyclic_reprogram_xcall, &creprog, 1);
+	} else {
+		hrtimer_start(&cyc->cyc.timr, delta, HRTIMER_MODE_REL_PINNED);
+	}
+}
+EXPORT_SYMBOL(cyclic_reprogram);
+
+static void *s_start(struct seq_file *seq, loff_t *pos)
+{
+	loff_t		n = *pos;
+	struct cyclic	*cyc;
+
+	list_for_each_entry(cyc, &cyclics, list) {
+		if (n == 0)
+			return cyc;
+
+		n--;
+	}
+
+	return NULL;
+}
+
+static void *s_next(struct seq_file *seq, void *p, loff_t *pos)
+{
+	struct cyclic	*cyc = p;
+
+	++*pos;
+
+	cyc = list_entry(cyc->list.next, struct cyclic, list);
+	if (&cyc->list == &cyclics)
+		return NULL;
+
+	return cyc;
+}
+
+static void s_stop(struct seq_file *seq, void *p)
+{
+}
+
+static int s_show(struct seq_file *seq, void *p)
+{
+	struct cyclic	*cyc = p;
+
+	if (CYCLIC_IS_OMNI(cyc)) {
+		struct cyclic	*c;
+
+		seq_puts(seq, "Omni-present cyclic:\n");
+		list_for_each_entry(c, &cyc->omni.cycl, list)
+			seq_printf(seq,
+				   "  CPU-%d: %c %lld ns hdlr %pB arg %llx\n",
+				   c->cpu,
+				   c->cyc.hdlr.cyh_level == CY_HIGH_LEVEL
+					? 'H' : 'l',
+				   c->cyc.when.cyt_interval,
+				   c->cyc.hdlr.cyh_func,
+				   (uint64_t)c->cyc.hdlr.cyh_arg);
+	} else
+		seq_printf(seq, "CPU-%d: %c %lld ns hdlr %pB arg %llx\n",
+			   cyc->cpu,
+			   cyc->cyc.hdlr.cyh_level == CY_HIGH_LEVEL
+				? 'H' : 'l',
+			   cyc->cyc.when.cyt_interval,
+			   cyc->cyc.hdlr.cyh_func,
+			   (uint64_t)cyc->cyc.hdlr.cyh_arg);
+
+	return 0;
+}
+
+static const struct seq_operations	cyclicinfo_ops = {
+	.start	= s_start,
+	.next	= s_next,
+	.stop	= s_stop,
+	.show	= s_show,
+};
+
+static int cyclicinfo_open(struct inode *inode, struct file *file)
+{
+	return seq_open(file, &cyclicinfo_ops);
+}
+
+static const struct proc_ops proc_cyclicinfo_ops = {
+	.proc_open	= cyclicinfo_open,
+	.proc_read	= seq_read,
+	.proc_lseek	= seq_lseek,
+	.proc_release	= seq_release,
+};
+
+static int __init cyclic_init(void)
+{
+	int	ret;
+
+	proc_create("cyclicinfo", 0400, NULL, &proc_cyclicinfo_ops);
+
+#ifdef CONFIG_HOTPLUG_CPU
+	if (!omni_enabled) {
+		ret = cpuhp_setup_state_nocalls(CPUHP_AP_CYCLIC_STARTING,
+						"Cyclic omni-timer starting",
+						cyclic_cpu_online,
+						cyclic_cpu_offline);
+		if (ret)
+			pr_warn_once("Cannot enable cyclic omni timer\n");
+		else
+			omni_enabled = 1;
+	}
+#endif
+
+	return 0;
+}
+module_init(cyclic_init);
diff --git a/kernel/dtrace/dtrace_cpu.c b/kernel/dtrace/dtrace_cpu.c
new file mode 100644
index 000000000000..1bc6e3bb4ce0
--- /dev/null
+++ b/kernel/dtrace/dtrace_cpu.c
@@ -0,0 +1,61 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:	dtrace_cpu.c
+ * DESCRIPTION:	DTrce - per-CPU state
+ *
+ * Copyright (c) 2010, 2014, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/dtrace_cpu.h>
+#include <linux/module.h>
+#include <asm/dtrace_cpuinfo.h>
+
+DEFINE_PER_CPU_SHARED_ALIGNED(struct cpu_core, dtrace_cpu_core);
+EXPORT_PER_CPU_SYMBOL(dtrace_cpu_core);
+
+DEFINE_PER_CPU_SHARED_ALIGNED(struct cpuinfo, dtrace_cpu_info);
+EXPORT_PER_CPU_SYMBOL(dtrace_cpu_info);
+
+void dtrace_cpu_init(void)
+{
+	int	cpu;
+
+	/*
+	 * Force this type into the CTF for the sake of userspace's
+	 * ABI requirements.
+	 */
+	cpuinfo_t *dummy __attribute__((__unused__)) = NULL;
+
+	for_each_present_cpu(cpu) {
+		cpuinfo_arch_t		*ci = &cpu_data(cpu);
+		struct cpuinfo		*cpui = per_cpu_info(cpu);
+		struct cpu_core		*cpuc = per_cpu_core(cpu);
+
+		cpui->cpu_id = cpu;
+		cpui->cpu_pset = 0;
+		cpui->cpu_chip = dtrace_cpuinfo_chip(ci);
+		cpui->cpu_lgrp = 0;
+		cpui->cpu_info = ci;
+
+		cpuc->cpuc_dtrace_flags = 0;
+		cpuc->cpuc_dcpc_intr_state = 0;
+		cpuc->cpuc_dtrace_illval = 0;
+		mutex_init(&cpuc->cpuc_pid_lock);
+
+		cpuc->cpu_dtrace_regs = NULL;
+		cpuc->cpu_dtrace_caller = 0;
+		rwlock_init(&cpuc->cpu_ft_lock);
+
+		cpuc->cpuc_current_probe = DTRACE_IDNONE;
+	}
+}
diff --git a/kernel/dtrace/dtrace_os.c b/kernel/dtrace/dtrace_os.c
new file mode 100644
index 000000000000..d023f3913323
--- /dev/null
+++ b/kernel/dtrace/dtrace_os.c
@@ -0,0 +1,332 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:	dtrace_os.c
+ * DESCRIPTION:	DTrace - OS support functions
+ *
+ * Copyright (c) 2010, 2018, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/binfmts.h>
+#include <linux/dtrace_cpu.h>
+#include <linux/dtrace_os.h>
+#include <linux/fs.h>
+#include <linux/hardirq.h>
+#include <linux/interrupt.h>
+#include <linux/kdebug.h>
+#include <linux/module.h>
+#include <linux/moduleloader.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/stacktrace.h>
+#include <linux/timekeeping.h>
+#include <linux/vmalloc.h>
+#include <linux/kallsyms.h>
+#include <linux/uaccess.h>
+#include <linux/workqueue.h>
+#include <asm/ptrace.h>
+#include <linux/init_task.h>
+#include <linux/sched/mm.h>
+#include <linux/shmem_fs.h>
+#include <linux/dtrace_task_impl.h>
+
+/*
+ * OS SPECIFIC DTRACE SETUP
+ */
+
+/*
+ * DTrace pseudo module that represents vmlinux (the kernel itself).
+ * Since we populate its sdt data members only once, it can be marked
+ * as RO after init.
+ */
+struct module		*dtrace_kmod __ro_after_init = NULL;
+EXPORT_SYMBOL(dtrace_kmod);
+
+int			dtrace_ustackdepth_max = 2048;
+
+struct kmem_cache	*dtrace_pdata_cachep = NULL;
+
+void __init dtrace_os_init(void)
+{
+	/*
+	 * Setup for module handling.
+	 */
+	dtrace_pdata_cachep = kmem_cache_create("dtrace_pdata_cache",
+				sizeof(struct dtrace_module), 0,
+				SLAB_HWCACHE_ALIGN|SLAB_PANIC, NULL);
+	if (dtrace_pdata_cachep == NULL)
+		pr_debug("Can't allocate kmem cache for pdata\n");
+
+	/*
+	 * We need to set up a psinfo structure for PID 0 (swapper).
+	 */
+	dtrace_task_os_init();
+	dtrace_psinfo_os_init();
+	dtrace_task_init(&init_task);
+	dtrace_psinfo_alloc(&init_task);
+}
+
+/*
+ * MODULE SUPPORT FUNCTIONS
+ */
+extern struct list_head *dtrace_modules;
+
+/*
+ * Iterate over all loaded kernel modules.  This is required until the linux
+ * kernel receives its own module iterator.
+ */
+void dtrace_for_each_module(for_each_module_fn func, void *arg)
+{
+	struct module *mp;
+
+	if (func == NULL)
+		return;
+
+	/* The dtrace fake module is not in the list. */
+	func(arg, dtrace_kmod);
+
+	list_for_each_entry(mp, dtrace_modules, list) {
+
+#ifdef MODULES_VADDR
+		if ((uintptr_t)mp < MODULES_VADDR ||
+		    (uintptr_t)mp >= MODULES_END)
+			continue;
+#else
+		if ((uintptr_t)mp < VMALLOC_START ||
+		    (uintptr_t)mp >= VMALLOC_END)
+			continue;
+#endif
+
+		func(arg, mp);
+	}
+}
+EXPORT_SYMBOL_GPL(dtrace_for_each_module);
+
+
+void dtrace_mod_pdata_alloc(struct module *mp)
+{
+	struct dtrace_module *pdata;
+
+	pdata = kmem_cache_alloc(dtrace_pdata_cachep, GFP_KERNEL | __GFP_ZERO);
+	if (pdata == NULL) {
+		mp->pdata = NULL;
+		return;
+	}
+
+	dtrace_mod_pdata_init(pdata);
+	mp->pdata = pdata;
+}
+
+void dtrace_mod_pdata_free(struct module *mp)
+{
+	struct dtrace_module *pdata = mp->pdata;
+
+	if (mp->pdata == NULL)
+		return;
+
+	mp->pdata = NULL;
+	dtrace_mod_pdata_cleanup(pdata);
+	kmem_cache_free(dtrace_pdata_cachep, pdata);
+}
+
+/*
+ * This function is called with module_mutex held.
+ */
+int dtrace_destroy_prov(struct module *mp)
+{
+	struct dtrace_module *pdata = mp->pdata;
+
+	if (pdata != NULL && pdata->prov_exit != NULL)
+		return pdata->prov_exit();
+
+	return 1;
+}
+
+/*---------------------------------------------------------------------------*\
+(* TIME SUPPORT FUNCTIONS                                                    *)
+\*---------------------------------------------------------------------------*/
+enum dtrace_vtime_state	dtrace_vtime_active = 0;
+
+/*
+ * Until Linux kernel gains lock-free realtime clock access we are maintaining
+ * our own version for lock-free access from within a probe context.
+ */
+static struct dtrace_time_fast {
+	seqcount_latch_t	dtwf_seq;
+	ktime_t			dtwf_offsreal[2];
+} dtrace_time ____cacheline_aligned;
+
+/*
+ * Callback from timekeeper code that allows dtrace to update its own time data.
+ */
+void dtrace_update_time(struct timekeeper *tk)
+{
+	raw_write_seqcount_latch(&dtrace_time.dtwf_seq);
+	dtrace_time.dtwf_offsreal[0] = tk->offs_real;
+	raw_write_seqcount_latch(&dtrace_time.dtwf_seq);
+	dtrace_time.dtwf_offsreal[1] = tk->offs_real;
+}
+
+/* Lock free walltime */
+ktime_t dtrace_get_walltime(void)
+{
+	u64 nsec = ktime_get_mono_fast_ns();
+	unsigned int seq;
+	ktime_t offset;
+
+	do {
+		seq = raw_read_seqcount_latch(&dtrace_time.dtwf_seq);
+		offset = dtrace_time.dtwf_offsreal[seq & 0x1];
+	} while (read_seqcount_latch_retry(&dtrace_time.dtwf_seq, seq));
+
+	return ktime_add_ns(offset, nsec);
+}
+EXPORT_SYMBOL(dtrace_get_walltime);
+
+ktime_t dtrace_gethrtime(void)
+{
+	return ns_to_ktime(ktime_get_raw_fast_ns());
+}
+EXPORT_SYMBOL(dtrace_gethrtime);
+
+/* Needed for lockstat probes where we cannot include ktime.h */
+u64 dtrace_gethrtime_ns(void)
+{
+	return ktime_get_raw_fast_ns();
+}
+EXPORT_SYMBOL(dtrace_gethrtime_ns);
+
+void dtrace_vtime_enable(void)
+{
+	enum dtrace_vtime_state	old, new;
+
+	do {
+		old = dtrace_vtime_active;
+		if (old == DTRACE_VTIME_ACTIVE) {
+			pr_warn_once("DTrace virtual time already enabled");
+			return;
+		}
+
+		new = DTRACE_VTIME_ACTIVE;
+	} while (cmpxchg(&dtrace_vtime_active, old, new) != old);
+}
+EXPORT_SYMBOL(dtrace_vtime_enable);
+
+void dtrace_vtime_disable(void)
+{
+	int	old, new;
+
+	do {
+		old = dtrace_vtime_active;
+		if (old == DTRACE_VTIME_INACTIVE) {
+			pr_warn_once("DTrace virtual time already disabled");
+			return;
+		}
+
+		new = DTRACE_VTIME_INACTIVE;
+	} while (cmpxchg(&dtrace_vtime_active, old, new) != old);
+}
+EXPORT_SYMBOL(dtrace_vtime_disable);
+
+void dtrace_vtime_switch(struct task_struct *prev, struct task_struct *next)
+{
+	struct dtrace_task *dprev = prev->dt_task;
+	struct dtrace_task *dnext = next->dt_task;
+	ktime_t	now = dtrace_gethrtime();
+
+	if (dprev != NULL && ktime_nz(dprev->dt_start)) {
+		dprev->dt_vtime = ktime_add(dprev->dt_vtime,
+					       ktime_sub(now,
+							 dprev->dt_start));
+		dprev->dt_start = ktime_set(0, 0);
+	}
+
+	if (dnext != NULL)
+		dnext->dt_start = now;
+}
+
+void dtrace_stacktrace(struct stacktrace_state *st)
+{
+	int	i;
+
+	if ((st->flags & STACKTRACE_TYPE) == STACKTRACE_USER) {
+		dtrace_user_stacktrace(st);
+		return;
+	}
+
+	if (st->pcs == NULL) {
+		st->depth = 0;
+		return;
+	}
+
+	st->depth = stack_trace_save((long unsigned int *) st->pcs,
+				     st->limit ? st->limit : 512, st->depth);
+
+	/*
+	 * For entirely unknown reasons, the save_stack_trace() implementation
+	 * on x86_64 adds a ULONG_MAX entry after the last stack trace entry.
+	 * This might be a sentinel value, but given that struct stack_trace
+	 * already contains a nr_entries counter, this seems rather pointless.
+	 * Alas, we need to add a special case for that...  And to make matters
+	 * worse, it actually does this only when there is room for it (i.e.
+	 * when nr_entries < max_entries).
+	 * Since ULONG_MAX is never a valid PC, we can just check for that.
+	 */
+#if defined(CONFIG_X86_64) || defined(CONFIG_ARM64)
+	if (st->depth && st->pcs[st->depth - 1] == ULONG_MAX)
+		st->depth--;
+#endif
+
+	if (st->fps != NULL) {
+		for (i = 0; i < st->limit; i++)
+			st->fps[i] = 0;
+	}
+}
+EXPORT_SYMBOL(dtrace_stacktrace);
+
+/*
+ * INVALID OPCODE AND PAGE FAULT HANDLING
+ */
+static struct notifier_block	dtrace_die = {
+	.notifier_call = dtrace_die_notifier,
+	.priority = 0x7fffffff
+};
+
+static int	dtrace_enabled;
+
+/*
+ * DTrace enable/disable must be called with dtrace_lock being held. It is not
+ * possible to check for safety here with an ASSERT as the lock itself is in the
+ * DTrace Framework kernel module.
+ */
+int dtrace_enable(void)
+{
+	if (dtrace_enabled)
+		return 0;
+
+	if (register_die_notifier(&dtrace_die) != 0)
+		return 1;
+
+	dtrace_enabled = 1;
+	return 0;
+}
+EXPORT_SYMBOL(dtrace_enable);
+
+void dtrace_disable(void)
+{
+	if (!dtrace_enabled)
+		return;
+
+	unregister_die_notifier(&dtrace_die);
+	dtrace_enabled = 0;
+}
+EXPORT_SYMBOL(dtrace_disable);
diff --git a/kernel/dtrace/dtrace_psinfo.c b/kernel/dtrace/dtrace_psinfo.c
new file mode 100644
index 000000000000..bb5f6fc2ce63
--- /dev/null
+++ b/kernel/dtrace/dtrace_psinfo.c
@@ -0,0 +1,212 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:	dtrace_psinfo.c
+ * DESCRIPTION:	DTrace - DTrace psinfo implementation
+ *
+ * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/binfmts.h>
+#include <linux/dtrace_psinfo.h>
+#include <linux/dtrace_task_impl.h>
+#include <linux/mm.h>
+#include <linux/sched.h>
+#include <linux/sched/mm.h>
+#include <linux/slab.h>
+#include <linux/uaccess.h>
+
+struct kmem_cache	*dtrace_psinfo_cachep;
+
+/*
+ * Free the psinfo_t structure.
+ */
+void dtrace_psinfo_free(struct dtrace_psinfo *psinfo)
+{
+	kfree(psinfo->dtps_argv);
+	kfree(psinfo->dtps_envp);
+	kmem_cache_free(dtrace_psinfo_cachep, psinfo);
+}
+
+/*
+ * Allocate a new dtrace_psinfo_t structure.
+ */
+void dtrace_psinfo_alloc(struct task_struct *tsk)
+{
+	struct dtrace_psinfo	*psinfo;
+	struct mm_struct	*mm = NULL;
+
+	if (unlikely(tsk->dt_task == NULL))
+		return;
+
+	if (likely(tsk->dt_task->dt_psinfo != NULL)) {
+		struct dtrace_psinfo *tmp = tsk->dt_task->dt_psinfo;
+		tsk->dt_task->dt_psinfo = NULL;
+
+		dtrace_psinfo_put(tmp);
+	}
+
+	psinfo = kmem_cache_alloc(dtrace_psinfo_cachep, GFP_KERNEL);
+	if (psinfo == NULL)
+		goto fail;
+
+	mm = get_task_mm(tsk);
+	if (mm) {
+		size_t	len = mm->arg_end - mm->arg_start;
+		int	i = 0;
+		char	*p;
+
+		/*
+		 * Construct the psargs string.
+		 */
+		if (len > 0) {
+			if (len >= PR_PSARGS_SZ)
+				len = PR_PSARGS_SZ - 1;
+
+			i = access_process_vm(tsk, mm->arg_start,
+					      psinfo->dtps_psargs, len, 0);
+
+			if (i > 0) {
+				if (i < len)
+					len = i;
+
+				for (i = 0, --len; i < len; i++) {
+					if (psinfo->dtps_psargs[i] == '\0')
+						psinfo->dtps_psargs[i] = ' ';
+				}
+			}
+		}
+
+		if (i < 0)
+			i = 0;
+
+		while (i < PR_PSARGS_SZ)
+			psinfo->dtps_psargs[i++] = 0;
+
+		/*
+		 * Determine the number of arguments.
+		 */
+		psinfo->dtps_argc = 0;
+		for (p = (char *)mm->arg_start; p < (char *)mm->arg_end;
+		     psinfo->dtps_argc++) {
+			size_t	l = strnlen_user(p, MAX_ARG_STRLEN);
+
+			if (!l)
+				break;
+
+			p += l + 1;
+		}
+
+		/*
+		 * Limit the number of stored argument pointers.
+		 */
+		len = psinfo->dtps_argc;
+		if (len >= PR_ARGV_SZ)
+			len = PR_ARGV_SZ - 1;
+
+		psinfo->dtps_argv = kmalloc((len + 1) * sizeof(char *),
+					 GFP_KERNEL);
+		if (psinfo->dtps_argv == NULL)
+			goto fail;
+
+		/*
+		 * Now populate the array of argument strings.
+		 */
+		for (i = 0, p = (char *)mm->arg_start; i < len; i++) {
+			psinfo->dtps_argv[i] = p;
+			p += strnlen_user(p, MAX_ARG_STRLEN) + 1;
+		}
+		psinfo->dtps_argv[len] = NULL;
+
+		/*
+		 * Determine the number of environment variables.
+		 */
+		psinfo->dtps_envc = 0;
+		for (p = (char *)mm->env_start; p < (char *)mm->env_end;
+		     psinfo->dtps_envc++) {
+			size_t	l = strnlen_user(p, MAX_ARG_STRLEN);
+
+			if (!l)
+				break;
+
+			p += l + 1;
+		}
+
+		/*
+		 * Limit the number of stored environment pointers.
+		 */
+		len = psinfo->dtps_envc;
+		if (len >= PR_ENVP_SZ)
+			len = PR_ENVP_SZ - 1;
+
+		psinfo->dtps_envp = kmalloc((len + 1) * sizeof(char *),
+					 GFP_KERNEL);
+		if (psinfo->dtps_envp == NULL)
+			goto fail;
+
+		/*
+		 * Now populate the array of environment variable strings.
+		 */
+		for (i = 0, p = (char *)mm->env_start; i < len; i++) {
+			psinfo->dtps_envp[i] = p;
+			p += strnlen_user(p, MAX_ARG_STRLEN) + 1;
+		}
+		psinfo->dtps_envp[len] = NULL;
+
+		mmput(mm);
+	} else {
+		size_t	len = min(TASK_COMM_LEN, PR_PSARGS_SZ);
+		int	i;
+
+		/*
+		 * We end up here for tasks that do not have managed memory at
+		 * all, which generally means that this is a kernel thread.
+		 * If it is not, this is still safe because we know that tasks
+		 * always have the comm member populated with something (even
+		 * if it would be an empty string).
+		 */
+		memcpy(psinfo->dtps_psargs, tsk->comm, len);
+		for (i = len; i < PR_PSARGS_SZ; i++)
+			psinfo->dtps_psargs[i] = 0;
+
+		psinfo->dtps_argc = 0;
+		psinfo->dtps_argv = kmalloc(sizeof(char *), GFP_KERNEL);
+		psinfo->dtps_argv[0] = NULL;
+		psinfo->dtps_envc = 0;
+		psinfo->dtps_envp = kmalloc(sizeof(char *), GFP_KERNEL);
+		psinfo->dtps_envp[0] = NULL;
+	}
+
+	atomic_set(&psinfo->dtps_usage, 1);
+	tsk->dt_task->dt_psinfo = psinfo;		/* new one */
+
+	return;
+
+fail:
+	if (mm)
+		mmput(mm);
+
+	if (psinfo)
+		dtrace_psinfo_free(psinfo);
+}
+
+/*
+ * Initialize DTrace's psinfo subsystem.
+ */
+void __init dtrace_psinfo_os_init(void)
+{
+	dtrace_psinfo_cachep = kmem_cache_create("dtrace_psinfo_cache",
+				sizeof(struct dtrace_psinfo), 0,
+				SLAB_HWCACHE_ALIGN | SLAB_PANIC,
+				NULL);
+
+}
diff --git a/kernel/dtrace/dtrace_task.c b/kernel/dtrace/dtrace_task.c
new file mode 100644
index 000000000000..02bcc6b7e0a2
--- /dev/null
+++ b/kernel/dtrace/dtrace_task.c
@@ -0,0 +1,237 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/*
+ * FILE:	dtrace_task.c
+ * DESCRIPTION:	DTrace - per-task data
+ *
+ * Copyright (c) 2018, Oracle and/or its affiliates. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/dtrace_task_impl.h>
+#include <linux/sched/mm.h>
+#include <linux/slab.h>
+
+struct kmem_cache	*dtrace_task_cachep;
+
+void (*dtrace_helpers_fork)(struct task_struct *, struct task_struct *);
+EXPORT_SYMBOL(dtrace_helpers_fork);
+
+/*
+ * Reset per-task sate to default values. Modifies only part of
+ * the state that does not persist across process forks.
+ */
+static void dtrace_task_reinit(struct dtrace_task *dtsk)
+{
+	dtsk->dt_predcache = 0;
+	dtsk->dt_stop = 0;
+	dtsk->dt_sig = 0;
+
+	dtsk->dt_helpers = NULL;
+	dtsk->dt_probes = 0;
+	dtsk->dt_tp_count = 0;
+}
+
+/*
+ * Allocate new per-task structure and initialize it with default
+ * values.
+ */
+static struct dtrace_task *dtrace_task_alloc(void)
+{
+	struct dtrace_task *dtsk;
+
+	/* Try to allocate new task. */
+	dtsk = kmem_cache_alloc(dtrace_task_cachep, GFP_KERNEL);
+	if (dtsk == NULL)
+		return NULL;
+
+	/* Initialize new task. */
+	dtrace_task_reinit(dtsk);
+
+	dtsk->dt_vtime = ktime_set(0, 0);
+	dtsk->dt_start = ktime_set(0, 0);
+	dtsk->dt_psinfo = NULL;
+	dtsk->dt_ustack = NULL;
+
+	return dtsk;
+}
+
+/*
+ * Cleans all attached resources to the per-task structure so it is ready to be
+ * reused or freed.
+ */
+static void dtrace_task_cleanup(struct task_struct *tsk)
+{
+	struct dtrace_psinfo *psinfo;
+
+	/* Nothing to remove. */
+	if (tsk->dt_task == NULL)
+		return;
+
+	/* Release psinfo if any. */
+	psinfo = tsk->dt_task->dt_psinfo;
+	if (psinfo != NULL) {
+		tsk->dt_task->dt_psinfo = NULL;
+		dtrace_psinfo_put(psinfo);
+	}
+}
+
+/*
+ * Kernel hooks for per-task events.
+ */
+
+/*
+ * Called when a new task has been created.
+ *
+ * It tries to allocate new per-task data strcture and initialize
+ * it with default values.
+ */
+void dtrace_task_init(struct task_struct *tsk)
+{
+	struct mm_struct	*mm = NULL;
+
+	/* Initialize new task structure */
+	tsk->dt_task = dtrace_task_alloc();
+	if (tsk->dt_task == NULL)
+		return;
+
+	/* Try to setup initial userspace stack. */
+	mm = get_task_mm(tsk);
+	if (mm) {
+		tsk->dt_task->dt_ustack = (void *)mm->start_stack;
+		mmput(mm);
+	}
+}
+
+/*
+ * Called when a task has been duplicated.
+ *
+ * When a task is duplicated this is called early to provide new instance
+ * of per-task data. This hook is called very early after a dup has been
+ * performed. The new task shares almost everything with its parent and
+ * locking performed must be aligned with locking of the kernel.
+ *
+ * DTrace resets new task to its default values.
+ */
+void dtrace_task_dup(struct task_struct *src, struct task_struct *dst)
+{
+	struct dtrace_psinfo *psinfo;
+	struct dtrace_task   *dtsk;
+
+	/* Nothing to clone. */
+	if (src->dt_task == NULL)
+		return;
+
+	/* Allocate and reinitialize new task. */
+	dtsk = dtrace_task_alloc();
+	if (dtsk == NULL) {
+		dst->dt_task = NULL;
+		return;
+	}
+	dtrace_task_reinit(dtsk);
+
+	/* Share psinfo if it is available. */
+	psinfo = src->dt_task->dt_psinfo;
+	if (psinfo != NULL) {
+		dtrace_psinfo_get(psinfo);
+		dtsk->dt_psinfo = psinfo;
+	}
+
+	/* Copy remaining attributes of the source task. */
+	dtsk->dt_ustack = src->dt_task->dt_ustack;
+	dst->dt_task = dtsk;
+}
+
+/*
+ * Called when a process has been copied.
+ *
+ * If the original task has helpers attached fork them too.
+ */
+void dtrace_task_copy(struct task_struct *tsk, struct task_struct *child)
+{
+	if (tsk->dt_task == NULL)
+		return;
+
+	if (child->dt_task == NULL)
+		return;
+
+	/* Handle helpers for this task. */
+	if (likely(dtrace_helpers_fork == NULL))
+		return;
+
+	if (tsk->dt_task->dt_helpers != NULL)
+		(*dtrace_helpers_fork)(tsk, child);
+}
+
+/*
+ * Called when a task has performed exec.
+ *
+ * If DTrace's per-task structure is already allocated it is reused for
+ * the new task. If it is not present an allocation attempt is made.
+ */
+void dtrace_task_exec(struct task_struct *tsk)
+{
+	struct mm_struct *mm = NULL;
+
+	/* Try to reuse existing dtrace task. */
+	if (tsk->dt_task != NULL) {
+		dtrace_task_cleanup(tsk);
+		dtrace_task_reinit(tsk->dt_task);
+
+		/* Try to set up initial userspace stack. */
+		mm = get_task_mm(tsk);
+		if (mm) {
+			tsk->dt_task->dt_ustack = (void *)mm->start_stack;
+			mmput(mm);
+		}
+	} else {
+		dtrace_task_init(tsk);
+
+		/* No luck, we won't be able to trace this task. */
+		if (tsk->dt_task == NULL)
+			return;
+	}
+
+	/* Finalize init of the per-task structure. */
+	dtrace_psinfo_alloc(tsk);
+}
+
+/*
+ * Called when a task is about to be released.
+ *
+ * The DTrace's per-task data are disconnected and freed.
+ */
+void dtrace_task_free(struct task_struct *tsk)
+{
+	struct dtrace_task *dtsk = tsk->dt_task;
+
+	/* Nothing to do. */
+	if (dtsk == NULL)
+		return;
+
+	/* Release the per-task data. */
+	dtrace_task_cleanup(tsk);
+	tsk->dt_task = NULL;
+	kmem_cache_free(dtrace_task_cachep, dtsk);
+}
+
+/*
+ * Initialize DTrace's task subsystem.
+ */
+void __init dtrace_task_os_init(void)
+{
+	/* Will panic if not initialized so no need to check for errors. */
+	dtrace_task_cachep = kmem_cache_create("dtrace_task_cache",
+				sizeof(struct dtrace_task), 0,
+				SLAB_HWCACHE_ALIGN | SLAB_PANIC,
+				NULL);
+}
+
diff --git a/kernel/exit.c b/kernel/exit.c
index d813ed83c00f..29297bd2d912 100644
--- a/kernel/exit.c
+++ b/kernel/exit.c
@@ -64,6 +64,7 @@
 #include <linux/rcuwait.h>
 #include <linux/compat.h>
 #include <linux/io_uring.h>
+#include <linux/dtrace_os.h>
 
 #include <linux/uaccess.h>
 #include <asm/unistd.h>
@@ -809,6 +810,9 @@ void __noreturn do_exit(long code)
 	tsk->exit_code = code;
 	taskstats_exit(tsk, group_dead);
 
+	/* Remove DTrace state for this task */
+	dtrace_task_free(tsk);
+
 	exit_mm();
 
 	if (group_dead)
diff --git a/kernel/fork.c b/kernel/fork.c
index 808af2cc8ab6..d03dad48e2c3 100644
--- a/kernel/fork.c
+++ b/kernel/fork.c
@@ -96,6 +96,7 @@
 #include <linux/kasan.h>
 #include <linux/scs.h>
 #include <linux/io_uring.h>
+#include <linux/dtrace_task_impl.h>
 
 #include <asm/pgalloc.h>
 #include <linux/uaccess.h>
@@ -443,6 +444,7 @@ void put_task_stack(struct task_struct *tsk)
 void free_task(struct task_struct *tsk)
 {
 	scs_release(tsk);
+	dtrace_task_free(tsk);
 
 #ifndef CONFIG_THREAD_INFO_IN_TASK
 	/*
@@ -945,6 +947,8 @@ static struct task_struct *dup_task_struct(struct task_struct *orig, int node)
 #ifdef CONFIG_MEMCG
 	tsk->active_memcg = NULL;
 #endif
+
+	dtrace_task_dup(orig, tsk);
 	return tsk;
 
 free_stack:
@@ -2313,6 +2317,25 @@ static __latent_entropy struct task_struct *copy_process(
 	syscall_tracepoint_update(p);
 	write_unlock_irq(&tasklist_lock);
 
+#ifdef CONFIG_DTRACE
+	/*
+	 * We make this call fairly late into the copy_process() handling,
+	 * because we need to ensure that we can look up this task based on
+	 * its pid using find_task_by_vpid().  We also must ensure that the
+	 * tasklist_lock has been released.
+	 */
+	dtrace_task_copy(current, p);
+
+	/*
+	 * If we're called with stack_start != 0, this is almost certainly a
+	 * thread being created in current.  Make sure it gets its own psinfo
+	 * data, because we need to record a new bottom of stack value.
+	 */
+	if (p->mm && args->stack)
+		if (p->dt_task != NULL)
+			p->dt_task->dt_ustack = (void *)args->stack;
+#endif
+
 	proc_fork_connector(p);
 	sched_post_fork(p);
 	cgroup_post_fork(p, args);
diff --git a/kernel/module.c b/kernel/module.c
index 77ffce94083f..88e52934a28a 100644
--- a/kernel/module.c
+++ b/kernel/module.c
@@ -45,6 +45,7 @@
 #include <asm/mmu_context.h>
 #include <linux/license.h>
 #include <asm/sections.h>
+#include <linux/dtrace_os.h>
 #include <linux/tracepoint.h>
 #include <linux/ftrace.h>
 #include <linux/livepatch.h>
@@ -90,6 +91,9 @@
 DEFINE_MUTEX(module_mutex);
 EXPORT_SYMBOL_GPL(module_mutex);
 static LIST_HEAD(modules);
+#ifdef CONFIG_DTRACE
+struct list_head *dtrace_modules = &modules;
+#endif /* CONFIG_DTRACE */
 
 /* Work queue for freeing init sections in success case */
 static void do_free_init(struct work_struct *w);
@@ -1052,6 +1056,12 @@ SYSCALL_DEFINE2(delete_module, const char __user *, name_user,
 		}
 	}
 
+	/* Try destroying DTrace provider. */
+	if (!dtrace_destroy_prov(mod)) {
+		ret = -EBUSY;
+		goto out;
+	}
+
 	/* Stop the machine so refcounts can't move and disable module. */
 	ret = try_stop_module(mod, flags, &forced);
 	if (ret != 0)
@@ -2243,6 +2253,7 @@ void __weak module_arch_freeing_init(struct module *mod)
 /* Free a module, remove from lists, etc. */
 static void free_module(struct module *mod)
 {
+	dtrace_mod_pdata_free(mod);
 	trace_module_free(mod);
 
 	mod_sysfs_teardown(mod);
@@ -4124,6 +4135,9 @@ static int load_module(struct load_info *info, const char __user *uargs,
 	/* Ftrace init must be called in the MODULE_STATE_UNFORMED state */
 	ftrace_module_init(mod);
 
+	/* Allocate DTrace per-module data. */
+	dtrace_mod_pdata_alloc(mod);
+
 	/* Finally it's fully formed, ready to start executing. */
 	err = complete_formation(mod, info);
 	if (err)
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index f0056507a373..56ab7d62c1a7 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -13,6 +13,7 @@
 #include "sched.h"
 
 #include <linux/nospec.h>
+#include <linux/dtrace_os.h>
 
 #include <linux/kcov.h>
 #include <linux/scs.h>
@@ -4173,6 +4174,11 @@ static struct rq *finish_task_switch(struct task_struct *prev)
 
 	rq->prev_mm = NULL;
 
+#ifdef CONFIG_DTRACE
+	if (dtrace_vtime_active)
+		dtrace_vtime_switch(prev, current);
+#endif
+
 	/*
 	 * A task struct has one reference for the use as "current".
 	 * If a task dies, then it sets TASK_DEAD in tsk->state and calls
@@ -7856,6 +7862,10 @@ void __init sched_init(void)
 #endif /* CONFIG_SMP */
 		hrtick_rq_init(rq);
 		atomic_set(&rq->nr_iowait, 0);
+
+#ifdef CONFIG_DTRACE
+		rq->dtrace_cpu_info = per_cpu_info(i);
+#endif
 	}
 
 	set_load_weight(&init_task, false);
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
index 282a6bbaacd7..b2b25d768c8f 100644
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -344,6 +344,7 @@ extern bool dl_cpu_busy(unsigned int cpu);
 #ifdef CONFIG_CGROUP_SCHED
 
 #include <linux/cgroup.h>
+#include <linux/dtrace_cpu.h>
 #include <linux/psi.h>
 
 struct cfs_rq;
@@ -1062,6 +1063,10 @@ struct rq {
 #endif
 	unsigned int		push_busy;
 	struct cpu_stop_work	push_work;
+
+#ifdef CONFIG_DTRACE
+	struct cpuinfo		*dtrace_cpu_info;
+#endif
 };
 
 #ifdef CONFIG_FAIR_GROUP_SCHED
diff --git a/kernel/time/timekeeping.c b/kernel/time/timekeeping.c
index 6aee5768c86f..b3036c5f659d 100644
--- a/kernel/time/timekeeping.c
+++ b/kernel/time/timekeeping.c
@@ -22,6 +22,7 @@
 #include <linux/pvclock_gtod.h>
 #include <linux/compiler.h>
 #include <linux/audit.h>
+#include <linux/dtrace_os.h>
 
 #include "tick-internal.h"
 #include "ntp_internal.h"
@@ -746,6 +747,7 @@ static void timekeeping_update(struct timekeeper *tk, unsigned int action)
 	tk_update_ktime_data(tk);
 
 	update_vsyscall(tk);
+	dtrace_update_time(tk);
 	update_pvclock_gtod(tk, action & TK_CLOCK_WAS_SET);
 
 	tk->tkr_mono.base_real = tk->tkr_mono.base + tk->offs_real;
diff --git a/scripts/coccinelle/dtrace/enum-elision.cocci b/scripts/coccinelle/dtrace/enum-elision.cocci
new file mode 100644
index 000000000000..77a5b33bd166
--- /dev/null
+++ b/scripts/coccinelle/dtrace/enum-elision.cocci
@@ -0,0 +1,29 @@
+/// Reduce uses of typedefs of named enums to the name of the enum
+
+virtual patch
+virtual context
+virtual org
+virtual report
+
+@td@
+type T;
+identifier E;
+@@
+- typedef enum E
++ enum E
+  { ...
+- } T;
++ };
+@@
+type td.T;
+identifier td.E;
+@@
+- T
++ enum E
+
+@@
+type td.T;
+identifier td.E;
+@@
+- const T
++ const enum E
diff --git a/scripts/coccinelle/dtrace/typedef-elision.cocci b/scripts/coccinelle/dtrace/typedef-elision.cocci
new file mode 100644
index 000000000000..bc4caf375b60
--- /dev/null
+++ b/scripts/coccinelle/dtrace/typedef-elision.cocci
@@ -0,0 +1,83 @@
+/// Reduce uses of typedefs of named structures to the name of the structure
+
+virtual patch
+virtual context
+virtual org
+virtual report
+
+@td@
+type T;
+identifier S;
+@@
+(
+- typedef struct S
++ struct S
+  { ...
+- } T;
++ };
+|
+  struct S;
+- typedef struct S T;
+)
+@@
+type td.T;
+identifier td.S;
+@@
+- T
++ struct S
+
+@@
+type td.T;
+identifier td.S;
+@@
+- const T
++ const struct S
+
+/// Now structures declared with typedefs of opaque structs, one by one
+@@
+typedef dtrace_ecb_t;
+@@
+- dtrace_ecb_t
++ struct dtrace_ecb
+
+@@
+typedef dtrace_actdesc_t;
+@@
+- dtrace_actdesc_t
++ struct dtrace_actdesc
+
+@@
+typedef dtrace_state_t;
+@@
+- dtrace_state_t
++ struct dtrace_state
+
+@@
+typedef dtrace_vstate_t;
+@@
+- dtrace_vstate_t
++ struct dtrace_vstate
+
+@@
+typedef dtrace_mstate_t;
+@@
+- dtrace_mstate_t
++ struct dtrace_mstate
+
+@@
+typedef dtrace_task_t;
+@@
+- dtrace_task_t
++ struct dtrace_task
+
+@@
+typedef dtrace_psinfo_t;
+@@
+- dtrace_psinfo_t
++ struct dtrace_psinfo
+
+@@
+typedef dt_fbt_bl_entry_t;
+@@
+- dt_fbt_bl_entry_t
++ struct dt_fbt_bl_entry
diff --git a/scripts/package/mkspec b/scripts/package/mkspec
index e9ff22c6fb4c..cba5be72adb9 100755
--- a/scripts/package/mkspec
+++ b/scripts/package/mkspec
@@ -150,6 +150,7 @@ $M	%exclude /lib/modules/$KERNELRELEASE/source
 	%files headers
 	%defattr (-, root, root)
 	/usr/include
+	%exclude /usr/include/linux/dtrace
 $S$M
 $S$M	%files devel
 $S$M	%defattr (-, root, root)
-- 
2.32.0

